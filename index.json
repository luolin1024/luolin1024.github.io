[{"content":"为什么要做好系统安全？ 作为技术开发人员，偶尔会有疏忽，但作为系统架构师，必须更加系统化、全面地考虑系统的安全问题。确保系统的安全性不仅是技术责任，也关系到公司的业务和信誉。\n系统安全的重要性体现在以下几个方面：\n防止服务中断和数据丢失\n如果系统软件受到攻击，可能会导致服务中断、数据丢失，甚至可能引发业务崩溃，带来不可估量的损失。 保护关键数据\n系统中往往包含大量重要的业务数据，这些数据可能会受到窃取、篡改或丢失，因此必须加强数据保护。 合规性和审计要求\n许多法律法规和审计标准都对数据安全有明确要求，定期的合规性审计也是企业必不可少的安全措施。 技术提升\n自己管理的系统被攻击或业务数据丢失，通常说明技术层面还有提升空间。因此，做好安全管理是技术能力的重要体现。 职业发展\n系统安全是IT行业的核心技能之一。了解和掌握相关安全知识不仅能增强技术能力，也能在职业发展中提高竞争力。 系统安全的目标 从上述原因来看，系统安全的核心目标可以总结为以下三个方面：\n可用性：确保系统在遭受攻击或发生故障时依然能够正常运行。 保密性：保护系统中的敏感数据不被泄露。 完整性：防止数据或系统文件被恶意篡改。 安全技术分析 根据系统的不同层次，安全技术大致可以分为三个层面：网络层、安全层、应用层。同时，贯穿于这些层次的管理层，也起着至关重要的作用。安全技术的层次结构如下图所示：\n网络层 网络层面面临的最大威胁是数据在传输过程中可能被篡改。为此，可以采取以下防护手段：\n限制访问：在业务网络中引入防火墙，合理配置ACL策略，严格控制网络访问。 加密传输：对于管理流量、敏感数据等，采用加密协议（如HTTPS、SSHv2等）进行安全传输，确保数据在跨越信任网络时不被泄露。 数据完整性校验：确保数据在传输过程中不会被篡改，可以使用加密哈希值等技术进行校验。 系统层 系统层安全包括操作系统、数据库、中间件等的安全配置。需要重点关注以下几个方面：\n操作系统安全：\n使用稳定、安全的操作系统版本，并及时安装操作系统供应商发布的安全补丁。 操作系统安装后应进行安全加固，关闭不必要的端口，开启必要的漏洞防御机制。 数据库安全：\n选择已知安全的数据库版本（如MySQL、PostgreSQL等），并定期更新数据库安全补丁。 强化数据库访问权限管理，防止未经授权的访问和数据篡改。 应用服务器和中间件安全：\n选择最新版本的应用服务器（如Tomcat）并对其进行安全配置，避免已知漏洞的威胁。 加强中间件（如MQ、Redis等）的安全配置，确保没有高危漏洞。 应用层 应用层安全涵盖了账号管理、身份认证、访问控制、密钥管理、输入校验等多个方面，具体措施包括：\n账号和口令安全：\n提供口令复杂度检测机制，并要求用户修改默认密码，避免因弱口令带来安全隐患。 认证安全：\n采用防暴力破解机制，当用户输入密码错误超过一定次数时，锁定账号，防止暴力攻击。 支持多因素认证（2FA）等更安全的认证方式。 密钥管理：\n通过加密技术确保用户密码和其他敏感信息的安全。 密钥存储时进行加密保护，并定期更新密钥。 会话管理：\n服务器对会话状态进行验证，确保每次访问都经过认证，并采取措施防止会话固定攻击。 设置会话超时机制，避免会话被恶意利用。 访问控制与授权：\n基于最小权限原则，确保每个进程和用户只能访问必要的资源。 使用权限隔离、不同UID等手段，确保高低风险模块分开，避免数据泄露和滥用。 管理层 管理层的安全管理，涉及对技术和非技术方面的协调和管理：\n帐号与权限管理：确保每个用户使用独立账号，防止共享账号带来的风险。同时，定期清理系统中无用的帐号和组。 日志审计：对系统操作进行日志记录，确保能够追溯异常操作和潜在的安全风险。 软件完整性保护：对发布的软件包进行签名和完整性校验，确保软件未被篡改。 安全管理不仅仅是技术手段的整合，还需要规范的流程、政策和制度。确保系统安全，离不开团队成员的安全意识提升和安全操作规范。\n总结 系统安全不仅是技术层面的挑战，更是公司运营和个人职业发展的关键因素。通过系统化地管理和优化网络层、系统层、应用层的安全措施，我们能够有效降低安全风险，保障企业的正常运营。同时，安全意识和技能的不断提升，也是开发人员职业成长的重要方面。系统安全的保障，不仅仅是防止攻击，更是为业务和数据的健康发展提供强有力的支撑。\n","permalink":"https://luolin1024.github.io/2024/11/security-for-system-architects/","summary":"为什么要做好系统安全？ 作为技术开发人员，偶尔会有疏忽，但作为系统架构师，必须更加系统化、全面地考虑系统的安全问题。确保系统的安全性不仅是技术","title":"全面提升系统安全意识：从网络、系统到应用层的多维度防护策略"},{"content":" 本文不是科普文，主要是一些LogBack和Springboot默认使用LogBack情况下遇到的一些问题以及对应解决方案\n日志级别 日志级别从低到高分为：\nTRACE \u0026lt; DEBUG \u0026lt; INFO \u0026lt; WARN \u0026lt; ERROR \u0026lt; FATAL\nLogBack会按照高于或等于当前配置的级别进行输出；例如日志级别设置为 WARN ，则低于 WARN 的信息都不会输出。\nSpringBoot中的默认使用 Spring Boot中默认日志输出级别为INFO，因此只有ERROR、WARN和INFO级别的日志会输出到控制台 LogBack日志级别优先级 LogBack默认使用最小子级的日志级别，比如下面配置案例中，如果是com.lin.controller中的日志，则会按照error级别进行控制输出，如果是com.lin以外的日志内容，则按照info级别控制输出\nlogging: level: root: info com.lin.controller: error com.lin: debug 注意，如果设置root为debug，对于项目中实际日志不需要的且没有被限制输出的情况下，他们的debug日志也会被打印出来，例如： 对于一个正常的大型项目来讲，强烈建议不要设置root为debug。\n自定义日志输出 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;clr\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.ColorConverter\u0026#34; /\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;wex\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\u0026#34; /\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;wEx\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;CONSOLE_LOG_PATTERN\u0026#34; value=\u0026#34;${CONSOLE_LOG_PATTERN:-%clr(%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;FILE_LOG_PATTERN\u0026#34; value=\u0026#34;${FILE_LOG_PATTERN:-%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}} ${LOG_LEVEL_PATTERN:-%5p} ${PID:- } --- [%t] %-40.40logger{39} : %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\u0026#34;/\u0026gt; \u0026lt;!-- 输出到控制台 --\u0026gt; \u0026lt;appender name=\u0026#34;CONSOLE-LOG\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;layout class=\u0026#34;ch.qos.logback.classic.PatternLayout\u0026#34;\u0026gt; \u0026lt;pattern\u0026gt;${CONSOLE_LOG_PATTERN}\u0026lt;/pattern\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- 异步输出 --\u0026gt; \u0026lt;appender name=\u0026#34;ASYNC-INFO\u0026#34; class=\u0026#34;ch.qos.logback.classic.AsyncAppender\u0026#34;\u0026gt; \u0026lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --\u0026gt; \u0026lt;discardingThreshold\u0026gt;8\u0026lt;/discardingThreshold\u0026gt; \u0026lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --\u0026gt; \u0026lt;queueSize\u0026gt;256\u0026lt;/queueSize\u0026gt; \u0026lt;!-- 添加附加的appender,最多只能添加一个 --\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE-LOG\u0026#34;/\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- 指定最基础的日志输出级别 --\u0026gt; \u0026lt;root level=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;ASYNC-INFO\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; 注意事项 如果是自己自定义配置了日志输出，同时想要指定某些包下的日志级别调整，则尽量使用additivity=\u0026quot;false\u0026quot;，例如：\n\u0026lt;logger name=\u0026#34;com.lin.controller\u0026#34; level=\u0026#34;debug\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE-LOG\u0026#34; /\u0026gt; \u0026lt;/logger\u0026gt; additivity的作用在于当前logger是否使用上级logeer（一般是root logger）配置的appender进行输出。\nfalse：表示只用当前logger的appender-ref。 true：表示当前logger的appender-ref和rootLogger的appender-ref都有效。这个是默认值。 如果当前logger设置了日志级别，但是没有设置additivity，则可能输出两次，此时需要使用additivity=\u0026quot;false\u0026quot;。 日志过滤 \u0026lt;turboFilter class=\u0026#34;org.lin.boot.ctrl.log.LogFilter\u0026#34;/\u0026gt; public class LogFilter extends TurboFilter { @Override public FilterReply decide(Marker marker, ch.qos.logback.classic.Logger logger, Level level, String format, Object[] params, Throwable t) { // 重写限制规则 return FilterReply.NEUTRAL; } } 配置加载优先级 Logback默认支持的配置文件：\n@Override protected String[] getStandardConfigLocations() { return new String[] { \u0026#34;logback-test.groovy\u0026#34;, \u0026#34;logback-test.xml\u0026#34;, \u0026#34;logback.groovy\u0026#34;, \u0026#34;logback.xml\u0026#34; }; } Springboot支持的配置文件：\nprotected String[] getSpringConfigLocations() { String[] locations = getStandardConfigLocations(); for (int i = 0; i \u0026lt; locations.length; i++) { String extension = StringUtils.getFilenameExtension(locations[i]); locations[i] = locations[i].substring(0, locations[i].length() - extension.length() - 1) + \u0026#34;-spring.\u0026#34; + extension; } return locations; } 优先级为Logback默认配置\u0026gt;默认配置的前缀“-spring”.xml\nlogback-test.xml \u0026gt; logback.groovy \u0026gt; logback.xml \u0026gt; logback-spring.groovy \u0026gt; logback-spring.xml\n原理 logback 的初始化步骤：\nlogback 会在类路径下寻找名为 logback-test.xml 的文件。 如果没有找到，logback 会继续寻找名为 logback.groovy 的文件。 如果没有找到，logback 会继续寻找名为 logback.xml 的文件。 如果没有找到，将会通过 JDK 提供的 ServiceLoader 工具在类路径下寻找文件 META-INFO/services/ch.qos.logback.classic.spi.Configurator，该文件的内容为实现了 Configurator 接口的实现类的全限定类名。 如果以上都没有成功，logback 会通过 BasicConfigurator 为自己进行配置，并且日志将会全部在控制台打印出来。 Springboot在上述第3步后添加步骤：如果尝试寻找名为logback.groovy、logback-spring.xml的文件\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/logback%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/","summary":"本文不是科普文，主要是一些LogBack和Springboot默认使用LogBack情况下遇到的一些问题以及对应解决方案 日志级别 日志级别从低","title":"LogBack踩坑记录"},{"content":"M1 安装mat 下载arm架构的jdk11：https://www.azul.com/downloads/?version=java-11-lts\u0026amp;os=macos\u0026amp;architecture=arm-64-bit\u0026amp;package=jdk\n下载arm架构的mat：https://www.eclipse.org/mat/downloads.php\nM1安装Viscosity 1.9.1 Viscosity：Mac端个人认为最好用的vpn，\nuse Little Snitch block Outgoing Connections Name: [Black Flag ] Email: random@user.com Serial: VM1U-QY3G41-XN5IYG-WIOCN2-RX7ZDS-UCHA4Y Mac M1通过jenv配置多版本jdk且可以主动切换 通过brew安装jenv\nbrew install jenv 通过命令查看你所使用的 shell\necho $0 如果是 bash 配置文件则为~/.bash_profile，按照方式一执行命令\n如果是 zsh，则配置文件为~/.zshrc，按照方式二执行命令\n方式一 echo \u0026#39;export PATH=\u0026#34;$HOME/.jenv/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bash_profile echo \u0026#39;eval \u0026#34;$(jenv init -)\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bash_profile source ~/.bash_profile 方式二 echo \u0026#39;export PATH=\u0026#34;$HOME/.jenv/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc echo \u0026#39;eval \u0026#34;$(jenv init -)\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc 此时jenv中没有管理任何java包，执行以下命令无结果\njenv versions 还需要像jenv中添加java包：\njenv add /Library/Java/JavaVirtualMachines/zulu-8.jdk/Contents/Home jenv add /Library/Java/JavaVirtualMachines/zulu-11.jdk/Contents/Home jenv add /Library/Java/JavaVirtualMachines/graalvm-ee-java17-22.3.1/Contents/Home 设置全局默认使用jdk1.8\njenv global 1.8 参考：\nhttps://icode.best/i/40028344746976\nhttps://blog.csdn.net/weixin_52911459/article/details/128063285\nMac：Understand破解 下载链接: https://pan.baidu.com/s/19H5qVc6kRSg9Jbmpm4grkA 提取码: 1nnv\n打开软件，开始激活，点击enter License Code\n点击“use legacy licenseing”\n点击“ADD A license”\n出现如下图，请选择“Add Eval SDL (RegCode)” 弹出注册界面，输入license code，邮箱任意输入 license code：\n185F996AEEC2 7808F4308398 F38075B00218 EBF578C60F6E 00479F7EE8D6 软件“Understand”破解成功！\nAxure9激活 Licensee:Freecrackdownload.comKey:5vYpJgQZ431X/G5kp6jpOO8Vi3TySCBnAslTcNcKkszfPH7jaM4eKM8CrALBcEC1\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E5%B7%A5%E5%85%B7/mac-m1%E5%A5%BD%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%88%97%E8%A1%A8%E4%B8%8E%E7%A0%B4%E8%A7%A3/","summary":"M1 安装mat 下载arm架构的jdk11：https://www.azul.com/downloads/?version=java-11-lt","title":"Mac M1好用软件列表与破解"},{"content":" 明确自己阅读的目的 扩充知识：期望扩充哪方面的知识呢 研究他人的方法论？ 深挖某些知识点？ 当前看的内容是否合适？ 应用方法论 SQ3R 阅读法 Survey (预览): 快速浏览标题、目录、摘要等，了解文章或书籍的大意。 Question (提问): 对内容提出问题，带着问题阅读能提高理解力。 Read (阅读): 带着问题进行深入阅读。 Recite (复述): 阅读后复述主要内容，加深记忆。 Review (复习): 定期复习，巩固所学内容。 PQRST 学习法 Preview (预习): 预习学习材料，形成整体概念。 Question (提问): 对学习材料提出问题。 Read (阅读): 带着问题阅读，寻找答案。 Self-recite (自我复述): 自我复述关键内容。 Test (测试): 自我测试，检查理解和记忆效果。 费曼技巧 选择一个你想学习的概念，然后试着用最简单的语言向别人解释。 发现自己无法解释清楚的部分，回头再学习，直到能用简单的语言解释为止。 笔记整理： 边读边记: 在阅读过程中随时记录自己的思考和疑问。 整理笔记: 阅读结束后，将所有笔记整理成系统的知识框架，可以使用思维导图或者结构化笔记软件（如Notion）。 定期复习: 定期复习整理好的笔记，巩固记忆和理解。 作用：加强记忆、方便后期回顾 如何阅读一本书 (豆瓣) (douban.com)\n","permalink":"https://luolin1024.github.io/blog_prepublish/pre-publish/%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E6%9C%AC%E4%B9%A6/","summary":"明确自己阅读的目的 扩充知识：期望扩充哪方面的知识呢 研究他人的方法论？ 深挖某些知识点？ 当前看的内容是否合适？ 应用方法论 SQ3R 阅读法 Survey (预览): 快速","title":"如何阅读一本书"},{"content":"Spring框架 Spring 中的条件注解 - spring 中文网 (springdoc.cn)\nSpringMVC框架 拦截器 源码分析Spring boot拦截器执行顺序_spring interceptor优先级设置-CSDN博客\nSpringBoot框架 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/springboot%E5%AD%A6%E4%B9%A0/","summary":"Spring框架 Spring 中的条件注解 - spring 中文网 (springdoc.cn) SpringMVC框架 拦截器 源码分析Spring boot拦截器执行顺序_spring interce","title":"SpringBoot学习"},{"content":"在服务器上配置 Spring Boot 应用作为服务（Service）启动通常涉及创建一个 Systemd 服务单元。Systemd 是 Linux 系统中常用的系统和服务管理器。\n以下是配置 Spring Boot 应用作为 Systemd 服务的一般步骤：\n1. 创建一个 Systemd 服务单元文件 在 /etc/systemd/system/ 目录下创建一个新的 .service 文件，比如 my-spring-boot-app.service。\nsudo nano /etc/systemd/system/my-spring-boot-app.service 2. 编辑服务单元文件 在文件中添加类似以下内容的配置，根据你的实际情况修改路径和参数：\n[Unit] Description=My Spring Boot Application After=syslog.target [Service] User=your-user ExecStart=/usr/bin/java -jar /path/to/your/spring-boot-app.jar SuccessExitStatus=143 Restart=on-failure [Install] WantedBy=multi-user.target Description: 描述服务的简短说明。 User: 用于运行 Spring Boot 应用的用户。 ExecStart: 指定启动命令，包括 Java 命令和 Spring Boot JAR 文件的路径。 SuccessExitStatus: 成功退出的状态码。 Restart: 定义服务在失败时是否自动重启。 WantedBy: 定义服务应该在何时启动，这里是 multi-user.target 表示多用户模式启动时启动。 3. 重新加载 Systemd 并启动服务 保存并退出编辑器后，重新加载 Systemd 并启动你的服务：\nsudo systemctl daemon-reload sudo systemctl start my-spring-boot-app 4. 验证服务状态 可以使用以下命令来检查服务的状态：\nsudo systemctl status my-spring-boot-app 5. 设置开机自启动（可选） 如果你想让服务在系统启动时自动启动，可以使用以下命令：\nsudo systemctl enable my-spring-boot-app 注意事项： 替换配置文件中的 your-user 为你的实际用户名，/path/to/your/spring-boot-app.jar 为你的 Spring Boot 应用的路径。 确保 Java 已经安装并且可以在系统中正确运行。 通过 Systemd 启动的服务会在后台运行，你可以使用 sudo journalctl -u my-spring-boot-app.service 查看服务的日志。 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/linux/linux%E4%B8%8A%E9%85%8D%E7%BD%AEspringboot%E4%BD%9C%E4%B8%BAsystemd-%E6%9C%8D%E5%8A%A1%E5%8D%95%E5%85%83/","summary":"在服务器上配置 Spring Boot 应用作为服务（Service）启动通常涉及创建一个 Systemd 服务单元。Systemd 是 Linux 系统中常用的系统和服务管理器。 以下是配置 Spring","title":"Linux上配置springboot作为Systemd 服务单元"},{"content":" 使用方式：ln [option] source_file dist_file -f 建立时，将同档案名删除.\n-i 删除前进行询问.\nln -s abc cde 建立abc 的软连接\nln abc cde 建立abc的硬连接， 软链接与硬链接的区别（通俗）： 硬链接可认为是一个文件拥有两个文件名;而软链接则是系统新建一个链接文件，此文件指向其所要指的文件\nln -s /root/lntest/source/ /root/lntest/dist/\n软链接与硬链接的区别（讲解）： Linux 软连接与硬连接\n对于一个文件来说，有唯一的索引接点与之对应，而、对于一个索引接点号，却可以有多个文件名与之对应。因此，在磁盘上的同一个文件可以通过不同的路径去访问该文件。注意在Linux下是一切皆文件的啊，文件夹、新加的硬盘 \u0026hellip;都可以看着文件来处理的啊。\n连接有软连接和硬连接(hard link)之分的，软连接(symbolic link)又叫符号连接。符号连接相当于Windows下的快捷方式。\n不可以对文件夹建立硬连接的，我们通常用的还是软连接比较多。\neg:\nln -s source dist # 建立软连接\nln -s /mnt/hgfs/ /home/luo/ 注意后面的“/” 是将目录里所有的文件链接过去，必须加上，否则，建立的目录显示颜色异常，还不能正常访问，如cd 进不去\nln source dist # 建立硬连接\n软链接实际上只是一段文字，里面包含着它所指向的文件的名字，系统看到软链接后自动跳到对应的文件位置处进行处理；相反，硬联接为文件开设一个新的目录项，硬链接与文件原有的名字是平权的，在Linux看来它们是等价的。由于这个原因，硬链接不能连接两个不同文件系统上的文件。\n（1）软连接可以 跨文件系统 ，硬连接不可以 。实践的方法就是用共享文件把windows下的 aa.txt文本文档连接到linux下/root目录 下 bb,cc . ln -s aa.txt /root/bb 连接成功 。ln aa.txt /root/bb 失败 。\n（2）关于 I节点的问题 。硬连接不管有多少个，都指向的是同一个I节点，会把 结点连接数增加，只要结点的连接数不是 0，文件就一直存在，不管你删除的是源文件还是 连接的文件 。只要有一个存在 ，文件就 存在 （其实也不分什么源文件连接文件的 ，因为他们指向都是同一个 I节点）。 当你修改源文件或者连接文件任何一个的时候 ，其他的文件都会做同步的修改。软链接不直接使用i节点号作为文件指针,而是使用文件路径名作为指针。所以 删除连接文件 对源文件无影响，但是删除源文件，连接文件就会找不到要指向的文件 。软链接有自己的inode,并在磁盘上有一小片空间存放路径名.\n（3）软连接可以对一个不存在的文件名进行连接 。\n（4）软连接可以对目录进行连接。\n备注：I节点 :它是UNIX内部用于描述文件特性的数据结构.我们通常称I节点为文件索引结点(信息结点).i节点含有关于文件的大部分的重要信息,包括文件数据块在磁盘上的地址.每一个I节点有它自己的标志号,我们称为文件顺序号.I节点包含的信息 1.文件类型 2.文件属主关系 3.文件的访问权限 4.文件的时间截.\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/linux/linux%E9%80%9A%E8%BF%87ln%E5%91%BD%E4%BB%A4%E5%BB%BA%E7%AB%8B%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E9%93%BE%E6%8E%A5/","summary":"使用方式：ln [option] source_file dist_file -f 建立时，将同档案名删除. -i 删除前进行询问. ln -s abc cde 建立abc 的软连接 ln abc cde 建立abc的硬连接， 软链接与硬链接的区别（通","title":"Linux通过ln命令建立文件\u0026目录链接"},{"content":" 添加用户 adduser username 添加sudo权限 usermod -G sudo username 添加root权限 sudo vim /etc/sudoers # User privilege specification root ALL=(ALL) ALL username ALL=(ALL) ALL 保存退出，username 用户就拥有了root权限。\nroot用户修改其他用户的密码 在root用户下，运行passwd 来重设的密码。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/linux/ubuntu22-%E6%B7%BB%E5%8A%A0%E7%94%A8%E6%88%B7%E5%B9%B6%E8%B5%8Bsudo%E6%9D%83%E9%99%90/","summary":"添加用户 adduser username 添加sudo权限 usermod -G sudo username 添加root权限 sudo vim /etc/sudoers # User privilege specification root ALL=(ALL) ALL username ALL=(ALL) ALL 保存退出，username 用户就拥有了root权限。 root用","title":"ubuntu22 添加用户并赋sudo权限"},{"content":" 协议 商业用途 修改 分发 GPL 限制 要求公开 要求开源 LGPL 允许 要求公开 允许分发修改版本 MPL 允许 不要求 要求修改版本开源 MIT 允许 不要求 允许分发修改版本 Apache 2.0 允许 不要求 允许分发修改版本 取自阮一峰老师的图： ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E5%85%B6%E4%BB%96/open-source-protocol/","summary":"协议 商业用途 修改 分发 GPL 限制 要求公开 要求开源 LGPL 允许 要求公开 允许分发修改版本 MPL 允许 不要求 要求修改版本开源 MIT 允许 不要求 允许分发修改版本 Apache 2.0 允许 不要","title":"开源协议"},{"content":"本文介绍Ubuntu 22.04手动搭建LNMP环境并做基础配置。nginx和php使用Ondřej Surý的ppa源进行安装和升级，mysql使用Ubuntu自带的软件源进行安装。本文操作在root账户下进行，非root用户需要使用sudo提升执行权限。\n安装NGINX 添加nginx软件源\n稳定版本\napt install software-properties-common -y \u0026amp;\u0026amp; add-apt-repository ppa:ondrej/nginx -y 主线版本\napt install software-properties-common -y \u0026amp;\u0026amp; add-apt-repository ppa:ondrej/nginx-mainline -y 安装nginx\nsudo apt -y install nginx 查看nginx版本号\nnginx -v 查看服务运行状态\nsystemctl status nginx 设置nginx服务开机自启动\nsystemctl enable nginx 重启nginx服务\nsystemctl restart nginx 安装PHP 添加php软件源\napt install software-properties-common -y \u0026amp;\u0026amp; add-apt-repository ppa:ondrej/php -y 安装php8.1及常用扩展\napt install php8.1 php8.1-fpm php8.1-curl php8.1-mbstring php8.1-ldap php8.1-tidy php8.1-xml php8.1-zip php8.1-gd php8.1-mysql -y 配置php\ncat \u0026gt; /etc/php/8.1/fpm/conf.d/config_php.ini \u0026lt;\u0026lt; EOF expose_php = Off error_reporting = E_ALL \u0026amp; ~E_NOTICE display_errors = Off display_startup_errors = Off log_errors = On error_log = /var/log/php_errors.log ignore_repeated_errors = Off allow_url_fopen = On allow_url_include = Off variables_order = \u0026#34;GPCS\u0026#34; allow_webdav_methods = On memory_limit = 128M max_execution_time = 300 output_buffering = On output_handler = \u0026#34;\u0026#34; zlib.output_compression = Off zlib.output_handler = \u0026#34;\u0026#34; safe_mode = Off register_globals = Off magic_quotes_gpc = Off file_uploads = On upload_max_filesize = 50M post_max_size = 50M enable_dl = Off disable_functions = \u0026#34;\u0026#34; disable_classes = \u0026#34;\u0026#34; session.save_handler = files session.use_cookies = 1 session.use_only_cookies = 1 session.auto_start = 0 session.cookie_lifetime = 0 session.cookie_httponly = 1 session.save_path = \u0026#34;/var/lib/php/sessions\u0026#34; opcache.enable=1 opcache.enable_cli=1 opcache.interned_strings_buffer=8 opcache.max_accelerated_files=10000 opcache.memory_consumption=128 opcache.save_comments=1 opcache.revalidate_freq=1 date.timezone = \u0026#34;PRC\u0026#34; EOF 重启php服务\nsystemctl restart php8.1-fpm.service 安装ionCube Loader模块（可选）\n下载ionCube Loader扩展\nwget https://downloads.ioncube.com/loader_downloads/ioncube_loaders_lin_x86-64.zip \u0026amp;\u0026amp; unzip ioncube_loaders_lin_x86-64.zip ioncube_loader需与php版本相对应，这里选择php8.1版本的ioncube_loader。将ioncube_loader_lin_8.1.so复制到php8.1的扩展目录/usr/lib/php/20210902\ncp ioncube/ioncube_loader_lin_8.1.so /usr/lib/php/20210902 添加ioncube_loader模块配置文件\ncat \u0026gt;\u0026gt; /etc/php/8.1/mods-available/ioncube.ini \u0026lt;\u0026lt; EOF zend_extension = ioncube_loader_lin_8.1.so EOF 将ioncube_loader模块接入php-fpm和php-cli并重启php8.1-fpm\nln -s /etc/php/8.1/mods-available/ioncube.ini /etc/php/8.1/fpm/conf.d/01-ioncube.ini \u0026amp;\u0026amp; \\ ln -s /etc/php/8.1/mods-available/ioncube.ini /etc/php/8.1/cli/conf.d/01-ioncube.ini \u0026amp;\u0026amp; \\ systemctl restart php8.1-fpm.service 检查ioncube_loader模块是否生效\nphp -v 终端输出信息中包含with the ionCube PHP Loader v12.0.2, Copyright (c) 2002-2022, by ionCube Ltd.说明ionCube模块安装成功\nPHP 8.1.12 (cli) (built: Oct 28 2022 17:39:57) (NTS) Copyright (c) The PHP Group Zend Engine v4.1.12, Copyright (c) Zend Technologies with the ionCube PHP Loader v12.0.2, Copyright (c) 2002-2022, by ionCube Ltd. with Zend OPcache v8.1.12, Copyright (c), by Zend Technologies 删除临时文件\nrm -rf ioncube ioncube_loaders_lin_x86-64.zip 如果php安装出现问题 通过如下命令查找到nginx之后，查看报错日志\nfind / -name nginx.conf 安装MySQL 使用Ubuntu自带的软件源进行安装，本例安装mysql8.0\napt install -y mysql-server-8.0 -y 登录mysql控制台，密码默认为空\nmysql -uroot -p 设置root用户密码，本文以设置root用户密码123456为例\nALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;123456\u0026#39;; 允许root远程登录\nuse mysql //查看 select host,user from user where user=\u0026#39;root\u0026#39;; //设置允许任何IP登录 update user set host=\u0026#39;%\u0026#39; where user=\u0026#39;root\u0026#39; and host=\u0026#39;localhost\u0026#39;; //刷新权限 flush privileges; 原因：\nmysql配置问题：/etc/mysql/mysql.conf.d/mysqld.cnf中，查看查看 bind-address ，如果是127.0.0.1，则连接不上，修改为0.0.0.0。 阿里云服务器的控制器配置安全组规则：点击云服务器ESC-\u0026gt;网络和安全-\u0026gt;安全组；进入点击最后的配置规则，然后看没有3306端口，添加安全组规则（使用快速添加 3306端口即可） 参考 lnmp环境搭建_云服务器 ECS(ECS)-阿里云帮助中心 (aliyun.com) Linux服务器连接不上3306端口，解决_mgr database ip:127.0.0.1 port:3306 is disconnecte-CSDN博客\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/linux/ubuntu22-%E6%90%AD%E5%BB%BAlnmp%E7%8E%AF%E5%A2%83/","summary":"本文介绍Ubuntu 22.04手动搭建LNMP环境并做基础配置。nginx和php使用Ondřej Surý的ppa源进行安装和升级，mysq","title":"ubuntu22 搭建LNMP环境"},{"content":"Mysql中组合索引排序问题 如果我们建立单列索引（A），实际上相当于在（A，ID）上建立了索引，其中ID为主键。这中情况下对于 where A=xx order by ID的查询是非常有帮助的。但是如果我们建立了复合索引（A,B）,那么就相当于在(A,B,ID)上建立了索引，那么对于where A=xx order by ID这样的查询，就使用不到索引扫描排序，只能用filesort排序(using filesort)了。\n字符条件强制要求必须使用字符类型参数匹配 背景 create table user ( user_id bigint auto_increment comment \u0026#39;主键\u0026#39; primary key, source_key varchar(30) not null comment \u0026#39;结算事务编号\u0026#39;, tenant_id bigint default 0 not null , constraint user_u1 unique (tenant_id, source_key) ) select * from user where tenant_id = 82058 and source_key = 470888; -- 只有租户id字段索引生效 select * from user where tenant_id = 82058 and source_key = \u0026#39;470888\u0026#39;; -- tenant_id和source_key字段索引均生效 select * from user where user_id = 118099017;-- settle_id字段索引生效 select * from user where user_id = \u0026#39;118099017\u0026#39;; -- settle_id字段索引生效 总结 mysql查询时，针对字段索引命中场景，想要索引生效，查询条件中字符条件不可以使用Long类型参数进行匹配命中索引，Long类型条件可以使用字符类型参数进行匹配命中索引 字符条件强制要求必须使用字符类型参数匹配\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9F%A5%E8%AF%86%E7%82%B9/","summary":"Mysql中组合索引排序问题 如果我们建立单列索引（A），实际上相当于在（A，ID）上建立了索引，其中ID为主键。这中情况下对于 where A=xx order by ID的","title":"Mysql 性能优化知识点"},{"content":"简单来说是一种对象锁，锁的是对象，而不是引用\n32位对象头mark work分布： ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/synchronized-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/","summary":"简单来说是一种对象锁，锁的是对象，而不是引用 32位对象头mark work分布：","title":"synchronized 实现原理"},{"content":"\tpublic static void main(String[] args) { ConcurrentHashMap\u0026lt;String, Integer\u0026gt; map = new ConcurrentHashMap\u0026lt;\u0026gt;(16); map.computeIfAbsent( \u0026#34;AaAa\u0026#34;, key -\u0026gt; { return map.computeIfAbsent( \u0026#34;BBBB\u0026#34;, key2 -\u0026gt; 42); } ); System.out.println(\u0026#34;程序完成\u0026#34;); } 执行以上代码，程序会进入死循环状态，导致CPU使用率暴涨。\nbug原因： 因为\u0026quot;AaAa\u0026quot;和“BBBB”的hash值相同，会定位到用一个bucket中，这样就形成了CAS嵌套，产生死循环问题。具体的可以看源码分析。\n解决： 禁止在向ConcurrentHashMap中嵌套执行computeIfAbsent/putIfAbsent操作。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/jdk8-concurrenthashmap%E7%9A%84%E6%AD%BB%E5%BE%AA%E7%8E%AFbug/","summary":"public static void main(String[] args) { ConcurrentHashMap\u0026lt;String, Integer\u0026gt; map = new ConcurrentHashMap\u0026lt;\u0026gt;(16); map.computeIfAbsent( \u0026#34;AaAa\u0026#34;, key -\u0026gt; { return map.computeIfAbsent( \u0026#34;BBBB\u0026#34;, key2 -\u0026gt; 42); } ); System.out.println(\u0026#34;程序完成\u0026#34;); } 执行以上代码，程序","title":"Jdk8 ConcurrentHashMap的死循环bug"},{"content":"什么是BitMap BitMap算法的核心思想在于用bit数组记录0/1两种状态，然后再将具体数据映射到这个比特数组的具体位置，这个比特位表示数据存在或者数据不存在\n位图的实现 目前主要可以使用JDK中的BitSet Google开源的EWAHCompressedBitmap\n位图使用案例 给定10亿正数进行，没排过序的，然后再给一个数，如果快速判断是否在这10亿数据里面 解法：通过bitMap映射判断是否存在值 使用位图法进行元素不重复的正整形数组排序 解法，存入bitMap后，从小打到去除存在1的值 在2.5亿个整数中找出不重复的正整数，注，内存不足以容纳这2.5亿个整数 采用2-bitMap（每个数分配2bit，00表示存在，01表示出现1次，10表示多次，11无意义） 采用两个bitmap，第一个bitmap标记是否第一次存在，第二个bitmap标记是否存在多次，如果只在第一个bitmap则表示存在1次，两个bitmap都存在则表示多次，两个bitmap都没有则表示没有值 在系统中给多名用户打多个标记，在拉取数据的时候可以通过这个标记直接获取结果，比如给三个人A、B、C分别标记程序员，产品经理和测试，那么在设计时就可以使用标记直接过去对应标记下的所有人 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E7%AE%97%E6%B3%95/%E4%BD%8D%E5%9B%BEbitmap/","summary":"什么是BitMap BitMap算法的核心思想在于用bit数组记录0/1两种状态，然后再将具体数据映射到这个比特数组的具体位置，这个比特位表示","title":"位图BitMap"},{"content":"什么是布隆过滤器 在实际业务场景中，存在网页 URL 去重、垃圾邮件识别、大集合中重复元素的判断和缓存穿透等问题。而布隆过滤器就主要是用于检索一个元素是否在一个集合中。它的优点是空间效率和查询效率比较高，缺点是删除困难和有一定的误判率。\n算法思想 通过n个hash算法对输入值分别进行hash计算 根据hash值来标记[[位图BitMap]]中的位置，比如hash值为5，则[[位图BitMap]]中index=5的值改为1 根据1可知，如果n=3，则会进行3次hash，对BitMap三个位置的值修改为1 对于输入的值，如果该元素任意一个hash结果在bitMap中的值为0，则表示该值在布隆过滤器中肯定不存在，只有所有hash结果在bitMap中均存在，才能表示该值在布隆过滤器中可能存在（由于hash冲突，导致不同的值，三个不同hash函数的结果依旧冲突） 算法实现 Google开源guaua实现 Redission实现 问题案例 布隆过滤器很重要的一个使用场景就是[[缓存穿透，缓存击穿和缓存雪崩的区别以及解决方案]]\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E7%AE%97%E6%B3%95/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","summary":"什么是布隆过滤器 在实际业务场景中，存在网页 URL 去重、垃圾邮件识别、大集合中重复元素的判断和缓存穿透等问题。而布隆过滤器就主要是用于检索一个元素","title":"布隆过滤器"},{"content":" 把系统当作故事来写\n有意义的命名 尽量避免误导，即使用类似命名表达完全不一样的意思。避免双关语，即同一个名称表达两种意思。 不需要使用a，the等前缀，使用单复数区分即可，对应数据结构使用数据结构后缀，比如List-\u0026gt;UserList 常量优于魔法值 添加有意义的语境，通过语境帮助解释功能作用；不要添加没用的语境，短名称足够清楚就可以了。 函数 函数内容尽可能短，一个函数完成一个功能 函数名尽可能描述清楚所完成的功能 函数入参越少越好 不要使用标记参数，比如向函数中传入布尔值，Assert() 【动词+名词】(名词)比【动词】(名称)更好理解 函数不要做多余的事情，避免产生副作用 函数要么做什么事，要么回答什么事，但二者不可兼得 编写函数初稿可以粗陋无序，冗长而复杂。可以通过分解函数，修改名称，消除重复，重新组装函数进行优化，并配合单元测试，确保程序的正确性。 永不被调用的方法应该丢弃。别害怕删除函数。 注释 对比注释，用代码来阐述系统才是更正确的事，因为程序员总是在维护代码，却不会同步维护注释。一些老的、坏的注释反而会误导程序员。 TODO注释是一种程序员认为要做，但是目前因为某些原因还没有做到的事情，但他们不是系统中留下糟糕的代码的借口。需要定期查看并清理TODO注释。 注释可以放大某些看起来不合理代码的重要性 公共api中的javadoc十分重要，但是他们也可能会提供错误信息，误导程序员。代码更新时，同步更新javadoc十分重要。 在当前VCS(版本控制系统)中，注释归属和署名的注释是没有必要的，因为VCS会记住所有改动。 直接把代码注释掉是很糟糕的做法，仔细思考被注释的代码，为什么要注释掉？他们重要吗？是为了给未来的修改做提示吗？或者只是某人多年以前懒得清理的过时代码？如果代码可以被注释掉，那么他就可以被删除掉，在VCS中，他们丢不了。 不要使用HTML注释，如果注释将由工具（比如javaDoc）抽取出来，呈现到网页上，那么应该有该工具而不是程序员负责加上合适的HTML标签。 尽可能避免使用注释，好的注释应该可以帮助其他人更好地理解系统，提高其他人读系统的时间，而不是花费更多的时间。糟糕的注释示例\n格式 完整逻辑之间的空白行可以提高可读性。 关系紧密的代码应该在垂直距离上靠近 按照函数的前后调用逻辑自上向下编写函数 水平方向上的代码紧密代码逻辑关联性强，而空格代表互相隔离的逻辑 团队规则：遵循团队规则，绝对不要用各种不同的风格来编写源代码 对象与数据结构 得墨忒耳律：模块不应了解他所操作对象得内部情形。类C的方法f只应该调用一下对象的方法：C；由f创造的对象；作为参数传递给f的对象；由C的实体变量持有的对象。 小结：对象暴露行为，隐藏数据。数据结构暴露数据，没有明显的行为。 异常处理 使用异常而不是返回码 在大型系统的调用层级中，最底层函数添加throws时，所有上层函数都需要添加控制异常。不推荐！ 不返回null，避免参数传入null 边界 Map有着广阔的接口和丰富的功能，十分灵活，但是这种灵活也是要付出代价的，过多的暴露细节，可以考虑对Map接口进行隐藏，比如\nclass Sensors{ private Map sensors = new HashMap(); public Sensor getById(String id){ returen (Sensor)sensors.get(id); } } 使用adapter模式转换接口，也可以清晰的确定边界\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/clean-code/","summary":"把系统当作故事来写 有意义的命名 尽量避免误导，即使用类似命名表达完全不一样的意思。避免双关语，即同一个名称表达两种意思。 不需要使用a，the等","title":"Clean Code"},{"content":"DDD领域驱动模型是当前业内通用的一套软件设计思路，也是目前我所在公司的软件设计方案。 首先介绍一下DDD领域驱动设计出现的背景，在现代化公司的模式下，现代化软件系统也来越大，业务场景越来越复杂的情况下，而公司中的人员变更也十分频繁，那么怎么设计一套高内聚、低耦合且能够将大的业务场景拆分更小的业务场景技术方案就变得十分重要，DDD领域驱动设计模型就随之诞生了。DDD的核心思想是业务和技术相结合的一种过程，即强调业务的理解，又强调应用领域建模方法的使用。 DDD的核心思想就是明确面向对象的范围以及范围内\nluolin1024/DDD: DDD领域模型设计实现 (github.com)\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/ddd%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E6%A8%A1%E5%9E%8B%E8%90%BD%E5%9C%B0/","summary":"DDD领域驱动模型是当前业内通用的一套软件设计思路，也是目前我所在公司的软件设计方案。 首先介绍一下DDD领域驱动设计出现的背景，在现代化公司","title":"DDD领域驱动模型落地"},{"content":" 本文目的：记录如何在eu.org申请免费域名\n域名官网：https://nic.eu.org/\n注册账号 注册链接：https://nic.eu.org/arf/en/contact/create/\n注册之前先看一下他们的Policy：https://nic.eu.org/policy.html\n注册页面如下所示：\n注意，这些信息可能有人工审核，因此不要填得太随便了。\nName：填英文，建议填人名而不是ID。 E-mail：填写一个常用邮箱。之后接收申请通知就是用这个邮箱。首选的还是gmail和outlook，我填的是163，实测也能用。qq还是尽量避免吧。 然后是5行地址，填英文。不需要全填，可按照从小地址到大地址的顺序填入。地址应该不太重要，但是也不要填一看就有问题的地址。 Country，建议如实选择。China是没问题的，不影响申请。 Phone和Fax，都可以不填。 建议勾选Private选项，否则你上面填写的信息能够被WHOIS查到。\n勾选 accept the domain policy，输两遍密码，然后点 Create。\n随后，会有一封主题为“new EU.org contact XXXX-FREE”的邮件送到你填入的邮箱中，其正文大致如下：\nHello,\nYour contact record has been successfully created with the following\ndata. You still need to activate it, by going to the following page:\nhttps://nic.eu.org/arf/en/contact/validate/xxxxx/xxxxxx\nperson: [你填的名字]\nnic-hdl: [以FREE结尾的、分配给你的用户名，需要记一下，之后就用这个登陆]\naddress: [你填入的地址，下同]\naddress: xxxx\naddress: xxxx\naddress: China\ne-mail: [你填的邮箱]\nchanged: [时间]\nBest Regards,\nThe EU.org team\n点击邮件中的链接来确认。确认完毕后使用分配给你的用户名和刚刚填入的密码来登录。\n申请新域名 你的主页大致是这个样子： 上面被黑色掩盖的区域是你的用户名，点击“New Domain”按钮，申请一个新域名。\n在“Complete domain name”栏填入你要申请的完整域名，需要带有eu.org后缀。如example.eu.org。 你可以直接申请eu.org域名，也可以申请一些子域，如example.cn.eu.org（表示中国）。完整的列表可以看这里。 Organization栏，是你先前注册时就填好的，一般不动就行。 Administrative contact，域名的管理联系人，是自己，且申请时不可更改，申请成功后可以转让给其他用户。 Technical contact，域名的技术联系人，默认是自己，可以填入他人的ID，也可以新注册一个账户。一般也是不动的。 域名服务器。eu.org组织不提供DNS服务，因此你需要选择别家。需要简单验证你提供的DNS服务是否可用。可以选择不同的验证级别。\n这部分是eu.org域名申请的最关键环节，一般的不通过风险都是这里产生的。我这里以DNSPod为例说明操作过程。\n先在这个申请页上点选第一个选项（Check for correctness of server names）。这三个选项从前到后，验证的内容越来越多，第一个是最简单的。DNSPod会在SOA验证那步失败，因此我们不做SOA验证就可以了。实测选择第一个选项是不会影响审核的。\n然后登陆DNSPod，转到控制台“我的域名”：https://console.dnspod.cn/dns/list\n点击“添加域名”。\n输入你要申请的eu.org域名，然后点“验证”。一般来说，一个未被申请的eu.org域名是没有任何解析记录的，如果你输入的域名搜索到了解析记录，那么可能是该域名被人申请过了。如果没有解析记录，点击下一步即可。\n这里会出现一些失败信息，没有关系。将给出的两个DNS服务器地址复制，然后回到eu.org申请页，分别粘贴在“Name1”和“Name2”栏中。其他Name栏和所有的IP栏都留空即可。记得点选第一个选项。 然后点Submit。\neu.org网站会验证给出的DNS服务器地址是否正常指向IP，如果没问题，就将你的请求保存下来等待人工审核了。\n---- Servers and domain names check Getting IP for FAITHE.DNSPOD.NET: 117.89.178.173 129.211.176.209 120.241.130.98 112.80.181.45 1.12.0.4 Getting IP for FAITHE.DNSPOD.NET: 2402:4e00:1430:1102:0:9136:2b30:e554 Getting IP for MOCCASIN.DNSPOD.NET: 129.211.176.239 36.155.149.176 112.80.181.111 117.89.178.184 1.12.0.1 Getting IP for MOCCASIN.DNSPOD.NET: 2402:4e00:111:fff::c No error, storing for validation... Saved as request 20240202174323-arf-27446 Done 看到“Done”，表示申请完成，然后等邮件通知就可以了。\n申请通过 等待的时间很随机，短的可能有数小时，长的可能有半年。我申请的第一个域名等了一个月，第二个域名等了40天。\n会有一封主题为“request [[申请时间]-arf-xxxxx] (domain [你申请的域名]) accepted”的邮件送到你的注册邮箱，其正文大致如下：\nHello,\nYour request [[申请时间]-arf-xxxxx] for creation of domain [你申请的域名]\nhas been accepted.\nThe following records will be inserted in the zone file:\n[你填入的DNS服务器地址]\nThe following records will be inserted in the WHOIS base:\nObject created:\ndomain: [你申请的域名]\naddress: [你注册时填写的Name]\naddress: [你注册时填写的地址，下同]\naddress: xxx\naddress: xxx\naddress: China\nchanged: [通过审核的时间]\ntech-c: [你申请域名时的技术联系人，默认是自己]\nadmin-c: [你申请域名时的管理联系人，是自己]\nDomains: 1\nPersons: 0\nPlease allow about half a day for propagation.\nBest Regards,\nThe EU.org team\n此时DNSPod那边可能已经过期很久，以至于把你申请时填的域名给删了。没有关系，进入 https://nic.eu.org/arf/en/ ，申请通过的域名会出现在列表中，点击域名进入设置，再点“Nameservers”按钮，可以重新编辑DNS服务器。按照之前的方法去DNSPod重复一遍即可。你还可以在设置页变更管理联系人和技术联系人。你也可以删除这个域名，这样该域名就重新进入eu.org的公共空间了。\n之后，你就可以在DNSPod上为域名添加解析记录了。\n新增白嫖域名 目前eu.org申请之后，审批时间很长（我上一个已经申请了半年多了，还是没有响应），建议可以按照下面的链接申请eu.org的域名： 又一个永久免费的域名可以撸，可托管至CloudFlare - GXNAS博客\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/free-domain-name/","summary":"本文目的：记录如何在eu.org申请免费域名 域名官网：https://nic.eu.org/ 注册账号 注册链接：https://nic.eu.","title":"eu.org申请免费域名"},{"content":"Excel使用\u0026amp;连接符批量 背景：很多时候需要修复数据，同时数据是通过数据库管理工具导出，因此固定了A列和B列作为参数，在C列通过公式进行SQL拼接\n示例输入：\n=\u0026#34;insert into ssta_line_limit(tenant_id, settle_config_id, document_type, enable_flag) value(\u0026#34;\u0026amp;B2\u0026amp;\u0026#34;, \u0026#34;\u0026amp;A2\u0026amp;\u0026#34;, \u0026#39;INVOICE\u0026#39;, 0);\u0026#34; 实现效果： ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E5%B7%A5%E5%85%B7/excel-use/","summary":"Excel使用\u0026amp;连接符批量 背景：很多时候需要修复数据，同时数据是通过数据库管理工具导出，因此固定了A列和B列作为参数，在C列通过公式","title":"Excel使用"},{"content":"feign、ribbon、hystrix三者之间的关系 如果微服务项目加上了spring-cloud-starter-netflix-hystrix依赖，那么，feign会通过代理模式， 自动将所有的方法用 hystrix 进行包装。在Spring Cloud微服务体系下，微服务之间的互相调用可以通过Feign进行声明式调用，在这个服务调用过程中Feign会通过Ribbon从服务注册中心获取目标微服务的服务器地址列表，之后在网络请求的过程中Ribbon就会将请求以负载均衡的方式打到微服务的不同实例上，从而实现Spring Cloud微服务架构中最为关键的功能即服务发现及客户端负载均衡调用。另一方面微服务在互相调用的过程中，为了防止某个微服务的故障消耗掉整个系统所有微服务的连接资源，所以在实施微服务调用的过程中我们会要求在调用方实施针对被调用微服务的熔断逻辑。而要实现这个逻辑场景在Spring Cloud微服务框架下我们是通过Hystrix这个框架来实现的。调用方会针对被调用微服务设置调用超时时间，一旦超时就会进入熔断逻辑，而这个故障指标信息也会返回给Hystrix组件，Hystrix组件会根据熔断情况判断被调微服务的故障情况从而打开熔断器，之后所有针对该微服务的请求就会直接进入熔断逻辑，直到被调微服务故障恢复，Hystrix断路器关闭为止。三者之间的关系图，大致如下： 如上图所示，在Spring Cloud中使用Feign进行微服务调用分为两层：Hystrix的调用和Ribbon的调用，Feign自身的配置会被覆盖。而如果开启了Hystrix，那么Ribbon的超时时间配置与Hystrix的超时时间配置则存在依赖关系，因为涉及到Ribbon的重试机制，所以一般情况下都是Ribbon的超时时间小于Hystrix的超时时间，否则会出现以下错误：\nWARN o.s.c.n.z.f.r.s.AbstractRibbonCommand - The Hystrix timeout of 10000ms for the command operation is set lower than the combination of the Ribbon read and connect timeout, 24000ms. 超时时间配置 Ribbon和Hystrix的超时时间配置的关系具体如下：\nHystrix的超时时间=Ribbon的重试次数(包含首次) * (ribbon.ReadTimeout + ribbon.ConnectTimeout)\nRibbon的重试次数的计算方式为:\nRibbon重试次数(包含首次)= 1 + ribbon.MaxAutoRetries + ribbon.MaxAutoRetriesNextServer + (ribbon.MaxAutoRetries * ribbon.MaxAutoRetriesNextServer)\n以上图中的Ribbon配置为例子，Ribbon的重试次数=1+(1+1+1)=4，所以Hystrix的超时配置应该\u0026gt;=4*(3000+3000)=24000毫秒。在Ribbon超时但Hystrix没有超时的情况下，Ribbon便会采取重试机制；而重试期间如果时间超过了Hystrix的超时配置则会立即被熔断（fallback）。如果不配置Ribbon的重试次数，则Ribbon默认会重试一次，加上第一次调用Ribbon，总的的重试次数为2次，以上述配置参数为例，Hystrix超时时间配置为2*6000=12000，由于很多情况下，大家一般不会主动配置Ribbon的重试次数，所以这里需要注意下！强调下，以上超时配置的值只是示范，超时配置有点大不太合适实际的线上场景，根据实际情况设置即可！说明下，如果不启用Hystrix，Feign的超时时间则是Ribbon的超时时间，Feign自身的配置也会被覆盖。\n三者的配置 feign github地址：https://github.com/OpenFeign/feign\nfeign: #替换掉JDK默认HttpURLConnection实现的 Http Client httpclient: enabled: true hystrix: enabled: true client: config: default: #连接超时时间 connectTimeout: 5000 #读取超时时间 readTimeout: 5000 hystrix GitHub地址：https://github.com/Netflix/hystrix\nhystrix: propagate: request-attribute: enabled: true command: #全局默认配置 default: #线程隔离相关 execution: timeout: #是否给方法执行设置超时时间，默认为true。一般我们不要改。 enabled: true isolation: #配置请求隔离的方式，这里是默认的线程池方式。还有一种信号量的方式 SEMAPHORE，使用比较少。 strategy: THREAD thread: #方式执行的超时时间，默认为1000毫秒，在实际场景中需要根据情况设置 timeoutInMilliseconds: 10000 #发生超时时是否中断方法的执行，默认值为true。不要改。 interruptOnTimeout: true #是否在方法执行被取消时中断方法，默认值为false。没有实际意义，默认就好！ interruptOnCancel: false circuitBreaker: #熔断器相关配置 enabled: true #是否启动熔断器，默认为true，false表示不要引入Hystrix。 requestVolumeThreshold: 20 #启用熔断器功能窗口时间内的最小请求数，假设我们设置的窗口时间为10秒， sleepWindowInMilliseconds: 5000 #所以此配置的作用是指定熔断器打开后多长时间内允许一次请求尝试执行，官方默认配置为5秒。 errorThresholdPercentage: 50 #窗口时间内超过50%的请求失败后就会打开熔断器将后续请求快速失败掉,默认配置为50 ribbon github地址：https://github.com/Netflix/ribbon\nribbon: eager-load: enabled: true #说明：同一台实例的最大自动重试次数，默认为1次，不包括首次 MaxAutoRetries: 1 #说明：要重试的下一个实例的最大数量，默认为1，不包括第一次被调用的实例 MaxAutoRetriesNextServer: 1 #说明：是否所有的操作都重试，默认为true OkToRetryOnAllOperations: true #说明：从注册中心刷新服务器列表信息的时间间隔，默认为2000毫秒，即2秒 ServerListRefreshInterval: 2000 #说明：使用Apache HttpClient连接超时时间，单位为毫秒 ConnectTimeout: 3000 #说明：使用Apache HttpClient读取的超时时间，单位为毫秒 ReadTimeout: 3000 总结 如何配置好hystrix和ribbon的超时时间呢？因为是feign的请求：其实就是hystrix+ribbon，hystrix在最外层，然后才到ribbon，最后是http请求；所以说，hysrix的熔断时间必须要大于ribbon的（ConnectTimeOut+ReadTime）,而如果Ribbon开启了重试机制的话，还需要乘以对应的重试次数，保证ribbon里的请求还没有结束，hystrix的熔断时间不会超时。另外，对于springcloud项目，添加了openfeign依赖之后，是没有hystrix的依赖的，还需要自己手动添加一下：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-hystrix\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/feignribbonhystrix%E5%88%86%E6%9E%90/","summary":"feign、ribbon、hystrix三者之间的关系 如果微服务项目加上了spring-cloud-starter-netflix-hyst","title":"feign、ribbon、hystrix分析"},{"content":"报错405 这两天遇到了一个FeignClient和GetMapping组合报错405请求方法错误，在写代码的时候，遇到一个情况，在使用FeignClient调用服务，因为是获得数据的接口，并且参数有很多，所以就直接使用的实体类，但是却总是报错，报的还是很奇怪的405，请求方法错误，被调用服务抛错具体内容如下：\n[org.springframework.web.HttpRequestMethodNotSupportedException: Request method \u0026lsquo;POST\u0026rsquo; not supported]\n通过全局异常捕捉时，发现在服务端显示的是调用源POST调用，可是我明明使用FeignClient的GetMapping发起的。(因为想着在SpringMVC可以直接接收实体对象，并且@RequestParam并不能直接作用于一个实体对象上，所以就直接如下写了FeignClient) 调用方代码如下：\n@FeignClient(value = \u0026#34;service-hi\u0026#34;, fallback = HelloServiceImpl.class) public interface HelloService { @GetMapping(\u0026#34;/{organizationId}/hi\u0026#34;) List\u0026lt;String\u0026gt; sayHiFromClientOne(@PathVariable(\u0026#34;organizationId\u0026#34;) Long tenantId, BillDimensionDtlDTO billDimensionDtlDTO); } 被调用服务接口如下，\n@RestController(\u0026#34;/{organizationId}\u0026#34;) public class HelloController { @Value(\u0026#34;${server.port}\u0026#34;) String port; @RequestMapping(\u0026#34;/hi\u0026#34;) public ResponseEntity\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; home(@PathVariable(\u0026#34;organizationId\u0026#34;) Long tenantId, BillDimensionDtlDTO billDimensionDtlDTO) { System.out.println(billDimensionDtlDTO); List\u0026lt;String\u0026gt; strings = new ArrayList\u0026lt;\u0026gt;(); strings.add(\u0026#34;a\u0026#34;); strings.add(\u0026#34;b\u0026#34;); strings.add(tenantId.toString()); return ResponseEntity.ok(strings); } } 事实上，通过分析造成如此的原因，我也整理了一下FeignClient的调用流程。这里先给出结论，为什么FeignClient发起的GetMapping会报405，是因为FeignClient最后是用HttpURLConnectiion发起的网络连接，在发起的过程中，Connection会判断其自身的body是否为空，如果不为空，则将 GET Method 转换为 POST Method。这也容易理解，因为body数据只能放在RquestBody内以流的形式传输，而param数据则在Http协议中直接放在URL上进行传输和获取，所以如果有body数据，理应转为POST请求，这也每种数据都能正确的传输到网络接口。但是，我们的服务端生产者是Get请求的接口，这样直接就会导致请求类型不一致报405，而为什么会造成转换，是因为body数据不为空，但是为什么body会有值，这要从初始化FeignClient和FeignClient的规则说起。在启动过程中，就将FeignClient注解的类进行动态代理，且初始化了代理类。\n如果有@RequestParam(“xx”)注解，则会将参数作为key，放入RequestTemplate.Factory中，由urlIndex来指明数组索引，并且在解析的时候，根据每个key从arg数组获取到具体值，拼接在url后面； 如果没有任何注解，或者用@RequestBody贴在参数前面，则初始化RequestTemplate.Factory的时候，bodyIndex会维护参数索引，并且bodyType这个参数会携带参数类型 所以我们现在的场景是没有加任何注解，FeignClient会把数据放入body中，那么怎么解决呢，可以直接加@RequestParam注解吗，如改写成下面这样？答案是否定的，因为@RequestParam只能注解单个基本数据类型，上面的写法将会让url的dto的值是dto.toString()。我们可以将dto的数据全部拿出来，一个一个写在参数列表上，并都贴上@RequestParam注解，但是这样写法无异于让参数列表变的很长。为此，如果我们要传递这种封装了多个数据的实体数据，又不想一个一个拿出来写在参数列表，我们在FeignClient中就要打破RESTful规范，使用POST来发起请求调用，同时服务端也使用POST来接收。(按照上面的GET会转POST的理论，如果我们FeignClient调用端写的是GetMapping，参数不贴注解，只要服务端的生产者是POST请求加@RequestBody接收，那么也能正确接收并响应数据，经过实验发现确实如此)\n405报错总结 对于get请求，路径上的参数必须使用@RequestParam注解或者@PathVariable 注解，否则将会报错405；对于Post请求，加上@RequestBody 就好。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/feign%E8%B0%83%E7%94%A8%E6%8E%A5%E5%8F%A3%E6%8A%A5%E9%94%99%E6%83%85%E5%86%B5%E5%88%86%E6%9E%90/","summary":"报错405 这两天遇到了一个FeignClient和GetMapping组合报错405请求方法错误，在写代码的时候，遇到一个情况，在使用Fei","title":"Feign调用接口报错情况分析"},{"content":"关于git的一些介绍以及大部分用法，可以参考官方文档,本文只记录一些常用操作和一些比较难的操作。\ngit fetch和git pull对比 先用一张图来理一下git fetch和git pull的概念：\ngit fetch是将远程主机的最新内容拉到本地，用户在检查了以后决定是否合并到工作本机分支中。\ngit fetch origin查找 “origin” 是哪一个服务器,从中抓取本地没有的数据，\ngit pull则是将远程主机的最新内容拉下来后直接合并，即：git pull = git fetch + git merge，这样可能会产生冲突，需要手动解决。\ngit fetch用法\ngit fetch 命令：\ngit fetch \u0026lt;远程主机名\u0026gt; //这个命令将某个远程主机的更新全部取回本地, 并且更新本地数据库，移动 origin/所有分支 指针指向新的、更新后的位置。 git fetch (后面不加参数) // 这个命令与上面的命令相似，远程主机用的默认远程主机 如果只想取回特定分支的更新，可以指定分支名：\ngit fetch \u0026lt;远程主机名\u0026gt; \u0026lt;分支名\u0026gt; //注意之间有空格 最常见的命令如取回origin 主机的master 分支：\ngit fetch origin master 取回更新后，会返回一个FETCH_HEAD ，指的是某个branch在服务器上的最新状态，我们可以在本地通过它查看刚取回的更新信息：\ngit log -p FETCH_HEAD git pull 用法\n前面提到，git pull 的过程可以理解为：\ngit fetch origin master //从远程主机的master分支拉取最新内容 git merge FETCH_HEAD //将拉取下来的最新内容合并到当前所在的分支中 即将远程主机的某个分支的更新取回，并与本地指定的分支合并，完整格式可表示为：\ngit pull \u0026lt;远程主机名\u0026gt; \u0026lt;远程分支名\u0026gt;:\u0026lt;本地分支名\u0026gt; 如果远程分支是与当前分支合并，则冒号后面的部分可以省略：\ngit pull origin dev git push git push的一般形式为 git push \u0026lt;远程主机名\u0026gt; \u0026lt;本地分支名\u0026gt; \u0026lt;远程分支名\u0026gt; ，例如 git push origin master，即是将本地的master分支推送到远程主机origin上的对应master分支， origin 是远程主机名,第一个master是本地分支名，第二个master是远程分支名。\n如果远程分支被省略，如下则表示将本地分支推送到与之存在追踪关系的远程分支（通常两者同名），如果该远程分支不存在，则会被新建\ngit push origin master 如果省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支，等同于 git push origin --delete master\ngit push origin:master 如果当前分支与远程分支存在追踪关系，则本地分支和远程分支都可以省略，将当前分支推送到origin主机的对应分支\ngit push origin 如果当前分支只有一个远程分支，那么主机名都可以省略，形如 git push，可以使用git branch -r，查看远程的分支名\ngit push git push 的其他命令\ngit push -u origin master 如果当前分支与多个主机存在追踪关系，则可以使用 -u 参数指定一个默认主机，这样后面就可以不加任何参数使用git push，不带任何参数的git push，默认只推送当前分支，这叫做simple方式，还有一种matching方式，会推送所有有对应的远程分支的本地分支， Git 2.0之前默认使用matching，现在改为simple方式,如果想更改设置，可以使用git config命令。git config \u0026ndash;global push.default matching OR git config \u0026ndash;global push.default simple；可以使用git config -l 查看配置 git push --all origin 当遇到这种情况就是不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机，这时需要 -all 选项 git push --force origin git push的时候需要本地先git pull更新到跟服务器版本一致，如果本地版本库比远程服务器上的低，那么一般会提示你git pull更新，如果一定要提交，那么可以使用这个命令。 git push origin --tags //git push 的时候不会推送分支，如果一定要推送标签的话那么可以使用这个命令 常用分支操作 git 本地分支操作 git branch //查看本地所有分支 git branch -r //查看远程所有分支 git branch -a //查看本地和远程的所有分支 git branch \u0026lt;branchname\u0026gt; //新建分支 git branch -d \u0026lt;branchname\u0026gt; //删除本地分支 git branch -d -r \u0026lt;branchname\u0026gt; //删除远程分支，删除后还需推送到服务器 git push origin:\u0026lt;branchname\u0026gt; //删除后推送至服务器 git branch -m \u0026lt;oldbranch\u0026gt; \u0026lt;newbranch\u0026gt; //重命名本地分支 /** *重命名远程分支： *1、删除远程待修改分支 *2、push本地新分支到远程服务器 */ //git中一些选项解释: -d --delete：删除 -D --delete --force的快捷键 -f --force：强制 -m --move：移动或重命名 -M --move --force的快捷键 -r --remote：远程 -a --all：所有 git check -b \u0026lt;新分支名称\u0026gt; //新建分支并切换到新建分支 git branch -vv // 查看本地处于远程库中哪个 git 操作远程分支 把新建的本地分支push到远程服务器，远程分支与本地分支同名（当然可以随意起名）：git push origin \u0026lt;本地分支名\u0026gt;:\u0026lt;远程分支名\u0026gt;,删除远程已有分支：git push origin --delete dbg_lichen_star\n$ git branch -a * dev master remotes/origin/dev remotes/origin/master 推送到远程： $ git push origin dev:dev2 Total 0 (delta 0), reused 0 (delta 0) remote: remote: Create a pull request for \u0026#39;dev2\u0026#39; on GitHub by visiting: remote: https://github.com/runooboy/runooboy.github.io/pull/new/dev2 remote: To github.com:runooboy/runooboy.github.io.git * [new branch] dev -\u0026gt; dev2 结果： $ git branch -a * dev master remotes/origin/dev remotes/origin/dev2 remotes/origin/master 删除远程已有分支： $ git push origin --delete dev2 To github.com:runooboy/runooboy.github.io.git - [deleted] dev2 结果： $ git branch -a * dev master remotes/origin/dev remotes/origin/master git 推送个人远程服务器 1. 服务器操作 # root用户操作： adduser git su git 2. 本地操作 ssh-keygen -t rsa cat .ssh/id_rsa.pub 3. 服务器操作 cd .ssh vim authorized_keys # 将本地公钥保存进来 mkdir repository mkdir repository/hello.git cd repository/hello.git git --bare init # 一定要用这个，不然不让本地推送远程 git branch -m master # 设置分支 使用git init,本地推送时将会报错：\nremote: error: refusing to update checked out branch: refs/heads/master remote: error: By default, updating the current branch in a non-bare repository 没有设置分支，将会报错：\nerror: remote unpack failed: unable to create temporary object directory git stash暂存 git stash 保存当前工作进度，会把暂存区和工作区的改动保存起来。执行完这个命令后，在运行git status命令，就会发现当前是一个干净的工作区，没有任何改动。使用git stash save 'message...'可以添加一些注释。\ngit stash list 显示保存进度的列表。也就意味着，git stash命令可以多次执行。\ngit stash pop [–index] [stash_id] git stash pop 恢复最新的进度到工作区。git默认会把工作区和暂存区的改动都恢复到工作区。 git stash pop --index 恢复最新的进度到工作区和暂存区。（尝试将原来暂存区的改动还恢复到暂存区） git stash pop 'stash@{1}'恢复指定的进度到工作区。stash_id是通过git stash list命令得到的通过git stash pop命令恢复进度后，会删除当前进度。 git stash apply [–index] [stash_id] 除了不删除恢复的进度之外，其余和git stash pop 命令一样。\ngit stash drop [stash_id] 删除一个存储的进度。如果不指定stash_id，则默认删除最新的存储进度。\ngit stash clear 删除所有存储的进度。\n注意 git中两个不同分支同时修改了同一处（同一行）内容之后，只要两个分支修改后的内容一致，就不会产生冲突。 参考： 本地git仓库推送到服务器自建的git仓库实现目录文件同步教程_51CTO博客_git推送到远程仓库\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E5%B7%A5%E5%85%B7/git-operation-manual/","summary":"关于git的一些介绍以及大部分用法，可以参考官方文档,本文只记录一些常用操作和一些比较难的操作。 git fetch和git pull对比 先用一张图来","title":"Git操作手册"},{"content":"今天有一个任务：向数据库中添加百万条数据用来做测试，考虑到单线程插入数据可能要花很久的时间，于是想到了用线程池来进行插入操作，但是里面有个一个唯一性约束字段，然后在这个过程中遇到了好几个问题：\n一开始使用线程池的时候由于唯一性约束字段的存在，需要将一个公有变量变成私有变量（每个线程在执行过程中变量需要不被外界修改），但是线程池中的线程是通过实现Runnable接口方式创建的，那么类中的私有变量其实是公有变量。 了解到ThreadLocal的用法后，也踩了几次坑，这里总结一些ThreadLocal的用法：尽量使用private static声明ThreadLocal变量；出main线程外，只有在run()中才能调用到TheadLocal变量（run中调用的其他方法中也能调用到，一开始将其放在在MyThread类的构造方法中，一直有NPE报出），说明只有在run()中，这个线程才算真正有了自己的生命周期。 线程数和循环次数不要太狠，尤其是在添加了对象到List中的时候，很容易出现内存不足异常。 ThreadLocal变量在不需要当前存放的值的时候，必须使用remove方法清除，这点也是一个大坑，下面主要是介绍这个坑以及解决方法。 调用线程池的shutdown()方法意味着该线程池在线程池中的所有线程执行完毕后就“关机了”，将不再接受任何调用。 （1）在线程中执行添加一段连续的Integer到List中；（2）（1）中的Integer不能是重复的；（3）在main中向线程池中添加10条线程，并启动它们；（4）线程池中的每条线程循环执行10次；未使用remove()的代码（其实也就是我注释了remove）如下：\npublic class ThreadLocalTest { static Integer initNum = 1; //初始数据 static int step = 10; //步长 static int threads = 10; //线程数 private static ThreadLocal\u0026lt;Integer\u0026gt; threadLocal = new ThreadLocal\u0026lt;\u0026gt;(); public static void main(String[] args) { ThreadLocalTest threadLocalTest = new ThreadLocalTest(); ExecutorService executorService = Executors.newFixedThreadPool(threads); List\u0026lt;MyThread\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for(int i = 0; i \u0026lt; threads; i++) { list.add(threadLocalTest.new MyThread()); } for(int j = 0; j \u0026lt; 10; j++) { for (int i = 0; i \u0026lt; threads; i++) { executorService.execute(list.get(i)); } try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } } executorService.shutdown(); } class MyThread implements Runnable{ @Override public void run() { if(null == threadLocal.get()){ synchronized (MyThread.class){ threadLocal.set(initNum); initNum+=step; } } System.out.println(\u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026#34;+Thread.currentThread().getName()+\u0026#34;\u0026gt;\u0026gt; 开始\u0026#34;); List list = new ArrayList\u0026lt;Integer\u0026gt;(); for(int i = 0; i \u0026lt; step; i++) { int localNum = threadLocal.get(); list.add(localNum); threadLocal.set(++localNum); } // threadLocal.remove(); System.out.println(\u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026#34;+Thread.currentThread().getName()+\u0026#34;\u0026gt;\u0026gt; 完成！---- \u0026#34;+list.toString()); } } } 此时会出现如下结果： 根据上面的结果可以看出，这并不是我想要的结果，按照我的需要最后结果应该是1000，而此时只是到了200，而且其中有重复的数字。\n然后我感觉可能是我没有添加我注释的threadLocal.remove()，加上后，果然，结果如我所预料的： 最后根据上面代码的思路，只花了大概6-7分钟完成了对mysql数据库插入100W条数据操作，美滋滋~\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%BB%93%E5%90%88threadlocal%E7%9A%84%E7%94%A8%E6%B3%95%E5%AE%9E%E4%BE%8B/","summary":"今天有一个任务：向数据库中添加百万条数据用来做测试，考虑到单线程插入数据可能要花很久的时间，于是想到了用线程池来进行插入操作，但是里面有个一","title":"Java线程池结合ThreadLocal的用法实例"},{"content":" 本文主要是记录Linux下常用的命令\nLinux下查询当前端口占用 ∂ ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/linux/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95/","summary":"本文主要是记录Linux下常用的命令 Linux下查询当前端口占用 ∂","title":"Linux常用命令记录"},{"content":"序言 这是我第一次参加类似读书会的活动，整体体验非常愉快。能够与来自不同领域、充满想法的年轻人交流探讨，让我受益匪浅。这篇文章将记录本次读书会的核心内容，包括主题探讨、案例分析，以及我个人的收获与感悟。\n主题 本次读书会的主题围绕创业与副业展开，探讨如何通过不同方式提升个人价值，拓展资源，实现更好的商业变现。\n案例分析 在讨论过程中，大家分享了多个具有实际应用价值的案例，以下是几个典型的案例分析：\n商业街资源整合\n通过整合商业街的资源，如商铺、客户流量、供应链等，打造互惠互利的商业生态，实现更高的运营效率与收益。\n茶叶品牌与传统文化结合\n利用传统文化对品牌进行包装，通过讲述茶文化故事、结合书法、国画等文化元素，提高品牌附加值，增强市场竞争力。\n个人品牌打造：设计师与程序员的案例\n对于设计师或程序员等职业，通过提高个人品牌知名度，建立社交影响力，吸引更优质的客户资源，从而提升商业价值。\n读书会与书画圈层的高端社交价值\n通过举办读书会、书画活动等，吸引中高产阶级及行业精英，打造高价值社交圈层，进而实现商业化变现，如高端培训、文化交流等。\n保险销售的新思路\n传统的保险销售模式较为固化，而通过授课的方式为客户提供理财培训或方案指导，不仅能提升客户的信任度，还能拓展更多商业机会。\n个人收获 通过这次读书会，我深刻认识到个人价值的提升是关键。打造个人品牌、结识高价值人群，并有效整合这些资源，能够形成杠杆效应，从而创造更大的商业价值。这次经历不仅让我对创业和副业有了新的理解，也激发了我在个人成长方面的更多思考。\n总的来说，这次读书会让我受益良多，期待未来能有更多这样的机会，与更多志同道合的朋友一起成长、探索，共同创造更大的价值。\n","permalink":"https://luolin1024.github.io/2024/02/moment-reading-club-no.10/","summary":"序言 这是我第一次参加类似读书会的活动，整体体验非常愉快。能够与来自不同领域、充满想法的年轻人交流探讨，让我受益匪浅。这篇文章将记录本次读书会","title":"Moment读书会第10期"},{"content":"本期主题 本期读书会的主题与上一期Moment读书会第10期有所重叠，依然围绕创业相关内容展开深入探讨。\n主要收获 本次读书会带来了以下几点重要启发：\n职业咨询的高回报模式\n通过教授他人知识和经验，转变为职业咨询的方式，不仅可以帮助他人，也能够实现高额回报。\n量化模型与私募发展路径\n搭建量化模型可以成为个人成长的重要路径，进一步发展可以进入私募股权或私募基金领域，甚至可以通过吸引合伙人，为更多人提供专业服务。\n提升时间单位价值\n如何高效利用时间、优化资源配置，是决定个人和企业价值提升的关键问题。\n商业分析模型\n在商业分析方面，我们需要遵循以下四个核心步骤：\n抓住用户痛点：明确目标用户的核心需求和困境。\n瞄准用户人群：精准定位目标群体，提高营销和服务的针对性。\n提供对应的内容或价值：基于用户需求，提供优质内容或服务，增强用户粘性。\n提升内容价值：不断优化和升级内容，以更高的价值吸引用户，实现长期增长。\n本次读书会的讨论内容深入且富有启发性，为未来创业方向提供了新的思考角度。期待下一期的交流！\n","permalink":"https://luolin1024.github.io/2024/02/moment-reading-club-no.11/","summary":"本期主题 本期读书会的主题与上一期Moment读书会第10期有所重叠，依然围绕创业相关内容展开深入探讨。 主要收获 本次读书会带来了以下几点重要启","title":"Moment读书会第11期"},{"content":"MyBatis中的一对一，一对多，多对多关联映射查询 一对多（嵌套结果） 将结果嵌套，在collection标签中加入对应的行表列映射：\n\u0026lt;resultMap id=\u0026#34;BaseResultMap\u0026#34; type=\u0026#34;com.luolin.springssm.model.Student\u0026#34;\u0026gt; \u0026lt;!-- id 表示主键, column 表示数据库中表的column名称，jdbcType表示，property表示对应model中的实体类的属性 --\u0026gt; \u0026lt;id column=\u0026#34;s_id\u0026#34; jdbcType=\u0026#34;BIGINT\u0026#34; property=\u0026#34;sId\u0026#34;/\u0026gt; \u0026lt;result column=\u0026#34;s_name\u0026#34; jdbcType=\u0026#34;VARCHAR\u0026#34; property=\u0026#34;sName\u0026#34;/\u0026gt; \u0026lt;result column=\u0026#34;s_birth\u0026#34; jdbcType=\u0026#34;VARCHAR\u0026#34; property=\u0026#34;sBirth\u0026#34;/\u0026gt; \u0026lt;result column=\u0026#34;s_sex\u0026#34; jdbcType=\u0026#34;VARCHAR\u0026#34; property=\u0026#34;sSex\u0026#34;/\u0026gt; \u0026lt;!--使用collention来做到头行的效果--\u0026gt; \u0026lt;collection property=\u0026#34;sScore\u0026#34; ofType=\u0026#34;com.luolin.springssm.model.Score\u0026#34;\u0026gt; \u0026lt;id column=\u0026#34;c_id\u0026#34; jdbcType=\u0026#34;VARCHAR\u0026#34; property=\u0026#34;cId\u0026#34;/\u0026gt; \u0026lt;result column=\u0026#34;s_id\u0026#34; jdbcType=\u0026#34;VARCHAR\u0026#34; property=\u0026#34;sId\u0026#34;/\u0026gt; \u0026lt;result column=\u0026#34;s_score\u0026#34; jdbcType=\u0026#34;BIGINT\u0026#34; property=\u0026#34;sScore\u0026#34;/\u0026gt; \u0026lt;/collection\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;select id=\u0026#34;getAll\u0026#34; resultMap=\u0026#34;BaseResultMap\u0026#34; \u0026gt; select student.s_id, s_name, s_birth, s_sex \u0026lt;!-- 连接查询只要是在sql语句中加上join on的写法 --\u0026gt; FROM student left join score c on student.s_id = c.s_id \u0026lt;/select\u0026gt; 一对多（关联的嵌套查询，在collection中添加select属性）： 这种方式只是写法与上述不同，只要是利用了collection的select属性，select对应的是一个select标签的id，并将结果映射到一个resultMap上去，使用resultType可能会出现数据查找不到的结果，不知道为什么，在网上是看到有人写的是resultType，然后自己本地测试写着没有用。\n\u0026lt;resultMap id=\u0026#34;BaseResultMap\u0026#34; type=\u0026#34;com.luolin.springssm.model.Student\u0026#34;\u0026gt; \u0026lt;id column=\u0026#34;s_id\u0026#34; jdbcType=\u0026#34;VARCHAR\u0026#34; property=\u0026#34;sId\u0026#34;/\u0026gt; \u0026lt;result column=\u0026#34;s_name\u0026#34; jdbcType=\u0026#34;VARCHAR\u0026#34; property=\u0026#34;sName\u0026#34;/\u0026gt; \u0026lt;result column=\u0026#34;s_birth\u0026#34; jdbcType=\u0026#34;VARCHAR\u0026#34; property=\u0026#34;sBirth\u0026#34;/\u0026gt; \u0026lt;result column=\u0026#34;s_sex\u0026#34; jdbcType=\u0026#34;VARCHAR\u0026#34; property=\u0026#34;sSex\u0026#34;/\u0026gt; \u0026lt;collection property=\u0026#34;sScore\u0026#34; javaType=\u0026#34;list\u0026#34; column=\u0026#34;s_id\u0026#34; ofType=\u0026#34;com.luolin.springssm.model.Score\u0026#34; select=\u0026#34;queryScore\u0026#34;/\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;resultMap id=\u0026#34;ScoreResultMap\u0026#34; type=\u0026#34;com.luolin.springssm.model.Score\u0026#34;\u0026gt; \u0026lt;result column=\u0026#34;s_id\u0026#34; jdbcType=\u0026#34;VARCHAR\u0026#34; property=\u0026#34;sId\u0026#34;/\u0026gt; \u0026lt;result column=\u0026#34;c_id\u0026#34; jdbcType=\u0026#34;VARCHAR\u0026#34; property=\u0026#34;cId\u0026#34;/\u0026gt; \u0026lt;result column=\u0026#34;s_score\u0026#34; jdbcType=\u0026#34;BIGINT\u0026#34; property=\u0026#34;sScore\u0026#34;/\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;select id=\u0026#34;getAll\u0026#34; resultMap=\u0026#34;BaseResultMap\u0026#34; \u0026gt; select s_id, s_name, s_birth, s_sex FROM student \u0026lt;/select\u0026gt; \u0026lt;select id=\u0026#34;queryScore\u0026#34; parameterType=\u0026#34;int\u0026#34; resultMap=\u0026#34;ScoreResultMap\u0026#34; \u0026gt; \u0026lt;!--下面这两行效果是一样的--\u0026gt; select s_id, c_id, s_score from score where s_id = #{s_id} select s_id, c_id, s_score from score where s_id = #{sId} \u0026lt;/select\u0026gt; 多对多 多对多暂时先不写吧，后面有空，然后碰到了类似的问题的时候再来写好了。\nMyBatis插入时参数问题和MyBatis中#{}和${}区别 MyBatis中做insert操作时，values后面的参数可以直接使用插入的数据类型中的属性，接下来写一个案例：在这个案例中Controller中的方法为： @PostMapping(\u0026#34;/addStudent\u0026#34;) public int addStudent(@RequestBody Student student){ return studentMapper.addStudent(student); } 传递为json格式数据。在xxxMapper.xml中写的配置为：\n\u0026lt;insert id=\u0026#34;addStudent\u0026#34; parameterType=\u0026#34;com.luolin.springssm.model.Student\u0026#34;\u0026gt; insert into student(s_id, s_name, s_birth, s_sex) values(#{sId}, #{sName}, #{sBirth}, #{sSex}) \u0026lt;/insert\u0026gt; 此时在接口xxxMapper就应该是写：\npublic int addStudent(Student student); 倘若此时写的是：\npublic int addStudent(@Param(\u0026#34;student\u0026#34;) Student student); 那么对不起，直接会报错：\nParameter \u0026#39;sId\u0026#39; not found. Available parameters are [student, param1] 此外还有一种写法，那就是在接口xxxMapper中给参数加上注解：\npublic int addStudent(@Param(\u0026#34;student\u0026#34;) Student student); 但是这个时候xxxMapper.xml中写的配置为：\n\u0026lt;insert id=\u0026#34;addStudent\u0026#34; parameterType=\u0026#34;com.luolin.springssm.model.Student\u0026#34;\u0026gt; insert into student(s_id, s_name, s_birth, s_sex) values(#{student.sId}, #{student.sName}, #{student.sBirth}, #{student.sSex}) \u0026lt;/insert\u0026gt; 这个时候用student去标识一下是哪个类（本例中为Student）的属性总结，第一种写法为什么会成功，目前我也不清楚，暂时没有太多时间去了解，只能后面在去研究一下MyBatis的源码才能了解，我现在的猜测是MhyBatis自动映射过来了（有待验证）。个人推荐使用第二种方式写吧，感觉更清晰。\nMyBatis中#{}和${}区别还是很大的：#{}是预编译好的占位符，它在编译前就已经给值加上了\u0026rsquo;\u0026rsquo;，可以有效防止sql注入，这是它最大的优点。比如： select * from user where name = #{name} 如果此时我传一个markdown，那么传过来就是: select * from user where name = \u0026#39;markdown\u0026#39; ${}是不会将传入的值做预编译的，比如\nselect * from user where name = ${name} 如果此时我传一个markdown，那么传过来就是: select * from user where name = markdown 关于网上说的** MyBatis排序时使用order by 动态参数时需要注意，用$而不是#，**其实现在不是很懂，希望以后遇到然后弄明白。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/mybatis%E4%B8%AD%E7%9A%84%E4%B8%80%E5%AF%B9%E4%B8%80%E4%B8%80%E5%AF%B9%E5%A4%9A%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%85%B3%E8%81%94%E6%98%A0%E5%B0%84%E6%9F%A5%E8%AF%A2/","summary":"MyBatis中的一对一，一对多，多对多关联映射查询 一对多（嵌套结果） 将结果嵌套，在collection标签中加入对应的行表列映射： \u0026lt;resultMap id=\u0026#34;BaseResultMap\u0026#34; type=\u0026#34;com.luolin.springssm.model.Student\u0026#34;\u0026gt; \u0026lt;!--","title":"MyBatis中的一对一，一对多，多对多关联映射查询"},{"content":"持久层解决方案 JDBC技术：Connection; PreparedStatement; ResultSet Spring的JdbcTemplate: Spring中对jdbc的简单封装 Apache的DBUtils:它和Spring的JdbcTemplate很想，也是对Jdbc的简单封装 但是，以上都不是框架，JDBC是规范，Spring的JdbcTemplate和Apache的DBUtils都只是工具类\nMyBatis框架概述 mybatis是一款优秀的基于java的持久层框架。采用ORM思想解决实体和数据映射的问题，对jdbc进行了封装，屏蔽了jdbc api底层访问细节，使得开发人员不用于jdbc api打交道，就可以完成对数据库的持久化操作。ORM: Object Relational Mapping 对象关系映射 简单的说，就是把数据库表和实体类以及实体类的属性对应起来，让我们可以操作实体类就实现操作数据库表。mybatis官方文档：https://mybatis.org/mybatis-3/zh/index.html\n入门案例 需要的maven依赖\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.19\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.12\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 在导入mybatis依赖之后，只需要通过配置文件和实体类文件就可以\n\u0026lt;!--mybatis config文件--\u0026gt; \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!--配置环境--\u0026gt; \u0026lt;environments default=\u0026#34;mysql\u0026#34;\u0026gt; \u0026lt;!--mysql环境--\u0026gt; \u0026lt;environment id=\u0026#34;mysql\u0026#34;\u0026gt; \u0026lt;!--事务--\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;!--数据源--\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://127.0.0.1:3306/mybatis-learn?serverTimezone=UTC\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;root\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;123456\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;!--配置mapper--\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper resource=\u0026#34;mapper/UserMapper.xml\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;/configuration\u0026gt; //实体类，对应数据库中的表 public class User { private Long userId; private String userName; private Long sex; private String address; private String email; private String phone; private String password; public Long getUserId() { return userId; } public void setUserId(Long userId) { this.userId = userId; } public String getUserName() { return userName; } public void setUserName(String userName) { this.userName = userName; } public Long getSex() { return sex; } public void setSex(Long sex) { this.sex = sex; } public String getAddress() { return address; } public void setAddress(String address) { this.address = address; } public String getEmail() { return email; } public void setEmail(String email) { this.email = email; } public String getPhone() { return phone; } public void setPhone(String phone) { this.phone = phone; } public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;userId=\u0026#34; + userId + \u0026#34;, userName=\u0026#39;\u0026#34; + userName + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, sex=\u0026#34; + sex + \u0026#34;, address=\u0026#39;\u0026#34; + address + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, email=\u0026#39;\u0026#34; + email + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, phone=\u0026#39;\u0026#34; + phone + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, password=\u0026#39;\u0026#34; + password + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } // UserMapper 接口 public interface UserMapper { List\u0026lt;User\u0026gt; selectAll(); @Select(\u0026#34;select * from user\u0026#34;) List\u0026lt;User\u0026gt; findAll(); } // UserMapper.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34; \u0026gt; \u0026lt;mapper namespace=\u0026#34;infra.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;!-- 根据命名空间+方法名确定对应Mapper的全限定类名 --\u0026gt; \u0026lt;select id=\u0026#34;selectAll\u0026#34; resultType=\u0026#34;domain.entity.User\u0026#34;\u0026gt; select * from user \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; // 测试类 public class TestUser { @Test public void test1(){ InputStream inputStream = null; SqlSession session = null; try { // 1. 读取配置文件 String resource = \u0026#34;mybatis-config.xml\u0026#34;; inputStream = Resources.getResourceAsStream(resource); // 2. 创建SqlSessionFactory对象 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); // 3. 使用sqlSessionFactory生产SqlSession对象 session = sqlSessionFactory.openSession(); // 4. 使用SqlSession创建Mapper的动态代理对象 UserMapper mapper = session.getMapper(UserMapper.class); // 5. 使用代理对象执行方法 List\u0026lt;User\u0026gt; users = mapper.selectAll(); System.out.println(users.toString()); List\u0026lt;User\u0026gt; all = mapper.findAll(); System.out.println(all.toString()); } catch (Exception e) { e.printStackTrace(); }finally { // 6. 释放资源 if(null != inputStream){ try { inputStream.close(); } catch (IOException e) { e.printStackTrace(); } } if(null != session){ session.close(); } } } } 通过上面简单的案例可以达到初步使用mybatis的目的。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/mybatis%E5%85%A5%E9%97%A8%E7%AF%87/","summary":"持久层解决方案 JDBC技术：Connection; PreparedStatement; ResultSet Spring的JdbcTemplate: Spring中对jdbc的简单封装 Apache","title":"MyBatis入门篇"},{"content":"对于开发人员来讲，mybatis作为一个框架需要做到哪些事情呢？\n根据技术简单的配置好配置文件即可连接数据库，框架需要读取配置文件； 框架根据写好的sql以及传入的参数动态生成最终执行的sql，可通过jdbc执行；在这一步框架需要能够读取到sql所在位置； 框架需要在执行sql的过程中生产日志文件、执行、回滚事务等AOP操作； 现在我们通过自定义mybatis实现上面的**selectAll()**接着进行分析，要想实现查询方法，必须执行：\n根据配置文件的信息创建Connection对象，注册驱动，获取连接\n获取预处理对象PreparedStatement，此时需要使用到SQL语句，conn.prepareStatement(sql);\n执行查询 ResultSet resultSet =preparedStatement.executeQuery();\n遍历结果集用于封装\n通过入门案例观察自定义mybatis需要的类：Resources、SqlSessionFactoryBuilder、SqlSession、SqlSessionFactory接口\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/mybatis%E6%8F%90%E5%8D%87%E7%AF%87/","summary":"对于开发人员来讲，mybatis作为一个框架需要做到哪些事情呢？ 根据技术简单的配置好配置文件即可连接数据库，框架需要读取配置文件； 框架根据写","title":"MyBatis提升篇"},{"content":"问题背景 https://fanlv.fun/2021/02/11/mysql-insert-lock/ https://blog.csdn.net/qq_42524262/article/details/123189023\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-rc%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E4%B8%8B%E7%9A%84%E6%AD%BB%E9%94%81%E5%88%86%E6%9E%90/","summary":"问题背景 https://fanlv.fun/2021/02/11/mysql-insert-lock/ https://blog.csdn.net/qq_42524262/article/details/123189023","title":"Mysql rc隔离级别下的死锁分析"},{"content":"索引的本质 索引是帮助MySQL高效获取数据的排好序的数据结构 索引数据结构 二叉树 红黑树 Hash表 B-Tree 索引的建立就是数据排序的过程 为什么二叉树不适合做索引 因为当数据在插入的数据，如果是排好序的，二叉树则会退化成链表，这样就失去了索引的意义。特别是自增主键，默认就是会建索引的。 为什么红黑树不适合做索引 因为红黑树是弱平衡树，如果插入的数据是排好序的，则只会单边增长，查询效率依然不高效。特别是自增数据量大的时候，高度非常大。 为什么Hash表不适合做索引 哈希表对于范围查找和排序效率低，但对于单个数据的查询效率很高。 B-Tree结构 叶节点具有相同的深度，叶节点的指针为空 所有索引元素不重复 节点中的数据索引从左到右递增排列 B+Tree结构 非叶子节点不存储data，只存储索引(冗余)，可以放更多的索引 叶子节点包含所有索引字段 叶子节点用指针链接，提高区间访问性能； MySQL 为什么使用 B+ 树来作索引 由于mysql通常将数据存放在磁盘中，读取数据就会产生磁盘IO消耗。而B+树的非叶子节点中不保存数据，B树中非叶子节点会保存数据，通常一个节点大小会设置为磁盘页大小，这样B+树每个节点可放更多的key，B树则更少。这样就造成了，B树的高度会比B+树更高，从而会产生更多的磁盘IO消耗。 B+树叶子节点构成链表，更利用范围查找和排序。而B树进行范围查找和排序则要对树进行递归遍历 B树与B+树比较 B+树层级更少，查找更快 B+树查询速度稳定：由于B+树所有数据都存储在叶子节点，所以查询任意数据的次数都是树的高度h B+树有利于范围查找 B+树全节点遍历更快：所有叶子节点构成链表，全节点扫描，只需遍历这个链表即可 B树优点：如果在B树中查找的数据离根节点近，由于B树节点中保存有数据，那么这时查询速度比B+树快。 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8-b+-%E6%A0%91%E6%9D%A5%E4%BD%9C%E7%B4%A2%E5%BC%95%E5%AF%B9%E6%AF%94-b-%E6%A0%91%E5%AE%83%E7%9A%84%E4%BC%98%E7%82%B9%E5%92%8C%E7%BC%BA%E7%82%B9%E6%98%AF%E4%BB%80%E4%B9%88/","summary":"索引的本质 索引是帮助MySQL高效获取数据的排好序的数据结构 索引数据结构 二叉树 红黑树 Hash表 B-Tree 索引的建立就是数据排序的过程 为什么二叉树不适","title":"MySQL 为什么使用 B+ 树来作索引，对比 B 树它的优点和缺点是什么？"},{"content":"前言\n随着业务的发展，用户对系统需求变得越来越多，这就要求系统能够快速更新迭代以满足业务需求，通常系统版本发布时，都要先执行数据库的DDL变更，包括创建表、添加字段、添加索引、修改字段属性等。在数据量大不大的情况下，执行DDL都很快，对业务基本没啥影响，但是数据量大的情况，而且我们业务做了读写分离，接入了实时数仓，这时DDL变更就是一个的难题，需要综合各方业务全盘考虑。下面就聊聊这些年我公司在里面，MySQL中的DDL执行方式的变化、大表DDL该如何选择以及DDL执行过程监控。\nMySQL中的DDL DDL概述 MySQL中的DDL语句形式比较多，概括一下有以下几类：CREATE，ALTER，DROP，RENAME，TRUNCATE。这些操作都是隐式提交且原子性，要么成功，要么失败，在MySQL 8.0之前DDL操作是不记录日志的。今天就聊一下跟系统版本发布相关的数据库结构变更，主要就是ALTER TABLE变更了，DDL变更流程普通的DML变更是类似的，如下所示 注：这里涉及MySQL基础知识，还不知道的朋友翻看下我MySQL基础章节即可。在早期的MySQL版本，DDL变更都会导致全表被锁，阻塞表上的DML操作，影响业务正常运行，好的一点就是，随着MySQL版本的迭代，DDL的执行方式也在变化。\nMetaData元数据 MySQL的元数据（MetaData）跟其他的RDBMS数据库一样的，描述的对象的结构信息，存储在information_schema架构下，例如常见的TABLES、COLUMNS等，下面例子是创建一个表crm_users，MySQL会自动往Information_schema.tables和columns等相关数据字典表中插入数据，这些数据称为元数据，一般都是静态化，只有表上发生了DDL操作才会实时更新。 MetaData Lock MySQL利用MetaData Lock来管理对象的访问，保证数据的一致性，对于一些核心业务表，表上DML操作比较频繁，这个时候添加字段可能会触发MetaData Lock。 可以看到Waiting for table metadata lock等待事件，thread 155正在执行alter table等待thread 154执行的select释放锁，因为DML在执行期间会持有SHARED_READ锁，要执行DDL时获取SHARED_UPGRADABLE（共享可升级锁，缩写为SU，允许并发更新和读同一个表）锁成功，但是获取EXCLUSIVE MetaData Lock锁失败，处于暂挂PENDING状态。\nDDL执行方式 从MySQL官方文档可以看到，ALTER TABLE的选项很多，跟性能相关的选项主要有ALGORITHM和LOCK。 ALGORITHM OPTION DESCRIPTION COPY MySQL早期的变更方式，需要创建修改后的临时表，然后按数据行拷贝原表数据到临时表，做rename重命名来完成创建，在此期间不允许并发DML操作，原表是可读的，不可写，同时需要额外一倍的磁盘空间。 INPLACE 直接在原表上进行修改，不需创建临时表拷贝数据及重命名，原表会持有Exclusive Metadata Lock，通常是允许并发DML操作。 INSTANT MySQL 5.8开始支持，只修改数据字典中的元数据，表数据不受影响，执行期间没有Exclusive Metadata Lock，允许并发的DML操作。 从这张表可以看到，MySQL对于DDL执行方式一直在做优化，目的就是为了提高DDL执行效率，减少锁等待，不影响表数据，同时不影响正常的DML操作。LOCK选项\nLOCK OPTiON DESCRIPTION DEFAULT 默认模式：MySQL根据运行情况，在尽量不锁表的情况下自动选择LOCK模式。 NONE 无锁：允许Online DDL期间进行并发读写操作，如果Online DDL操作不支持对表并发DML操作，则DDL操作失败，对表修改无效。 SHARED 共享锁：Online DDL操作期间不影响读取，阻塞写入。 EXCLUSIVE 排它锁：Online DDL操作期间不允许对锁表进行任何操作。 下面举例说明下这几种方式的执行过程，先创建测试表，制造一些数据。 COPY COPY方式的变更流程如下： 根据业务需要，需要在crm_users添加一个字段user_type，采用COPY方式执行变更。 从执行过程及profile可以看出，通过COPY方式会创建临是表#sql-564_85，获取System Lock，拷贝数据到临时表，最后做rename表名切换，释放Lock资源，在执行期间不支持并发DML操作。\nINPLACE INPLACE方式是在原表上直接修改，对于添加索引、添加/删除列、修改字段NULL/NOT NULL属性等操作，需要修改MySQL内部的数据记录，需要重建表（Rebuild Table）。 从执行过程可以看到，需要获取Exclusive Metadata Lock，修改表数据，释放Lock，在执行期间支持并发DML操作。\nINSTANT MySQL 5.8开始推出的方式，DDL只修改数据字典中的元数据，表数据不受影响，没有Exclusive Metadata Lock，允许并发的DML操作，支持的DDL变更是有限制的，目前主要包括添加字段，添加/删除生成列，修改ENUM或SET列，改变索引类型以及重命名表。 比对下这三种方式的执行效率\n执行方式/项目 数据量(w) 执行时间(s) 重建表 修改MetaData 修改Data 允许并发DML COPY 650 29.89 YES No Yes No INPLACE 650 10.56 YES No Yes Yes INSTANT 650 0.19 No Yes No Yes ONLINE DDL 截止MySQL 8.0，OnLine DDL有三种方式COPY，INPLACE，INSTANT，MySQL会自动根据执行的DDL选择使用哪种方式，一般会优先选择INSTANT方式，如果不支持，就选择INPLANCE方式，再不支持就只能选择COPY方式了。MySQL官方文档也给出了Online DDL的支持矩阵，列下常用的DDL操作，对比项主要包括是否重建表，允许并发的DML操作以及只修改元数据，表数据不受影响。\nOperation Instant In Place Copy Rebuilds Table Permits Concurrent DML Only Modifies Metadata Adding a column Yes Yes* Yes No* Yes* Yes Dropping a column No Yes Yes Yes Yes No Renaming a column No Yes Yes No Yes Yes Setting a column default value Yes Yes Yes No Yes Yes Dropping the column default value Yes Yes Yes No Yes Yes Changing the auto-increment value No Yes Yes No Yes No Making a column NULL No Yes Yes Yes* Yes No Making a column NOT NULL No Yes Yes Yes* Yes No Adding a primary key No Yes* Yes Yes* Yes No Dropping a primary key No No Yes Yes No No Creating or adding a secondary index No Yes Yes No Yes No Dropping an index No Yes Yes No Yes Yes Renaming an index No Yes Yes No No No Adding a FULLTEXT index No Yes* Yes No* No No 大表DDL方案 在实际业务系统中，业务发展比较快，表的数据量比较大，业务层面又做了读写分离，同时会将MySQL数据实时同步到数据仓库（包括实时数仓和离线数仓），实际的数据库架构如下。 假设这是一个交易系统数据库，订单表booking有8000w数据，且接入到了实时和离线仓库，根据业务需要，在订单表booking添加一个字段，在MySQL 5.7之前添加字段属于高危操作，需要充分考虑对业务的影响，主要存在于两个方面：\n在读写分离场景，主从同步延迟导致业务数据不一致 实时数仓ADB不允许源端MySQL表重命名，如果通过COPY方式或者pt-osc、gh-ost等工具都会rename表名，那么就需要从数仓删除该表，重新配置同步（全量 + 增量），会影响数仓业务 ONLINE DDL方式 对于MySQL 5.6到5.7的版本，可以使用OnLine DDL的方式变更，对于大表来说，执行时间会很长，好处是在Master上DML操作不受影响，但是会导致主从延时。假如Master上添加字段执行了20分钟，相应的Slave也要执行20分钟，在这期间Slave一直处于延迟状态，会造成业务数据不一致，比如用户在Master下单成功，由于Slave延迟查询不到订单信息，用户误以为网络原因没有下单成功，又下了一单，导致重复下单的情况。这种方式会导致主从延迟，但是不会影响实时数仓的业务，根据业务情况，只能选择在业务低峰期执行了。\npt-osc工具 为了解决DDL变更导致主从延时对业务的影响，会想到用大表变更利器pt-osc（pt-online-schema-change）或者gh-ost工具来做，这两个工具执行过程及原理大同小异，变更流程如下（不考虑外键，按照MySQL规范不允许使用外键）： 创建一个新的表，表结构为修改后的数据表，用于从源数据表向新表中导入数据。 在源表上创建触发器，用于记录从拷贝数据开始之后，对源数据表继续进行数据修改的操作记录下来，用于数据拷贝结束后，执行这些操作，保证数据不会丢失。 拷贝数据，从源数据表中拷贝数据到新表中。 修改外键相关的子表，根据修改后的数据，修改外键关联的子表。 rename源数据表为old表，把新表rename为源表名，并将old表删除。 删除触发器。 执行pt-osc的时候也需要获取一个Exclusive Metadata Lock，如果在此期间表上有DML操作正在进行，pt-osc操作会一直处于暂挂PENDING状态，这个时候表上正常DML操作都会被阻塞，MySQL活动连接数瞬间暴涨，CPU使用率100%，依赖的该表的接口都会报错，所以要选择在业务低峰期执行，同时做好MetaData Lock锁的监控以便业务不受影响，来看一个例子： D=trade, t=booking：数据库trade，表名booking。\u0026ndash;chunk-size=1000：每次拷贝的数据行数。\u0026ndash;max-log = 1：确保从库延迟不超过1s，超过就停止拷贝数据。\u0026ndash;check-interval=2：表示等待2s之后继续拷贝数据。\u0026ndash;recursion-method=\u0026ldquo;hosts\u0026rdquo;：如果不是使用默认端口3306，那么使用hosts方式来查找从库更可靠。一般MySQL binlog格式都是ROW，pt-osc在拷贝数据的过程也会产生大量的binlog，也可能导致主从延时，需要控制好每次拷贝数据的大小和频率，在执行期间，也会降低DML的并发度。\nMySQL 8.0变更方式 用过Oracle的都知道，DDL变更都是修改元数据，上亿的表在Oracle中DDL变更都是瞬间完成。令人激动的是，MySQL 8.0也推出了INSTANT方式，真正的只修改MetaData，不影响表数据，所以它的执行效率跟表大小几乎没有关系。建议新系统上线用MySQL的话尽量使用MySQL 8.0，老的数据库也可以升级到MySQL 8.0获取更好的性能。官方文档对INSTANT的解释：INSTANT: _Operations only modify metadata in the data dictionary. No exclusive metadata locks are taken on the table during preparation and execution, and table data is unaffected, making operations instantaneous. Concurrent DML is permitted. (Introduced in MySQL 8.0.12)_既要解决主从同步，又要解决rename数仓不同步的问题，目前只有INSTANT方式满足需求了。\n监控DDL执行进度 在大表执行DDL变更的时候，非常关心它的执行进度，MySQL 5.7之前是没有好的工具去监控，基本只能坐等了。在MySQL 8.0可以通过开启performance_schema，打开events_stages_current事件进行监控。 总结 DDL在业务系统版本迭代的过程是必不可少的，如何在不影响业务以及外围系统的情况下，实现DDL的平滑变更，是需要综合个系统特性考虑的，评估出重要性和优先级，同时也要掌握不同MySQL版本DDL执行方式，以便我们做更好的选择。例如上面提到了，目前我在大数据团队，我们的业务都做了读写分离，同时接入实时数仓，数仓不支持rename操作，这时就可以选择在业务低峰期使用ONLINE DDL的方式执行，对业务系统影响最小，同时不影响数仓。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql%E5%A4%A7%E8%A1%A8%E6%9B%B4%E6%96%B0%E6%96%B9%E6%A1%88/","summary":"前言 随着业务的发展，用户对系统需求变得越来越多，这就要求系统能够快速更新迭代以满足业务需求，通常系统版本发布时，都要先执行数据库的DDL变更","title":"MySql大表更新方案"},{"content":"Mysql分层、存储引擎 常用引擎对比：InnoDB:事务优先(适合高并发操作，使用行锁) MyISAM:性能优先（使用表锁）\n可以使用show engines;查看当前使用数据库支持哪些引擎；使用show VARIABLES LIKE '%storage_engine%';正在使用的引擎。\nsql解析过程、索引、B树 sql解析过程 一条sql示例如下：\nSELECT DISTINCT \u0026lt; select_list \u0026gt; FROM \u0026lt; left_table \u0026gt; \u0026lt; join_type \u0026gt; JOIN \u0026lt; right_table \u0026gt; ON \u0026lt; join_condition \u0026gt; WHERE \u0026lt; where_condition \u0026gt; GROUP BY \u0026lt; group_by_list \u0026gt; HAVING \u0026lt; having_condition \u0026gt; ORDER BY \u0026lt; order_by_condition \u0026gt; LIMIT \u0026lt; limit_number \u0026gt; 然而它的执行过程却是：\nFROM \u0026lt;left_table\u0026gt; ON \u0026lt;join_condition\u0026gt; \u0026lt;join_type\u0026gt; JOIN \u0026lt;right_table\u0026gt; WHERE \u0026lt;where_condition\u0026gt; GROUP BY \u0026lt;group_by_list\u0026gt; HAVING \u0026lt;having_condition\u0026gt; SELECT DISTINCT \u0026lt;select_list\u0026gt; ORDER BY \u0026lt;order_by_condition\u0026gt; LIMIT \u0026lt;limit_number\u0026gt; 索引 索引相当于书的目录，可以帮助Mysql高效获取数据的数据结构，一般使用树、B树、Hash树..完成\n索引的弊端：\n索引本身很大，可以存放在内存/硬盘（通常为硬盘） 索引不是所有情况均适用：少量数据频繁更新的字段很少使用的字段 索引会降低增删改的效率 索引的优势：\n提高查询效率（降低IO使用率） 降低CPU使用率(\u0026hellip; order by age desc，因为B树索引本身就是一个排好序的结构，不再需要排序) 索引分类\n主键索引：不能重复。id 不能是null 唯一索引：不能重复。id 可以是null 单值索引：单列，age；一个表可以有多个单值索引,name。 复合索引：多个列构成的索引（相当于二级目录：z:zhao） 创建索引\n方式一：create \u0026lt;索引类型\u0026gt; \u0026lt;索引名\u0026gt; on \u0026lt;表名(字段)\u0026gt;单值： create index dept_index on tb(dept)唯一： create unique index name_index on tb(name)复合： create index dept1_dept2_index on tb(dept1,dept2) 方式二：alter table \u0026lt;表名\u0026gt; add \u0026lt;索引类型\u0026gt; \u0026lt;索引名(字段)\u0026gt;单值： alter table tb add index dept_index(dept)唯一： alter table tb add unique index name_index(name)复合： alter table tb add index dept1_dept2_index(dept1,dept2) 删除索引\ndrop index 索引名 on 表名 查询索引\nshow index from 表名 sql优化 sql优化主要通过优化索引完成。通过explain分析sql的执行计划，可以模拟sql优化器执行sql语句，从而知道 MySQL 是如何处理你的 SQL 语句的。分析查询语句或是表结构的性能瓶颈。\nEXPLAIN 使用方式 EXPLAIN + SQL 语句 执行计划包含的信息\n表的读取顺序 ( id ) 数据读取操作的操作类型 ( select_type ) 每个子查询使用了哪种类型 ( type ) 哪些索引可以使用 ( possible_keys ) 哪些索引被实际使用 ( key ) 索引的长度 ( key_len ) 表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 ( ref ) 每张表有多少行被优化器查询 ( rows ) 执行计划各字段含义： id id 相同，执行顺序由上至下 id 不同，如果是子查询，id 的序号会递增，id 值越大优先级越高，越先被执行 id 同时存在相同的和不同的,还是按照上面两个规则执行 id 为 null 时表示一个结果集，不需要使用它查询，常出现在包含 union 等查询语句中 执行计划各字段含义： select_type 分别用来表示查询的类型，主要是用于区别普通查询、联合查询、子查询等的复杂查询。\nSIMPLE 简单的 select 查询，查询中不包含子查询或者 union PRIMARY 查询中若包含任何复杂的子部分，最外层查询则被标记为 primary SUBQUERY 在 select 或 where 列表中包含了子查询 DERIVED 在 from 列表中包含的子查询被标记为 derived（衍生），MySQL 会递归执行这些子查询，把结果放在临时表中 UNION 若第二个 select 出现在 union 之后，则被标记为 union，若 union 包含在 from - 子句的子查询中，外层 select 将被标记为：derived UNION RESULT 从 union 表获取结果的 select 执行计划各字段含义： table 标识查询的数据表\n若查询时表使用了别名，则 table 显示别名； 当从衍生表（即临时表）中查数据时会显示 , x 表示对应的执行计划 id； 若显示 \u0026lt;union x,y\u0026gt;，也表示一个临时表，表示这个结果来自于执行计划 id 为 x，y 的结果集； 执行计划各字段含义： type type 所显示的是查询使用了哪种类型，type 包含的类型包括如所示的几种：\nsystem \u0026gt; const \u0026gt; eq_ref \u0026gt; ref \u0026gt; range \u0026gt; index \u0026gt; all 一般来说，得保证查询至少达到 range 级别，最好能达到 ref\nNULL MySQL 在优化过程中分解语句，执行时甚至不用访问表或索引 system 表只有一行记录（等于系统表），这是 const 类型的特列，平时不会出现，这个也可以忽略不计 const 表示通过索引一次就找到了，const 用于比较 primary key 或者 unique 索引。因为只匹配一行数据，所以很快。如将主键置于 where 列表中，MySQL 就能将该查询转换为一个常量 eq_ref 唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描 ref 非唯一性索引扫描，返回匹配某个单独值的所有行，本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而，它可能会找到多个符合条件的行，所以它应该属于查找和扫描的混合体 range 只检索给定范围的行，使用一个索引来选择行，key 列显示使用了哪个索引，一般就是在你的 where 语句中出现 between、\u0026lt; 、\u0026gt;、in 等的查询，这种范围扫描索引比全表扫描要好，因为它只需要开始于索引的某一点，而结束于另一点，不用扫描全部索引 index Full Index Scan，Index 与 All 区别为 index 类型只遍历索引树。这通常比 All 快，因为索引文件通常比数据文件小。（也就是说虽然 All 和Index都是读全表，但 Index 是从索引中读取的，而 All 是从硬盘读取的） all Full Table Scan 将遍历全表以找到匹配的行 执行计划各字段含义： possible_keys 和 key possible_keys\n显示可能应用在这张表中的索引，一个或多个。查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用。\nkey\n实际使用的索引，如果为NULL，则没有使用索引。（可能原因包括没有建立索引或索引失效） 查询中若使用了覆盖索引（select 后要查询的字段刚好和创建的索引字段完全相同），则该索引仅出现在 key 列表中 执行计划各字段含义： key_len 查询中若使用了覆盖索引（select 后要查询的字段刚好和创建的索引字段完全相同），则该索引仅出现在 key 列表中\n执行计划各字段含义：ref 显示索引的那一列被使用了，如果可能的话，最好是一个常数。哪些列或常量被用于查找索引列上的值\n执行计划各字段含义： rows 根据表统计信息及索引选用情况，大致估算出找到所需的记录所需要读取的行数，也就是说，用的越少越好\n执行计划各字段含义： Extra Using filesort：说明 MySQL 会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。MySQL 中无法利用索引完成的排序操作称为“文件排序”。 Using temporary：表示 MySQL 需要使用临时表来存储结果集，常见于 order by 和 group by。 Using index：表示相应的 select 操作中使用了覆盖索引（Covering Index），避免访问了表的数据行，效率不错。如果同时出现 using where，表明索引被用来执行索引键值的查找；如果没有同时出现 using where，表明索引用来读取数据而非执行查找动作。 Using where：表明使用了where过滤 Using join buffer：表明使用了连接缓存，比如说在查询的时候，多表 join 的次数非常多，那么将配置文件中的缓冲区的 join buffer 调大一些。 impossible where：where 子句的值总是 false，不能用来获取任何元组 select tables optimized away：在没有 group by 子句的情况下，基于索引优化 MIN/MAX 操作或者对于 MyISAM 存储引擎优化 COUNT(*) 操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化。 distinct：优化 distinct 操作，在找到第一匹配的元组后即停止找同样值的动作 firstmatch：5.6.x 开始引入的优化子查询的新特性之一，常见于 where 字句含有 in() 类型的子查询。如果内表的数据量比较大，就可能出现这个 loosescan：5.6.x 之后引入的优化子查询的新特性之一，在 in() 类型的子查询中，子查询返回的可能有重复记录时，就可能出现这个 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/","summary":"Mysql分层、存储引擎 常用引擎对比：InnoDB:事务优先(适合高并发操作，使用行锁) MyISAM:性能优先（使用表锁） 可以使用show e","title":"MySql性能优化基本知识"},{"content":"前言 本文主要介绍在MySql数据库中如何进行基本的死锁分析，尤其是针对线上环境死锁，但是仅仅通过日志可能不是很好分析具体死锁原因的，只能通过死锁日志进行分析。\nMySql死锁日志介绍 MySQL的死锁指的是两个事务互相等待的场景，这种循环等待理论上不会有尽头。 比如事务A持有行1的锁，事务B持有行2的锁； 然后事务A试图获取行2的锁，事务B试图获取行1的锁； 这样事务A要等待事务B释放行2的锁，事务B要等待事务A释放行1的锁； 两个事务互相等待，谁也提交不了。\n死锁验证 新建表，有如下数据： start TRANSACTION; delete from t_order where id = 156; update t_order set order_num = \u0026#39;test-dead-lock\u0026#39; where id = 168; start TRANSACTION; delete from t_order where id = 168; update t_order set order_num = \u0026#39;test-dead-lock\u0026#39; where id = 156; 流程如下：\n流程 TRANSACTION1 TRANSACTION2 1 begin begin 2 delete from t_order where id = 156; 3 delete from t_order where id = 168; 4 update t_order set order_num = \u0026rsquo;test-dead-lock\u0026rsquo; where id = 168; 5 update t_order set order_num = \u0026rsquo;test-dead-lock\u0026rsquo; where id = 156; 死锁日志获取 执行show engine innodb status\n注意：针对线上环境，建议将 innodb_print_all_deadlocks 参数设置为 1 ，这样每次发生死锁后，系统会自动将死锁信息输出到错误日志中，需要注意的是打开此参数后，只会记录死锁部分信息而不会记录 innodb 其他相关信息，即只会记录 show engine innodb status 中的 LATEST DETECTED DEADLOCK 部分。\n死锁日志分析 \u0026#34;Type\u0026#34;\t\u0026#34;Name\u0026#34;\t\u0026#34;Status\u0026#34; \u0026#34;InnoDB\u0026#34;\t\u0026#34;\u0026#34;\t\u0026#34; ===================================== 2023-01-30 15:57:23 0x16e733000 INNODB MONITOR OUTPUT ===================================== Per second averages calculated from the last 49 seconds ----------------- BACKGROUND THREAD ----------------- srv_master_thread loops: 72 srv_active, 0 srv_shutdown, 252891 srv_idle srv_master_thread log flush and writes: 252963 ---------- SEMAPHORES ---------- OS WAIT ARRAY INFO: reservation count 151 OS WAIT ARRAY INFO: signal count 148 RW-shared spins 0, rounds 198, OS waits 88 RW-excl spins 0, rounds 30, OS waits 0 RW-sx spins 0, rounds 0, OS waits 0 Spin rounds per wait: 198.00 RW-shared, 30.00 RW-excl, 0.00 RW-sx ------------------------ LATEST DETECTED DEADLOCK ------------------------ 2023-01-30 15:56:09 0x16e733000 #最近一次发生死锁的日期和时间 *** (1) TRANSACTION: #死锁相关的第一个事务 TRANSACTION 9863, ACTIVE 37 sec starting index read #该事务id为9863，事务处于活跃状态37s，starting index read表示正在使用索引读取数据行 mysql tables in use 1, locked 1 #该事务正在使用1个表，且涉及锁的表有1个 LOCK WAIT 3 lock struct(s), heap size 1136, 2 row lock(s), undo log entries 1 #该事务在等待3把锁，占用内存1136字节，涉及2行记录 MySQL thread id 177, OS thread handle 6152269824, query id 2378 localhost 127.0.0.1 root updating #该事务的线程ID信息，操作系统句柄信息，连接来源、用户 update t_order set order_num = \u0026#39;test-dead-lock\u0026#39; where id = 168 #该事务执行的最后一条SQL信息 *** (1) WAITING FOR THIS LOCK TO BE GRANTED: #事务1想要获取的锁 RECORD LOCKS space id 24 page no 3 n bits 80 index PRIMARY of table `springboot`.`t_order` trx id 9863 lock_mode X locks rec but not gap waiting #该事务等待的锁是一个record lock，空间id是24，页编号为3，大概位置在页的80位处，锁发生在表springboot.t_order的PRIMARY索引上，是一个X锁，但是不是gap lock，waiting表示正在等待锁（X：排他锁，S：共享锁），非间隙锁 Record lock, heap no 6 PHYSICAL RECORD: n_fields 4; compact format; info bits 32 0: len 4; hex 000000a8; asc ;; 1: len 6; hex 000000002688; asc \u0026amp; ;; 2: len 7; hex 5200000166032b; asc R f +;; 3: len 9; hex 4f5244455274657374; asc ORDERtest;;# 表明想要持有值=ORDERtest的那笔数据 *** (2) TRANSACTION: TRANSACTION 9864, ACTIVE 34 sec starting index read #该事务id为9864，事务处于活跃状态34s，starting index read表示正在使用索引读取数据行 mysql tables in use 1, locked 1 #该事务正在使用1个表，且涉及锁的表有1个 3 lock struct(s), heap size 1136, 2 row lock(s), undo log entries 1 #该事务在等待3把锁，占用内存1136字节，涉及2行记录 MySQL thread id 181, OS thread handle 6148009984, query id 2382 localhost 127.0.0.1 root updating #该事务的线程ID信息，操作系统句柄信息，连接来源、用户 update t_order set order_num = \u0026#39;test-dead-lock\u0026#39; where id = 156 #该事务执行的最后一条SQL信息 *** (2) HOLDS THE LOCK(S): # 事务2持有的锁 正是事务1想要获取的锁 RECORD LOCKS space id 24 page no 3 n bits 80 index PRIMARY of table `springboot`.`t_order` trx id 9864 lock_mode X locks rec but not gap Record lock, heap no 6 PHYSICAL RECORD: n_fields 4; compact format; info bits 32 0: len 4; hex 000000a8; asc ;; 1: len 6; hex 000000002688; asc \u0026amp; ;; 2: len 7; hex 5200000166032b; asc R f +;; 3: len 9; hex 4f5244455274657374; asc ORDERtest;; # 表明持有值=ORDERtest的那笔数据 *** (2) WAITING FOR THIS LOCK TO BE GRANTED: #事务1想要获取的锁 RECORD LOCKS space id 24 page no 3 n bits 80 index PRIMARY of table `springboot`.`t_order` trx id 9864 lock_mode X locks rec but not gap waiting Record lock, heap no 8 PHYSICAL RECORD: n_fields 4; compact format; info bits 32 0: len 4; hex 0000009c; asc ;; 1: len 6; hex 000000002687; asc \u0026amp; ;; 2: len 7; hex 510000016501ec; asc Q e ;; 3: len 14; hex 746573742d646561642d6c6f636b; asc test-dead-lock;; # 表明想要持有值=ORDERtest的那笔数据 #上面这部分是事务二正在等待的锁，从信息上看，等待的是同一个表，同一个索引，同一个page上的record lock X锁，但是heap no位置不同，即不同的行上的锁 *** WE ROLL BACK TRANSACTION (2) ------------ TRANSACTIONS ------------ Trx id counter 9870 Purge done for trx\u0026#39;s n:o \u0026lt; 9870 undo n:o \u0026lt; 0 state: running but idle History list length 4 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 281479704088128, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 281479704089936, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 281479704089032, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 281479704086320, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 9863, ACTIVE 111 sec 3 lock struct(s), heap size 1136, 2 row lock(s), undo log entries 2 MySQL thread id 177, OS thread handle 6152269824, query id 2385 localhost 127.0.0.1 root -------- FILE I/O -------- I/O thread 0 state: waiting for i/o request (insert buffer thread) I/O thread 1 state: waiting for i/o request (log thread) I/O thread 2 state: waiting for i/o request (read thread) I/O thread 3 state: waiting for i/o request (read thread) I/O thread 4 state: waiting for i/o request (read thread) I/O thread 5 state: waiting for i/o request (read thread) I/O thread 6 state: waiting for i/o request (write thread) I/O thread 7 state: waiting for i/o request (write thread) I/O thread 8 state: waiting for i/o request (write thread) I/O thread 9 state: waiting for i/o request (write thread) Pending normal aio reads: [0, 0, 0, 0] , aio writes: [0, 0, 0, 0] , ibuf aio reads:, log i/o\u0026#39;s:, sync i/o\u0026#39;s: Pending flushes (fsync) log: 0; buffer pool: 0 509 OS file reads, 891 OS file writes, 507 OS fsyncs 0.00 reads/s, 0 avg bytes/read, 0.00 writes/s, 0.00 fsyncs/s ------------------------------------- INSERT BUFFER AND ADAPTIVE HASH INDEX ------------------------------------- Ibuf: size 1, free list len 0, seg size 2, 0 merges merged operations: insert 0, delete mark 0, delete 0 discarded operations: insert 0, delete mark 0, delete 0 Hash table size 34679, node heap has 0 buffer(s) Hash table size 34679, node heap has 0 buffer(s) Hash table size 34679, node heap has 0 buffer(s) Hash table size 34679, node heap has 0 buffer(s) Hash table size 34679, node heap has 1 buffer(s) Hash table size 34679, node heap has 0 buffer(s) Hash table size 34679, node heap has 0 buffer(s) Hash table size 34679, node heap has 0 buffer(s) 0.00 hash searches/s, 0.00 non-hash searches/s --- LOG --- Log sequence number 3001164 Log flushed up to 3001164 Pages flushed up to 3001164 Last checkpoint at 3001155 0 pending log flushes, 0 pending chkp writes 314 log i/o\u0026#39;s done, 0.00 log i/o\u0026#39;s/second ---------------------- BUFFER POOL AND MEMORY ---------------------- Total large memory allocated 137428992 Dictionary memory allocated 148351 Buffer pool size 8192 Free buffers 7765 Database pages 426 Old database pages 0 Modified db pages 0 Pending reads 0 Pending writes: LRU 0, flush list 0, single page 0 Pages made young 0, not young 0 0.00 youngs/s, 0.00 non-youngs/s Pages read 367, created 59, written 515 0.00 reads/s, 0.00 creates/s, 0.00 writes/s No buffer pool page gets since the last printout Pages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/s LRU len: 426, unzip_LRU len: 0 I/O sum[0]:cur[0], unzip sum[0]:cur[0] -------------- ROW OPERATIONS -------------- 0 queries inside InnoDB, 0 queries in queue 0 read views open inside InnoDB Process ID=1616, Main thread ID=6142193664, state: sleeping Number of rows inserted 939, updated 2, deleted 16, read 1596 0.00 inserts/s, 0.00 updates/s, 0.00 deletes/s, 0.00 reads/s ---------------------------- END OF INNODB MONITOR OUTPUT ============================ \u0026#34; 总结 通过本文[[MySQL死锁日志查看与分析#死锁日志分析]]中一些枯燥的注释，基本可以看出事务9863和事务9864存在冲突，导致数据库层面发生死锁，正常线上代码应该尽量规避死锁，由于线上情况比较复杂，这里给出几个可供参考的解决方案：\n针对一些update强制调整成按照主键顺序执行，如果是根据非唯一组合所以进行更新，则考虑使用分布式锁，针对进行进行大批量锁定 RC隔离级别MySql，代码层面规避使用delete-insert-update对同一数据进行多次db操作，因为并发情况下会导致出现乐观锁报错或者其他业务报错，从而带出范围锁，进一步引发出死锁 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql%E6%AD%BB%E9%94%81%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B%E4%B8%8E%E5%88%86%E6%9E%90/","summary":"前言 本文主要介绍在MySql数据库中如何进行基本的死锁分析，尤其是针对线上环境死锁，但是仅仅通过日志可能不是很好分析具体死锁原因的，只能通过","title":"MySQL死锁日志查看与分析"},{"content":" MySQL索引数据结构分析\n摘要 本文讨论MySQL数据库索引数据结构相关的一些话题，重点在于常用的B+Tree索引以及性能十分高的Hash索引的数据组织方式；还包括B+Tree索引中的聚集索引和非聚集索引，以及B+Tree索引和Hash索引使用的到复合索引数据组织方式。\nHash索引 在MySQL的存储引擎中，由于InnoDB和MyISAM默认都是使用的B+Tree索引，所以通常情况我们都是是用的B+Tree索引。尽管hash索引并不是非常常见，但是我认为hash索引也是需要掌握的，Mermory默认使用的Hash索引。\nMySQL中的Hash索引是基于hash table实现的，只有精确匹配索引所有列的查询才会生效。对于表中的每一行数据，MySQL都会为其中的所有索引列计算一个hash code （利用hash算法计算）,使用mysql的select语言进行查询操作时，会根据where后面的条件索引列计算出hash code，利用这个hash code可以直接获取到对应记录的地址。当然，可能存在不同组合索引值计算出了相同的hash code，这就是hash冲突。对于hash冲突，我们通常有两种办法: 1. 开放地址法； 2. 拉链法（关闭地址法）\n如图一，使用name,age作为表的hash索引列，遇到hash冲突时则使用拉链法解决；利用hash table获取到记录的地址之后可以直接根据地址获取数据。相比较B+Tree，在很多情况下hash索引的检索速度要快于B+Tree索引。但是，为什么平时我们还是主要使用B+Tree索引呢？其实，根据图一，我们也能看出hash索引有如下特点：\n只有使用=，!=, \u0026lt;\u0026gt;时才能使用到hash索引，即只能使用等值查询，不能使用范围查询。 hash索引无法被用来避免数据的排序操作，什么意思呢？其实就是如果需要进行order by操作，根据hash索引获取到的数据还得进行一次排序，不能像B+Tree一样，根据索引拿到的数据可以直接排好序。 hash索引必须使用所有索引列进行查询，因为hash code是经过所有索引列计算出来的。所以通过组合索引的前面一个或几个索引键进行查询的时候，hash索引将无法被利用。 hash索引在任何时候都不能避免表扫描，由于根据hash table存在多个key对应一个hash code，所以一旦hash code相同的情况下，必须根据表中实际数据对比获取想要查找的结果。 hash索引遇到大量hash值相等的情况后性能并不一定就会比BTree索引高。对于选择性比较低的索引键，如果创建Hash索引，那么会有大量的key对应同一个hash code；根据第4点我们知道，此时是要进行表扫描的，这时定位一条记录，会浪费多次表数据的访问，而造成整体性能低下。 B+Tree索引 在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对B+Tree索引的实现方式有所不同，这里就主要分析MyISAM通过非聚集索引的方式实现的B+Tree索引和InnoDB通过聚集索引的方式实现的B+Tree。\nMyISAM引擎实现方式 MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。图二是MyISAM索引的原理图： 这里设表一共有四列，假设我们以id为主键，则图二是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在name上建立一个辅助索引，则此索引的结构中B+Tree节点中应该保存的是name字段值，而非主键值。\nInnoDB实现方式 虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。最大区别就在于InnoDB的数据文件本身就是索引文件。而MyISAM索引文件和数据文件是分离的，索引文件仅仅保存数据记录的地址。在InnoDb中，数据文件本身就是按B+Tree组织的一个索引结构，这个B+Tree的叶子节点会存储完整的数据记录。这个索引的key是数据表的主键。因此InnoDB表数据文件本身就是primary key。而如果没有显示地为表声明主键，InnoDB则会隐式地创建主键索引树。 InnoDB和MyISAM的辅助索引区别则如图四（取自高性能mysql） 复合索引 对于mysql中的复合索引（使用B+Tree索引），不管是基于聚集索引还是非聚集索引，其实与普通索引并没有什么区别，只是每一个节点存储的数据列发生了变化，主要是复合索引的树节点中存储的将会是复合索引的所有列组合，可以参考图五（取自高性能mysql）内容进行分析。 参考资料：高性能mysql\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql%E7%B4%A2%E5%BC%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/","summary":"MySQL索引数据结构分析 摘要 本文讨论MySQL数据库索引数据结构相关的一些话题，重点在于常用的B+Tree索引以及性能十分高的Hash索引","title":"MySQL索引数据结构分析"},{"content":"宏观 数据库锁 数据库锁适用于集群 粒度小，更方便控制 代码锁 需要复杂的处理，才能作用于集群 粒度大 微观 行锁和表锁 说明 说明只有明确指定主键，才会执行锁，否则将会执行表锁\n示例 假设有个表 products ，字段id、name、type，id是主键。\n无锁 # 明确指定主键，但不存在该主键的值(没有数据，当然不会有锁) SELECT * FROM products WHERE id=-1 FOR UPDATE; 行锁 # 明确指定主键 SELECT * FROM products WHERE id=3 FOR UPDATE; SELECT * FROM products WHERE id=3 AND type=1 FOR UPDATE; 表锁 # 主键不明确 SELECT * FROM products WHERE name=\u0026#39;Mouse\u0026#39; FOR UPDATE; SELECT * FROM products WHERE id\u0026lt;\u0026gt;\u0026#39;3\u0026#39; FOR UPDATE; SELECT * FROM products WHERE id LIKE \u0026#39;3\u0026#39; FOR UPDATE; 注意 要测试锁定的状况，可以利用 MySQL 的 Command Mode ，开二个视窗来做测试。 MyAsim 只支持表级锁，InnerDB支持行级锁添加了（行级锁、表级锁）锁的数据不能被其它事务再锁定，也不被其它事务修改（修改、删除） 。是表级锁时，不管是否查询到记录，都会锁定表。 行锁算法 Record Lock (普通行锁) 对于键值在条件范围内，且存在的记录，使用“Record Lock”，即普通的行锁机制 GAP Lock（间隙锁） 对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP）”，InnoDB会对这个“间隙”加锁，这种锁机制就是所谓的\u0026quot; Gap Lock \u0026ldquo;(间隙锁)； Next-Key Lock（行\u0026amp;间隙锁） 对于存在于不存在的数据同时加锁，则称为\u0026rdquo; Next-Key Lock \u0026ldquo;； Next-Key Lock包含Record Lock和Gap Lock； # 假如user表中只有101条记录，empid的值是1,2,...,100,101 # 范围条件的检索，会对值为101的记录加锁，也会对大于101（不存在）加锁 # 由于两个锁同时存在，则此处为 Next-Key Lock select * from user where user_id \u0026gt; 100 for update; 表锁算法 意向锁 当一个事务带着表锁去访问一个被加了行锁的资源，那么，此时，这个行锁就会升级为意向锁，将表锁住。 常用的意向锁有：意向共享锁，意向排它锁，共享意向排它锁 自增锁 事务插入自增类型的列时获取自增锁 如果一个事务正在往表中插入自增记录，所有其他事务的插入必须等待\n实现 共享锁\u0026amp;排他锁 行锁和表锁是锁粒度的概念，共享锁和排它锁是他们的具体实现\n共享锁(S):读锁 允许一个事务去读一行数据，组织其他事物获取该数据的排他锁 多事务时，只能加共享锁，不能加排他锁；单事务时，可以加任何锁 一般理解为：能读，不能写 排他锁(X):写锁 允许只有排他锁的事务读写数据，阻止其他事物获取该数据的共享锁和排他锁 其他事物不能获取该数据的任何锁，直到排他锁持有者释放 不能获取任何锁，不代表不能无锁读取 注意 排它锁指的是，在某个事务获取数据的排它锁后，其他事务不能获取该数据的任何锁， 并不代表其他事务不能无锁读取该数据。 无锁 select \u0026hellip; from 共享锁 select \u0026hellip; lock in share mode 排它锁 update delete insert select \u0026hellip; for update MySQL8.0 中，使用 FOR SHARE 替代了 LOCK IN SHARE MODE，但仍然支持 LOCK IN SHARE MODE； 虽然是等价的，但是 FOR SHARE 支持 NOWAIT 、 SKIP LOCKED 等，配合自旋，可以实现高效的等待队列。 3.2 乐观锁 \u0026amp; 悲观锁 不管是什么锁都需要增加，需加失败重试\n3.2.1 乐观锁 通过版本号来进行更新的操作属于乐观锁update tab set name = \u0026lsquo;xxx\u0026rsquo; where id = 1 and version = xxx 3.2.2 悲观锁 共享锁 \u0026amp; 排它锁都是悲观锁的具象实现\n显示地控制行或表锁属于悲观锁 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql%E9%94%81%E6%9C%BA%E5%88%B6/","summary":"宏观 数据库锁 数据库锁适用于集群 粒度小，更方便控制 代码锁 需要复杂的处理，才能作用于集群 粒度大 微观 行锁和表锁 说明 说明只有明确指定主键，才会执行锁","title":"MySQL锁机制"},{"content":"描述 给出一个整型数组 numbers 和一个目标值 target，请在数组中找出两个加起来等于目标值的数的下标，返回的下标按升序排列。\n（注：返回的数组下标从1开始算起，保证target一定可以由数组里面2个数字相加得到）\n示例1：\n输入： [3,2,4],6 返回值： [2,3] 说明： 因为 2+4=6 ，而 2的下标为2 ， 4的下标为3 ，又因为 下标2 \u0026lt; 下标3 ，所以返回[2,3] 答案：\nimport java.util.*; public class Solution { /** * 代码中的类名、方法名、参数名已经指定，请勿修改，直接返回方法规定的值即可 * * * @param numbers int整型一维数组 * @param target int整型 * @return int整型一维数组 */ public int[] twoSum (int[] numbers, int target) { // write code here Map\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; numbers.length; i++) { if (map.containsKey(target - numbers[i])) { return new int[] {map.get(target - numbers[i])+1, i+1}; } map.put(numbers[i], i); } return new int[] {0, 0}; } } ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E7%AE%97%E6%B3%95/nc61-%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/","summary":"描述 给出一个整型数组 numbers 和一个目标值 target，请在数组中找出两个加起来等于目标值的数的下标，返回的下标按升序排列。 （注：返回的数组下标从1","title":"NC61 两数之和"},{"content":"package java.lang; public class Object { private static native void registerNatives(); static { // 对象初始化时自动调用此方法 registerNatives(); } /** * 返回此对象的运行时类 * * @return The {@code Class} object that represents the runtime * class of this object. * @jls 15.8.2 Class Literals */ public final native Class\u0026lt;?\u0026gt; getClass(); /** * hashCode规定： * 1. 在java程序执行期间，在对同一个对象多次调用hashCode()方式时，必须一致地返回相同地整数， * 前提是将对象进行equals比较时所用到的信息没有被修改。从某一应用程序的一次执行到同一应用程序的另一次执行，该整数无需保持一致。 * 2. 如果根据equals(Object)方法确定两个对象是相等的，那么这两个对象调用hashCode()必须生成相同的整数结果。 * 3. 如果根据equals(Object)方法确定两个对象是不相等的，那么对这两个对象调用hashCode()不要求一定生成不同的结果。 * 但是，编程人员应该知道，为不同的对象生成不同的整数结果可以提高hash table的性能。 * 注意：hashCode()返回的不是对象的地址，而是对象的hash值，java.lang.System#identityHashCode可以返回对象的地址 * @return a hash code value for this object. * @see java.lang.Object#equals(java.lang.Object) * @see java.lang.System#identityHashCode */ public native int hashCode(); /** * 比较对象的地址 */ public boolean equals(Object obj) { return (this == obj); } /** * 用于克隆一个对象， 返回的结果满足如下等式： * 1.x.clone() != x * 2.x.clone().getClass() == x.getClass() * 3.!x.clone().equals(x) * 子类使用clone方法时，需要先实现Cloneable接口，否则会报java.lang.CloneNotSupportedException异常 * * 浅拷贝：拷贝地址引用，拷贝对象修改指向的内存中的值时，被拷贝对象指向内存中的值也会被修改，简单地浅拷贝：Object a = b; * 深拷贝：拷贝引用所指向内存中的值，拷贝对象修改指向的内存中的值时，被拷贝对象指向内存中的值不会被修改，简单地深拷贝：Object a = b.clone(); */ protected native Object clone() throws CloneNotSupportedException; /** * 默认返回如下格式 * getClass().getName() + \u0026#39;@\u0026#39; + Integer.toHexString(hashCode()) * * 一般通过重写获取想要的信息 */ public String toString() { return getClass().getName() + \u0026#34;@\u0026#34; + Integer.toHexString(hashCode()); } /** * 用于唤醒一个在因等待该对象（调用了wait方法）被处于等待状态（waiting 或 time_wait）的线程，该方法只能同步方法或同步块中调用。 * 该方法不能被重写。 */ public final native void notify(); /** * Wakes up all threads that are waiting on this object\u0026#39;s monitor. A * thread waits on an object\u0026#39;s monitor by calling one of the * {@code wait} methods. * \u0026lt;p\u0026gt; * The awakened threads will not be able to proceed until the current * thread relinquishes the lock on this object. The awakened threads * will compete in the usual manner with any other threads that might * be actively competing to synchronize on this object; for example, * the awakened threads enjoy no reliable privilege or disadvantage in * being the next thread to lock this object. * \u0026lt;p\u0026gt; * This method should only be called by a thread that is the owner * of this object\u0026#39;s monitor. See the {@code notify} method for a * description of the ways in which a thread can become the owner of * a monitor. * * @throws IllegalMonitorStateException if the current thread is not * the owner of this object\u0026#39;s monitor. * @see java.lang.Object#notify() * @see java.lang.Object#wait() */ public final native void notifyAll(); /** * Causes the current thread to wait until either another thread invokes the * {@link java.lang.Object#notify()} method or the * {@link java.lang.Object#notifyAll()} method for this object, or a * specified amount of time has elapsed. * \u0026lt;p\u0026gt; * The current thread must own this object\u0026#39;s monitor. * \u0026lt;p\u0026gt; * This method causes the current thread (call it \u0026lt;var\u0026gt;T\u0026lt;/var\u0026gt;) to * place itself in the wait set for this object and then to relinquish * any and all synchronization claims on this object. Thread \u0026lt;var\u0026gt;T\u0026lt;/var\u0026gt; * becomes disabled for thread scheduling purposes and lies dormant * until one of four things happens: * \u0026lt;ul\u0026gt; * \u0026lt;li\u0026gt;Some other thread invokes the {@code notify} method for this * object and thread \u0026lt;var\u0026gt;T\u0026lt;/var\u0026gt; happens to be arbitrarily chosen as * the thread to be awakened. * \u0026lt;li\u0026gt;Some other thread invokes the {@code notifyAll} method for this * object. * \u0026lt;li\u0026gt;Some other thread {@linkplain Thread#interrupt() interrupts} * thread \u0026lt;var\u0026gt;T\u0026lt;/var\u0026gt;. * \u0026lt;li\u0026gt;The specified amount of real time has elapsed, more or less. If * {@code timeout} is zero, however, then real time is not taken into * consideration and the thread simply waits until notified. * \u0026lt;/ul\u0026gt; * The thread \u0026lt;var\u0026gt;T\u0026lt;/var\u0026gt; is then removed from the wait set for this * object and re-enabled for thread scheduling. It then competes in the * usual manner with other threads for the right to synchronize on the * object; once it has gained control of the object, all its * synchronization claims on the object are restored to the status quo * ante - that is, to the situation as of the time that the {@code wait} * method was invoked. Thread \u0026lt;var\u0026gt;T\u0026lt;/var\u0026gt; then returns from the * invocation of the {@code wait} method. Thus, on return from the * {@code wait} method, the synchronization state of the object and of * thread {@code T} is exactly as it was when the {@code wait} method * was invoked. * \u0026lt;p\u0026gt; * A thread can also wake up without being notified, interrupted, or * timing out, a so-called \u0026lt;i\u0026gt;spurious wakeup\u0026lt;/i\u0026gt;. While this will rarely * occur in practice, applications must guard against it by testing for * the condition that should have caused the thread to be awakened, and * continuing to wait if the condition is not satisfied. In other words, * waits should always occur in loops, like this one: * \u0026lt;pre\u0026gt; * synchronized (obj) { * while (\u0026amp;lt;condition does not hold\u0026amp;gt;) * obj.wait(timeout); * ... // Perform action appropriate to condition * } * \u0026lt;/pre\u0026gt; * (For more information on this topic, see Section 3.2.3 in Doug Lea\u0026#39;s * \u0026#34;Concurrent Programming in Java (Second Edition)\u0026#34; (Addison-Wesley, * 2000), or Item 50 in Joshua Bloch\u0026#39;s \u0026#34;Effective Java Programming * Language Guide\u0026#34; (Addison-Wesley, 2001). * * \u0026lt;p\u0026gt;If the current thread is {@linkplain java.lang.Thread#interrupt() * interrupted} by any thread before or while it is waiting, then an * {@code InterruptedException} is thrown. This exception is not * thrown until the lock status of this object has been restored as * described above. * * \u0026lt;p\u0026gt; * Note that the {@code wait} method, as it places the current thread * into the wait set for this object, unlocks only this object; any * other objects on which the current thread may be synchronized remain * locked while the thread waits. * \u0026lt;p\u0026gt; * This method should only be called by a thread that is the owner * of this object\u0026#39;s monitor. See the {@code notify} method for a * description of the ways in which a thread can become the owner of * a monitor. * * @param timeout the maximum time to wait in milliseconds. * @throws IllegalArgumentException if the value of timeout is * negative. * @throws IllegalMonitorStateException if the current thread is not * the owner of the object\u0026#39;s monitor. * @throws InterruptedException if any thread interrupted the * current thread before or while the current thread * was waiting for a notification. The \u0026lt;i\u0026gt;interrupted * status\u0026lt;/i\u0026gt; of the current thread is cleared when * this exception is thrown. * @see java.lang.Object#notify() * @see java.lang.Object#notifyAll() */ public final native void wait(long timeout) throws InterruptedException; /** * Causes the current thread to wait until another thread invokes the * {@link java.lang.Object#notify()} method or the * {@link java.lang.Object#notifyAll()} method for this object, or * some other thread interrupts the current thread, or a certain * amount of real time has elapsed. * \u0026lt;p\u0026gt; * This method is similar to the {@code wait} method of one * argument, but it allows finer control over the amount of time to * wait for a notification before giving up. The amount of real time, * measured in nanoseconds, is given by: * \u0026lt;blockquote\u0026gt; * \u0026lt;pre\u0026gt; * 1000000*timeout+nanos\u0026lt;/pre\u0026gt;\u0026lt;/blockquote\u0026gt; * \u0026lt;p\u0026gt; * In all other respects, this method does the same thing as the * method {@link #wait(long)} of one argument. In particular, * {@code wait(0, 0)} means the same thing as {@code wait(0)}. * \u0026lt;p\u0026gt; * The current thread must own this object\u0026#39;s monitor. The thread * releases ownership of this monitor and waits until either of the * following two conditions has occurred: * \u0026lt;ul\u0026gt; * \u0026lt;li\u0026gt;Another thread notifies threads waiting on this object\u0026#39;s monitor * to wake up either through a call to the {@code notify} method * or the {@code notifyAll} method. * \u0026lt;li\u0026gt;The timeout period, specified by {@code timeout} * milliseconds plus {@code nanos} nanoseconds arguments, has * elapsed. * \u0026lt;/ul\u0026gt; * \u0026lt;p\u0026gt; * The thread then waits until it can re-obtain ownership of the * monitor and resumes execution. * \u0026lt;p\u0026gt; * As in the one argument version, interrupts and spurious wakeups are * possible, and this method should always be used in a loop: * \u0026lt;pre\u0026gt; * synchronized (obj) { * while (\u0026amp;lt;condition does not hold\u0026amp;gt;) * obj.wait(timeout, nanos); * ... // Perform action appropriate to condition * } * \u0026lt;/pre\u0026gt; * This method should only be called by a thread that is the owner * of this object\u0026#39;s monitor. See the {@code notify} method for a * description of the ways in which a thread can become the owner of * a monitor. * * @param timeout the maximum time to wait in milliseconds. * @param nanos additional time, in nanoseconds range * 0-999999. * @throws IllegalArgumentException if the value of timeout is * negative or the value of nanos is * not in the range 0-999999. * @throws IllegalMonitorStateException if the current thread is not * the owner of this object\u0026#39;s monitor. * @throws InterruptedException if any thread interrupted the * current thread before or while the current thread * was waiting for a notification. The \u0026lt;i\u0026gt;interrupted * status\u0026lt;/i\u0026gt; of the current thread is cleared when * this exception is thrown. */ public final void wait(long timeout, int nanos) throws InterruptedException { if (timeout \u0026lt; 0) { throw new IllegalArgumentException(\u0026#34;timeout value is negative\u0026#34;); } if (nanos \u0026lt; 0 || nanos \u0026gt; 999999) { throw new IllegalArgumentException( \u0026#34;nanosecond timeout value out of range\u0026#34;); } if (nanos \u0026gt; 0) { timeout++; } wait(timeout); } /** * Causes the current thread to wait until another thread invokes the * {@link java.lang.Object#notify()} method or the * {@link java.lang.Object#notifyAll()} method for this object. * In other words, this method behaves exactly as if it simply * performs the call {@code wait(0)}. * \u0026lt;p\u0026gt; * The current thread must own this object\u0026#39;s monitor. The thread * releases ownership of this monitor and waits until another thread * notifies threads waiting on this object\u0026#39;s monitor to wake up * either through a call to the {@code notify} method or the * {@code notifyAll} method. The thread then waits until it can * re-obtain ownership of the monitor and resumes execution. * \u0026lt;p\u0026gt; * As in the one argument version, interrupts and spurious wakeups are * possible, and this method should always be used in a loop: * \u0026lt;pre\u0026gt; * synchronized (obj) { * while (\u0026amp;lt;condition does not hold\u0026amp;gt;) * obj.wait(); * ... // Perform action appropriate to condition * } * \u0026lt;/pre\u0026gt; * This method should only be called by a thread that is the owner * of this object\u0026#39;s monitor. See the {@code notify} method for a * description of the ways in which a thread can become the owner of * a monitor. * * @throws IllegalMonitorStateException if the current thread is not * the owner of the object\u0026#39;s monitor. * @throws InterruptedException if any thread interrupted the * current thread before or while the current thread * was waiting for a notification. The \u0026lt;i\u0026gt;interrupted * status\u0026lt;/i\u0026gt; of the current thread is cleared when * this exception is thrown. * @see java.lang.Object#notify() * @see java.lang.Object#notifyAll() */ public final void wait() throws InterruptedException { wait(0); } /** * finalize()不同于C++的析构函数，发生GC(垃圾回收)时，finalize()会被调用，主要用于回收JNI(Java Native Interface)调用non-Java程序（C或C++）所使用到的内存 * 关于GC需要知道： * 1. 对象可能不被垃圾回收 * 2. 垃圾回收并不等于“析构” * 3. 垃圾回收只与内存有关 * 也就是说 */ protected void finalize() throws Throwable { } } ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/object%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","summary":"package java.lang; public class Object { private static native void registerNatives(); static { // 对象初始化时自动调用此方法 registerNatives(); } /** * 返回此对象的运行时类 * * @return The {@code Class} object that represents the runtime * class of this object. * @jls 15.8.2 Class Literals */ public final native Class\u0026lt;?\u0026gt; getClass(); /** *","title":"Object源码分析"},{"content":"背景 通过springboot整合Redission实现分布式锁\n可重入锁 可重入锁，也叫做递归锁，是指在一个线程中可以多次获取同一把锁，比如：一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行调用的方法【即可重入】，而无需重新获得锁；对于不同线程则相当于普通的互斥锁。\n为什么要用可重入锁，因为即时在单线程的环境下，方法直接互相调用是十分场景的，比如方法A调用方法B，方法B调用方法C，方法C调用方法A，那这个锁如果是\nRedission使用可重入锁 互斥锁测试：\n@Service public class RedisServiceImpl implements RedisService { private static final Logger logger = LoggerFactory.getLogger(RedisServiceImpl.class); @Autowired private RedissonClient redissonClient; @Override public void testLock() { logger.info(Thread.currentThread().getName()+\u0026#34;:begin\u0026#34;); RLock lock = redissonClient.getLock(\u0026#34;testLock\u0026#34;); try { lock(lock); } catch (InterruptedException e) { logger.error(\u0026#34;获取锁失败\u0026#34;); } finally { // lock.unlock(); logger.info(\u0026#34;end\u0026#34;); } } private void lock(RLock lock) throws InterruptedException { boolean result = lock.tryLock(5, 30, TimeUnit.SECONDS); logger.info(Thread.currentThread().getName()+\u0026#34;加锁结果：\u0026#34;+result); int holdCount = lock.getHoldCount(); String name = lock.getName(); logger.info(\u0026#34;当前线程加锁结果：\u0026#34;+name+\u0026#34;:\u0026#34;+holdCount); if(result) Thread.sleep(30000); } } 连续发出两次http请求，输出结果：\n2022-03-26 14:52:10.493 INFO 52327 --- [nio-8080-exec-3] c.lin.app.service.impl.RedisServiceImpl : http-nio-8080-exec-3:begin 2022-03-26 14:52:10.494 INFO 52327 --- [nio-8080-exec-3] c.lin.app.service.impl.RedisServiceImpl : http-nio-8080-exec-3加锁结果：true 2022-03-26 14:52:10.495 INFO 52327 --- [nio-8080-exec-3] c.lin.app.service.impl.RedisServiceImpl : 当前线程加锁结果：testLock:1 2022-03-26 14:52:14.187 INFO 52327 --- [nio-8080-exec-5] c.lin.app.service.impl.RedisServiceImpl : http-nio-8080-exec-5:begin 2022-03-26 14:52:19.192 INFO 52327 --- [nio-8080-exec-5] c.lin.app.service.impl.RedisServiceImpl : http-nio-8080-exec-5加锁结果：false 2022-03-26 14:52:19.205 INFO 52327 --- [nio-8080-exec-5] c.lin.app.service.impl.RedisServiceImpl : 当前线程加锁结果：testLock:0 2022-03-26 14:52:19.206 INFO 52327 --- [nio-8080-exec-5] c.lin.app.service.impl.RedisServiceImpl : end 2022-03-26 14:52:40.501 INFO 52327 --- [nio-8080-exec-3] c.lin.app.service.impl.RedisServiceImpl : end 可重入锁测试代码：\n@Service public class RedisServiceImpl implements RedisService { private static final Logger logger = LoggerFactory.getLogger(RedisServiceImpl.class); @Autowired private RedissonClient redissonClient; @Override public void testLock() { logger.info(Thread.currentThread().getName()+\u0026#34;:begin\u0026#34;); RLock lock = redissonClient.getLock(\u0026#34;testLock\u0026#34;); try { lock(lock); ((Runnable) () -\u0026gt; { try { lock(lock); } catch (InterruptedException e) { e.printStackTrace(); } }).run(); } catch (InterruptedException e) { logger.error(\u0026#34;获取锁失败\u0026#34;); } finally { logger.info(\u0026#34;end\u0026#34;); } } private void lock(RLock lock) throws InterruptedException { boolean result = lock.tryLock(5, 30, TimeUnit.SECONDS); logger.info(Thread.currentThread().getName()+\u0026#34;加锁结果：\u0026#34;+result); int holdCount = lock.getHoldCount(); String name = lock.getName(); logger.info(\u0026#34;当前线程加锁结果：\u0026#34;+name+\u0026#34;:\u0026#34;+holdCount); if(result) Thread.sleep(30000); } } 输出结果：\n2022-03-26 15:07:00.403 INFO 52581 --- [nio-8080-exec-2] c.lin.app.service.impl.RedisServiceImpl : http-nio-8080-exec-2:begin 2022-03-26 15:07:00.415 INFO 52581 --- [nio-8080-exec-2] c.lin.app.service.impl.RedisServiceImpl : http-nio-8080-exec-2加锁结果：true 2022-03-26 15:07:00.416 INFO 52581 --- [nio-8080-exec-2] c.lin.app.service.impl.RedisServiceImpl : 当前线程加锁结果：testLock:1 2022-03-26 15:07:00.437 INFO 52581 --- [nio-8080-exec-2] c.lin.app.service.impl.RedisServiceImpl : http-nio-8080-exec-2加锁结果：true 2022-03-26 15:07:00.438 INFO 52581 --- [nio-8080-exec-2] c.lin.app.service.impl.RedisServiceImpl : 当前线程加锁结果：testLock:2 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/redission%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E6%88%98/","summary":"背景 通过springboot整合Redission实现分布式锁 可重入锁 可重入锁，也叫做递归锁，是指在一个线程中可以多次获取同一把锁，比如：一","title":"Redission分布式锁实战"},{"content":"setnx key value 只在键 key 不存在的情况下， 将键 key 的值设置为 value 。若键 key 已经存在， 则 SETNX 命令不做任何动作。SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写。\n返回值 命令在设置成功时返回 1 ， 设置失败时返回 0 。\n代码示例 redis\u0026gt; EXISTS job # job 不存在 (integer) 0 redis\u0026gt; SETNX job \u0026#34;programmer\u0026#34; # job 设置成功 (integer) 1 redis\u0026gt; SETNX job \u0026#34;code-farmer\u0026#34; # 尝试覆盖 job ，失败 (integer) 0 redis\u0026gt; GET job # 没有被覆盖 \u0026#34;programmer\u0026#34; 设计礼品领取的架构设计以及多次领取现象解决？ 如果出现网络延迟的情况下，多个请求阻塞，那么恶意攻击就可以全部请求领取接口成功，而针对这种做法，我们使用setnx来解决，确保只有一个请求可以进入接口请求。 下面，我们就专门讲解一下setnx，setnx可以用作分布式锁，但是这个场景并不是分布式锁的一个较好的实践，因为每个用户的key都是不一样的，我们主要是防止同一个用户恶意领取，setnx本身是一个原子操作，可以保证多个线程只有一个能拿到锁，能返回true,其他的都会返回false。但是上面的做法，没有设置过期时间，在生产上一般是不可以这么使用。不设置过期时间的key多了之后，redis服务器很容易内存打满，这时候不知道哪些是强制依赖的，只能扩容，从代码层面去清理，如果直接清理不常用的，也很难保证不出事。（基本不允许这么干，除非是基础数据，跟着服务器启动，写入redis的，不会变更的，比如城市数据，国家数据等等，当然，这些也可以考虑在本地内存中实现）如果在上面的代码中，加入超时时间，假设是一个月或者半年，流程变成这样： 设置key的超时时间使用expire,但是这样还有缺陷么？在redis 2.6.12之前，setnx和expire都不是原子操作，也就是很有可能在setnx成功之后，expire设置失败，也就不会有超时时间了。虽然这个影响在当前业务不是很大，但是还是一个小缺陷。Redis2.6.12以上版本，可以用set获取锁,set包含setnx和expire，实现了原子操作。也就是两步要么一起成功，要么一起失败。除此之外，上面的流程可能还存在的一个问题，是请求C服务的时候出现超时，然后删除key，恰好这个时候redis有问题，删除失败了，这个key就永远存在了。表现在业务上，就是A用户点击了领取，领取失败了，但是后面再怎么点，都是已经领取的状态了。那这种现象怎么优化呢？这种情况，其实已经是很少见的情况，按照我们当前的业务场景也看，就是当前的用户，redis记录了它已经领取过了，但是由于接口的失败，成功之后还没将mysql/其他数据库更新,两个数据库不一致了。我能想到的一个方法，就是再删除失败的时候，告警，并且将业务相关的数据记录下来，比如key，uid等等，针对这部分数据，做一次补发，或者手动删除key。或者，启动一个定时任务或者lua脚本，去判定redis和数据库不一致的情况，但是切记不要全部查询，应该是隔一段时间，查询最后增加的部分，做一个校验以及相应的处理。枚举key是十分耗时的操作！！！setnx 除了解决上面的问题，还可以应用在解决缓存击穿的问题上。譬如现在有热点数据，不仅在mysql数据库存储了，还在redis中存了一份缓存，那么如果有一个时间点，缓存失效了，这时候，大量的请求打过来，同时到达，缓存拿不到数据，都去数据库取数据，假设数据库操作比较耗时，那么压力全都在数据库服务器上了。这个时候所有的请求都去更新数据，明显是不合适的，应该是使用分布式锁，让一个线程去请求mysql一次即可。但是为了避免死锁的情况，如果超时，得及时额外释放锁，要不可能请求mysql都失败了，其他线程又拿不到锁，那么数据就会一直为null了。可以使用以下的命令：SETNX lock.foo \u0026lt;current Unix time + lock timeout + 1\u0026gt;\n","permalink":"https://luolin1024.github.io/blog_prepublish/pre-publish/redis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81setnx/","summary":"setnx key value 只在键 key 不存在的情况下， 将键 key 的值设置为 value 。若键 key 已经存在， 则 SETNX 命令不做任何动作。SETNX 是『SET if Not eXists』(如果不存在，","title":"redis实现分布式锁——setnx"},{"content":"RestFul是什么？ REST是REpresentational State Transfer的缩写（表述性状态转移），REST是一种体系结构。简单的说，REST就是将资源的状态以合适客户端或服务端的形式从服务端转移到客户端（或者反过来）。在REST中，资源通过 URL 进行识别和定位，然后通过不同的 action（既HTTP方法，GET等） 来定义REST应该完成的功能。\n在实际的web开发中，CRUD动作与HTTP方法的匹配一般如下：\nCRUD动作 HTTP方法 Create POST Read GET Update PUT或PATCH Delete DELETE 上述匹配不是绝对的，可以根据需要进行改动，但一般情况这样写比较好。\n在使用RESTful风格之前，如果想要增加一条商品数据，通常写法是这样的：\n/addCategory?name=xxx 但是使用RESTful之后，就会变成这样：\n/category (请求方式为POST即可) 这就是使用同一个URL，但是通过约定不同的HTTP方法对应不同的CRUD动作来实现不同的业务。\n下面再写一个具体的RESTful的API实现：\n请求类型 URL 功能说明 GET /users 查询用户列表 POST /users 创建一个用户 GET /user/id 根据id查询一个用户的数据 PUT /user/id 根据id更新一个用户的数据 DELETE /user/id 根据id删除一个用户数据 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/restful%E9%A3%8E%E6%A0%BCapi/","summary":"RestFul是什么？ REST是REpresentational State Transfer的缩写（表述性状态转移），REST是一种体系结构。简单的说","title":"RestFul风格API"},{"content":"Spring\u0026amp; Spring Cloud基础使用 [[feign、ribbon、hystrix分析]]\n[[Spring组件]] [[Spring事务以及事务嵌套]] [[Spring中利用AOP使用自定义注解]] [[Spring中Bean的生命周期]] [[SpringBoot异步线程]] [[SpringBoot事务自定义提交后执行]] [[SpringBoot yaml日志级别配置]]\n[[Spring 中当前类方法调用本类其他方法注意事项]] [[Spring Bean初始化]] [[Spring AOP注解常见问题]] [[Redission分布式锁实战]]\n源码阅读 [[Spring5 源码阅读环境搭建]] [[Spring结构组成]]\nSpring常见问题 [[Feign调用接口报错情况分析]] [[循环依赖和Spring循环依赖]] [[记一次事务的坑：Transaction rolled back because it has been marked as rollback-only]]\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/spring/","summary":"Spring\u0026amp; Spring Cloud基础使用 [[feign、ribbon、hystrix分析]] [[Spring组件]] [[Spring事务以及事务嵌套]] [[S","title":"Spring"},{"content":"[[Java动态代理]] [[Java注解与自定义注解]] [[Spring中利用AOP使用自定义注解]]\n使用 @Transactional , @Async 等Spring AOP注解不生效 问题背景 public class ServiceImpl implements Service{ // funA是接口暴露方法 @Override public void funA(){ try{ funA(); }catch(Exception e){ Logger.infor(e); } } // funB是接口暴露方法 @Override @Transactional(rollbackFor = Exception.class) public void funB(){ // 执行计算逻辑 funC(); } public void funC(){ insertIntoHeader(); // 计算逻辑... try{ // 计算出错 }catch(Exception e){ // 执行catch代码块 throw new CommonException(\u0026#34;xxxx\u0026#34;); } insertIntoLine(); } } 以上代码出现了header插入成功，但是计算出错导致line插入失败的结果，分析过后发现其实是调用的时候没有使用动态代理对象来调用funB()导致funB()上面的 @Transactional(rollbackFor = Exception.class) 失效，从而使得整个 funA-\u0026gt;funB-\u0026gt;funC 流程都没有被spring事务管理器管理起来。写到这里，就必须把spring的AOP机制原理以及spring的aop常见问题记录下来了：首先必须要记住的一个点就是spring的AOP是通过动态代理完成，其次就是spring aop注解失效以及解决方案。\n解释说明 通常情况，会出现Spring AOP注解失效主要是因为在同一个类中，funA调用给了funB（funB上加有注解），此时注解不生效。 针对所有的Spring AOP注解，Spring在扫描bean的时候发现有AOP注解，那么会动态的构造一个代理对象\n如果是想要通过类的对象（通过spring依赖注入）直接调用其中带注解的funA时，此时funA的注解生效，因为此时spring会使用类的代理对象调用funA 假设类中的funA调用带有AOP注解的funB，而我们是通过对象（通过Spring依赖注入）调用funA的，那么funB上的注解是不生效的，因为此时调用funB使用的是原对象，而非代理对象，那么A在调用B时，在原对象内funB的注解当然时无效的。 解决方案： 把两个方法放到不同的类中 通过获取当前动态代理对象调用funcB：((X)AopContext.currentProxy()).B() springboot下的分布式锁执行顺序 切面之间使用older注解，区分调用顺序，Order值越小,那么切面越先执行(越后结束) 不指定Order,那么Order是默认值-\u0026gt;Integer.MAX_VALUE. 如果Order相同,则是按照切面字母的顺序来执行切面.比如@Transactional和@Cacheable-\u0026gt;对应的切面是TransactionInterceptor和CacheInterceptor,则先执行@Cacheable的切面 @Transactional也是通过切面实现，Order值是Integer.MAX_VALUE。（如果在service方法上同时添加带order的日志注解，在日志切面after里面报错，不会回滚事务） @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Import({TransactionManagementConfigurationSelector.class}) public @interface EnableTransactionManagement { boolean proxyTargetClass() default false; AdviceMode mode() default AdviceMode.PROXY; int order() default 2147483647; } ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/spring-aop%E6%B3%A8%E8%A7%A3%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","summary":"[[Java动态代理]] [[Java注解与自定义注解]] [[Spring中利用AOP使用自定义注解]] 使用 @Transactional , @Async 等Spring AOP注解不生","title":"Spring AOP注解常见问题"},{"content":" scan\u0026mdash;beanDefinition\u0026mdash;-map 遍历map validate 得到class 推断构造方法 反射 实例化这个对象 合并beanDefinition 提前暴露一个bean工厂对象 填充属性\u0026mdash;自动注入 \u0026mdash;部分aware接口 执行\u0026mdash;部分aware接口 执行spring生命周期回调方法 接口版的生命周期回调方法 beanPostprocessor的前置方法\u0026mdash;aop put 单例池 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/spring-bean%E5%88%9D%E5%A7%8B%E5%8C%96/","summary":"scan\u0026mdash;beanDefinition\u0026mdash;-map 遍历map validate 得到class 推断构造方法 反射 实例化这个对象 合并beanDefinition 提前暴露一个bean工厂对象 填充属性\u0026mdash;","title":"Spring Bean初始化"},{"content":" 加入存在类AServiceImpl中存在方法a()，没有事务注解（没有被spring事务管理管理），调用本类中方法b(),而b()是使用了事务注解的，也就是说a没有被事务管理器管理，b被事务管理器管理，此时如果使用this.b()调用b方法则b中的事务会失效 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/spring-%E4%B8%AD%E5%BD%93%E5%89%8D%E7%B1%BB%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E6%9C%AC%E7%B1%BB%E5%85%B6%E4%BB%96%E6%96%B9%E6%B3%95%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","summary":"加入存在类AServiceImpl中存在方法a()，没有事务注解（没有被spring事务管理管理），调用本类中方法b(),而b()是使用了事","title":"Spring 中当前类方法调用本类其他方法注意事项"},{"content":"这一阵子在读spring源码，但是网上的文章，构建spring源码大都有问题，导致我构建源码的时候出现了很多问题，所以我自己重新构建了一下。\n本机环境 win10 + jdk1.8.0_151 + IntelliJ IDEA 2019.1.3spring使用的是5.0版本（下面介绍的方法在5.0和5.1下都可以成功）\n源码构建 在cmd命令框下进入源码目录，使用命令： gradlew :spring-oxm:compileTestJava 网上很多文章都说这里要下载gradle，其实是可以不用的，输入这个指令之后会自己下载的（亲测），截图如下（中间可能会出错，十有八九是网络问题，建议挂vpn，或者多试几次）\n最好再预编译一下 gradlew :spring-core:compileTestJava： 打开Intellij IDEA，依次选择File -\u0026gt; New -\u0026gt; Project from Existing Sources -\u0026gt; spring项目根目录 -\u0026gt; 选择 build.gradle，然后如下图，一路ok即可。 点击完finish之后会要等待一段时间，看个人网速，大概20分钟吧，构建成功后的结果如下图所示，如果中间有什么问题就直接点击idea左边的刷新试试（这里我没有出过问题..）。 其实到了这一步已经差不多完成了，只不过后面如果要使用到spring源码还得接着往下看 新建module： 添加spring-context依赖： 新建MyConfig类和Main类用来测试 ```java @Configuration public class MyConfig { } public class Main { public static void main(String[] args) { AnnotationConfigApplicationContext ac = new AnnotationConfigApplicationContext(MyConfig.class); System.out.println(ac); } } 点击运行，此时会出现错误如下，原因是spring-context中没有添加spring-instrument依赖\n3. ![](./assets/1596509440296-0413f80e-bad7-46ee-befb-9fbfd0e2dfd1.jpeg) 只需要在spring-context模块中的gradle配置文件中添加依赖即可：![](./assets/1596509438533-ad0b85e1-2c9f-402b-b0a9-c363b7697990.jpeg) 此时再次运行即可成功：![](./assets/1596509438540-69efe5b5-0119-4363-bd93-97f00a4e2e6a.jpeg) 3. **注意**：后面如果需要使用aspects模块的时候，需要先将这个模块unload。 spring-framework\\gradle\\wrapper\\gradle-wrapper.properties 记录了对应gradle版本 编译的过程中报错：需要修改build.gradle中的： ```kotlin compileKotlin { kotlinOptions { jvmTarget = \u0026#34;1.8\u0026#34; freeCompilerArgs = [\u0026#34;-Xjsr305=strict\u0026#34;] apiVersion = \u0026#34;1.4\u0026#34; languageVersion = \u0026#34;1.4\u0026#34; } } 遇到报错： 需要在自己的模块中添加依赖spring-instrument：\ndependencies { compile(project(\u0026#34;:spring-context\u0026#34;)) compile(project(\u0026#34;:spring-instrument\u0026#34;)) } 2021版本idea 编码可参考：https://blog.csdn.net/chuanchengdabing/article/details/115330718\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/spring5-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","summary":"这一阵子在读spring源码，但是网上的文章，构建spring源码大都有问题，导致我构建源码的时候出现了很多问题，所以我自己重新构建了一下。","title":"Spring5 源码阅读环境搭建"},{"content":"问题背景 [[记一次事务的坑：Transaction rolled back because it has been marked as rollback-only]]\n源码分析 @Nullable protected Object invokeWithinTransaction(Method method, @Nullable Class\u0026lt;?\u0026gt; targetClass, final InvocationCallback invocation) throws Throwable { // If the transaction attribute is null, the method is non-transactional. TransactionAttributeSource tas = getTransactionAttributeSource(); final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null); final PlatformTransactionManager tm = determineTransactionManager(txAttr); final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) { // Standard transaction demarcation with getTransaction and commit/rollback calls. TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification); Object retVal = null; try { // This is an around advice: Invoke the next interceptor in the chain. // This will normally result in a target object being invoked. retVal = invocation.proceedWithInvocation(); } catch (Throwable ex) { // aop对应目标方法报错 completeTransactionAfterThrowing(txInfo, ex); throw ex; } finally { cleanupTransactionInfo(txInfo); } // aop对应目标方法正常执行进行事务提交 commitTransactionAfterReturning(txInfo); return retVal; } else { final ThrowableHolder throwableHolder = new ThrowableHolder(); // It\u0026#39;s a CallbackPreferringPlatformTransactionManager: pass a TransactionCallback in. try { Object result = ((CallbackPreferringPlatformTransactionManager) tm).execute(txAttr, status -\u0026gt; { TransactionInfo txInfo = prepareTransactionInfo(tm, txAttr, joinpointIdentification, status); try { return invocation.proceedWithInvocation(); } catch (Throwable ex) { if (txAttr.rollbackOn(ex)) { // A RuntimeException: will lead to a rollback. if (ex instanceof RuntimeException) { throw (RuntimeException) ex; } else { throw new ThrowableHolderException(ex); } } else { // A normal return value: will lead to a commit. throwableHolder.throwable = ex; return null; } } finally { cleanupTransactionInfo(txInfo); } }); // Check result state: It might indicate a Throwable to rethrow. if (throwableHolder.throwable != null) { throw throwableHolder.throwable; } return result; } catch (ThrowableHolderException ex) { throw ex.getCause(); } catch (TransactionSystemException ex2) { if (throwableHolder.throwable != null) { logger.error(\u0026#34;Application exception overridden by commit exception\u0026#34;, throwableHolder.throwable); ex2.initApplicationException(throwableHolder.throwable); } throw ex2; } catch (Throwable ex2) { if (throwableHolder.throwable != null) { logger.error(\u0026#34;Application exception overridden by commit exception\u0026#34;, throwableHolder.throwable); } throw ex2; } } } 异常aop： org.springframework.transaction.interceptor.TransactionAspectSupport#invokeWithinTransaction -\u0026gt;org.springframework.transaction.interceptor.TransactionAspectSupport#completeTransactionAfterThrowing -\u0026gt;org.springframework.transaction.support.AbstractPlatformTransactionManager#rollback -\u0026gt;org.springframework.transaction.support.AbstractPlatformTransactionManager#processRollback\n正常提交aop org.springframework.transaction.interceptor.TransactionAspectSupport#invokeWithinTransaction -\u0026gt;org.springframework.transaction.interceptor.TransactionAspectSupport#commitTransactionAfterReturning -\u0026gt;org.springframework.transaction.support.AbstractPlatformTransactionManager#commit -\u0026gt;org.springframework.transaction.support.AbstractPlatformTransactionManager#processRollback\n@Override public final void commit(TransactionStatus status) throws TransactionException { if (status.isCompleted()) { throw new IllegalTransactionStateException( \u0026#34;Transaction is already completed - do not call commit or rollback more than once per transaction\u0026#34;); } DefaultTransactionStatus defStatus = (DefaultTransactionStatus) status; if (defStatus.isLocalRollbackOnly()) { if (defStatus.isDebug()) { logger.debug(\u0026#34;Transactional code has requested rollback\u0026#34;); } processRollback(defStatus, false); return; } if (!shouldCommitOnGlobalRollbackOnly() \u0026amp;\u0026amp; defStatus.isGlobalRollbackOnly()) { if (defStatus.isDebug()) { logger.debug(\u0026#34;Global transaction is marked as rollback-only but transactional code requested commit\u0026#34;); } processRollback(defStatus, true); return; } processCommit(defStatus); } private void processRollback(DefaultTransactionStatus status, boolean unexpected) { try { boolean unexpectedRollback = unexpected; try { triggerBeforeCompletion(status); if (status.hasSavepoint()) { if (status.isDebug()) { logger.debug(\u0026#34;Rolling back transaction to savepoint\u0026#34;); } status.rollbackToHeldSavepoint(); } else if (status.isNewTransaction()) { if (status.isDebug()) { logger.debug(\u0026#34;Initiating transaction rollback\u0026#34;); } doRollback(status); } else { // Participating in larger transaction if (status.hasTransaction()) { if (status.isLocalRollbackOnly() || isGlobalRollbackOnParticipationFailure()) { if (status.isDebug()) { logger.debug(\u0026#34;Participating transaction failed - marking existing transaction as rollback-only\u0026#34;); } // 对当前事务设置RollbackOnly=true doSetRollbackOnly(status); } else { if (status.isDebug()) { logger.debug(\u0026#34;Participating transaction failed - letting transaction originator decide on rollback\u0026#34;); } } } else { logger.debug(\u0026#34;Should roll back transaction but cannot - no transaction available\u0026#34;); } // Unexpected rollback only matters here if we\u0026#39;re asked to fail early if (!isFailEarlyOnGlobalRollbackOnly()) { unexpectedRollback = false; } } } catch (RuntimeException | Error ex) { triggerAfterCompletion(status, TransactionSynchronization.STATUS_UNKNOWN); throw ex; } triggerAfterCompletion(status, TransactionSynchronization.STATUS_ROLLED_BACK); // Raise UnexpectedRollbackException if we had a global rollback-only marker if (unexpectedRollback) { throw new UnexpectedRollbackException( \u0026#34;Transaction rolled back because it has been marked as rollback-only\u0026#34;); } } finally { cleanupAfterCompletion(status); } } org.springframework.transaction.interceptor.TransactionAspectSupport#invokeWithinTransaction\n解决方案 捕获异常时，手动设置上层事务状态为 rollback 状态 @Override @Transactional(rollbackFor = Exception.class) public void testRollbackOnly() { String transactionName = TransactionSynchronizationManager.getCurrentTransactionName(); logger.info(\u0026#34;com.lin.app.service.impl.TransactionalServiceImpl.testRollbackOnly:\u0026#34; + transactionName); try { self().rollbackOnlyA(); } catch (Exception e) { logger.error(\u0026#34;com.lin.app.service.impl.TransactionalServiceImpl.testRollbackOnly.error\u0026#34;, e); } if (TransactionAspectSupport.currentTransactionStatus().isRollbackOnly()) { TransactionAspectSupport.currentTransactionStatus().setRollbackOnly(); logger.error(\u0026#34;com.lin.app.service.impl.TransactionalServiceImpl.testRollbackOnly.isRollbackOnly\u0026#34;); } Order order = new Order(\u0026#34;ORDER\u0026#34; + \u0026#34;test\u0026#34;); orderMapper.insertSelective(order); } 修改事务传播机制，比如说将内层事务的传播方式指定为@Transactional(propagation= Propagation.NESTED)，外层事务的提交和回滚能够控制嵌套的内层事务回滚；而内层事务报错时，只回滚内层事务，外层事务可以继续提交。但尝试Propagation.NESTED与 Hibernate JPA 一起使用将导致 Spring 异常：JpaDialect does not support savepoints - check your JPA provider's capabilities,这是因为 Hibernate JPA 不支持嵌套事务。可以考虑用 Propagation.REQUIRES_NEW 代替一下。 如果这个异常发生时，内层需要事务回滚的代码还没有执行，则可以@Transactional(noRollbackFor = {内层抛出的异常}.class)，指定内层也不为这个异常回滚。 取消内层方法的@Transactional 注解 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/springboot%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E7%9C%8B%E8%BF%99%E7%AF%87%E5%B0%B1%E5%A4%9F%E4%BA%86/","summary":"问题背景 [[记一次事务的坑：Transaction rolled back because it has been marked as rollback-only]] 源码分析 @Nullable protected Object invokeWithinTransaction(Method method, @Nullable Class\u0026lt;?\u0026gt; targetClass, final InvocationCallback invocation) throws Throwable { // If the transaction attribute is null, the method is non-transactional. TransactionAttributeSource tas = getTransactionAttributeSource(); final TransactionAttribute txAttr","title":"Springboot事务管理看这篇就够了"},{"content":"背景 在SpringBoot通常会使用到事务注解快速启动一个事务，但是在一个大型项目中，往往会存在一些流程上的逻辑需要在事务提交之后新启一个方法执行逻辑，比如避免后续逻辑报错影响前面执行的db操作进行事务回滚，伪代码如下：\n@Transactional void funcA(){ funcDB(); // do some db process logger.info(\u0026#34;do some db process\u0026#34;); TransactionSynchronizationManager.registerSynchronization( new TransactionSynchronizationAdapter() { @Override public void afterCommit() { serviceImpl.funcB(); } } ); funcC(); // do some db process } 按照上述代码的执行，整个方法的执行顺序如下： @Transactional切面 -\u0026gt; funcDB()-\u0026gt;funcC() -\u0026gt; 切面后置环绕：afterCommit();\n源码分析 DataSourceTransactionManager 的实现 public class DataSourceTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, InitializingBean { /** 持有 javax.sql.DataSource对象 */ private DataSource dataSource; /** * 这里是产生 Transaction对象 的地方，为 Transaction 的创建提供服务，对数据库而言， * 事务工作是由 Connection 来完成的。这里把数据库的 Connection对象 放到了 ConnectionHolder 中， * 然后封装到一个 DataSourceTransactionObject对象 中，在这个封装过程中增加了许多为事务处理服务的 * 控制数据 */ @Override protected Object doGetTransaction() { DataSourceTransactionObject txObject = new DataSourceTransactionObject(); txObject.setSavepointAllowed(isNestedTransactionAllowed()); // 获取与当前线程绑定的数据库Connection，这个 Connection 在第一个事务开始 // 的地方与线程绑定 ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(this.dataSource); txObject.setConnectionHolder(conHolder, false); return txObject; } /** * 判断是否存在活跃的事务，由ConnectionHolder的transactionActive属性 来控制 */ @Override protected boolean isExistingTransaction(Object transaction) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; return (txObject.getConnectionHolder() != null \u0026amp;\u0026amp; txObject.getConnectionHolder().isTransactionActive()); } /** * 这里是处理事务开始的地方，在这里设置隔离级别，但忽略超时 */ @Override protected void doBegin(Object transaction, TransactionDefinition definition) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; Connection con = null; try { if (txObject.getConnectionHolder() == null || txObject.getConnectionHolder().isSynchronizedWithTransaction()) { Connection newCon = this.dataSource.getConnection(); if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Acquired Connection [\u0026#34; + newCon + \u0026#34;] for JDBC transaction\u0026#34;); } txObject.setConnectionHolder(new ConnectionHolder(newCon), true); } txObject.getConnectionHolder().setSynchronizedWithTransaction(true); con = txObject.getConnectionHolder().getConnection(); Integer previousIsolationLevel = DataSourceUtils.prepareConnectionForTransaction(con, definition); txObject.setPreviousIsolationLevel(previousIsolationLevel); // 这里是 数据库Connection 完成事务处理的重要配置，需要把 autoCommit属性 关掉 if (con.getAutoCommit()) { txObject.setMustRestoreAutoCommit(true); if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Switching JDBC Connection [\u0026#34; + con + \u0026#34;] to manual commit\u0026#34;); } con.setAutoCommit(false); } txObject.getConnectionHolder().setTransactionActive(true); int timeout = determineTimeout(definition); if (timeout != TransactionDefinition.TIMEOUT_DEFAULT) { txObject.getConnectionHolder().setTimeoutInSeconds(timeout); } // 把当前的 数据库Connection 与线程绑定 if (txObject.isNewConnectionHolder()) { TransactionSynchronizationManager.bindResource(getDataSource(), txObject.getConnectionHolder()); } } catch (Throwable ex) { DataSourceUtils.releaseConnection(con, this.dataSource); throw new CannotCreateTransactionException(\u0026#34;Could not open JDBC Connection for transaction\u0026#34;, ex); } } /** * 事务提交的具体实现 */ @Override protected void doCommit(DefaultTransactionStatus status) { // 取得 Connection 以后，通过Connection 进行提交 DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); Connection con = txObject.getConnectionHolder().getConnection(); if (status.isDebug()) { logger.debug(\u0026#34;Committing JDBC transaction on Connection [\u0026#34; + con + \u0026#34;]\u0026#34;); } try { con.commit(); } catch (SQLException ex) { throw new TransactionSystemException(\u0026#34;Could not commit JDBC transaction\u0026#34;, ex); } } /** * 事务提交的具体实现，通过 Connection对象 的 rollback()方法 实现 */ @Override protected void doRollback(DefaultTransactionStatus status) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); Connection con = txObject.getConnectionHolder().getConnection(); if (status.isDebug()) { logger.debug(\u0026#34;Rolling back JDBC transaction on Connection [\u0026#34; + con + \u0026#34;]\u0026#34;); } try { con.rollback(); } catch (SQLException ex) { throw new TransactionSystemException(\u0026#34;Could not roll back JDBC transaction\u0026#34;, ex); } } } 相关问题： [[记一次事务的坑：Transaction rolled back because it has been marked as rollback-only]] [[Spring中利用AOP使用自定义注解]]\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/springboot%E4%BA%8B%E5%8A%A1%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8F%90%E4%BA%A4%E5%90%8E%E6%89%A7%E8%A1%8C/","summary":"背景 在SpringBoot通常会使用到事务注解快速启动一个事务，但是在一个大型项目中，往往会存在一些流程上的逻辑需要在事务提交之后新启一个方","title":"SpringBoot事务自定义提交后执行"},{"content":"线程池参数含义:\ncorePoolSize：核心线程数 核心线程会一直存活，及时没有任务需要执行 当线程数小于核心线程数时，即使有线程空闲，线程池也会优先创建新线程处理 设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭 queueCapacity：任务队列容量（阻塞队列） 当核心线程数达到最大时，新任务会放在队列中排队等待执行 maxPoolSize：最大线程数 当线程数\u0026gt;=corePoolSize，且任务队列已满时。线程池会创建新线程来处理任务 当线程数=maxPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常 keepAliveTime：线程空闲时间 当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量=corePoolSize 如果allowCoreThreadTimeout=true，则会直到线程数量=0 allowCoreThreadTimeout：允许核心线程超时 rejectedExecutionHandler：任务拒绝处理器 两种情况会拒绝处理任务： 当线程数已经达到maxPoolSize，切队列已满，会拒绝新任务 当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务 线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置默认是AbortPolicy，会抛出异常 ThreadPoolExecutor类有几个内部实现类来处理这类情况： AbortPolicy 丢弃任务，抛运行时异常 CallerRunsPolicy 执行任务 DiscardPolicy 忽视，什么都不会发生 DiscardOldestPolicy 从队列中踢出最先进入队列（最后一个执行）的任务 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/springboot%E5%BC%82%E6%AD%A5%E7%BA%BF%E7%A8%8B/","summary":"线程池参数含义: corePoolSize：核心线程数 核心线程会一直存活，及时没有任务需要执行 当线程数小于核心线程数时，即使有线程空闲，线程池","title":"SpringBoot异步线程"},{"content":"SpringCloud简介 Spring Cloud是一系列框架的有序集合。它利用SpringBoot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务注册中心、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用SpringBoot的开发风格做到一键启动和部署。SpringCloud将目前各家公司开发的比较成熟、经得起考验的服务框架组合起来，通过SpringBoot风格进行再封装屏蔽掉复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。微服务是可以独立部署、水平扩展、独立访问（或者有独立的数据库）的服务单元，springcloud就是这些微服务的大管家，采用了微服务这种架构之后，项目的数量会非常多，springcloud需要管理好这些微服务。\n本文主要将通过手动搭建一个Spring Cloud分布式项目学习SpringCloud中的各个组件。\n本文采用Idea搭建SpringCloud项目，文中使用的工程和服务都是整个项目的模块。结构类如下： Maven主工程 基于对maven依赖管理的考虑，新建一个maven主工程，主要用来约定整个工程项目中的所有服务使用到的依赖版本。新建服务spring-cloud-parent，pom.xml如下\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.2.RELEASE\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.lin\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;project.reporting.outputEncoding\u0026gt;UTF-8\u0026lt;/project.reporting.outputEncoding\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;spring-cloud.version\u0026gt;Hoxton.SR6\u0026lt;/spring-cloud.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; *注意：本文后续所有服务pom.xml中的都使用如下配置\n\u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;com.lin\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; 服务注册与发现——Eureka SpringCloud中的所有服务之间的交互都是基于注册中心，这里就用Eureka注册中心组件搭建服务。\n注册中心 首先新建一个eureka-server服务，需要额外添加依赖spring-cloud-starter-netflix-eureka-server\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-eureka-server\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 启动一个服务注册中心只需要在Springboot启动类上添加一个注解@EnableEurekaServer\n@SpringBootApplication @EnableEurekaServer public class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); } } 另外，我们还需要配置eureka使用的端口，registerWithEureka和fetchRegistry来标明这是一个eureka-server服务，配置好serviceUrl.defaultZone, application.yml文件内容如下：\nserver: port: 8761 eureka: instance: hostname: localhost client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 现在eureka-server服务已经配置完成，接下来就只要启动注册中心服务就好了。使用浏览器访问http://localhost:8761/ 可以看到如下界面 服务提供者和服务消费者 其实相对eureka-server服务来说，其他的eureka-client服务本身既可以是服务提供者，也可以是服务消费者，所以我们把spring-cloud-starter-netflix-eureka-client和spring-boot-starter-web添加到parent主工程中，新建一个service-hi服务，\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-eureka-client\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 添加完依赖之后在SpringBoot启动类中添加 @EnableDiscoveryClient :\n@SpringBootApplication @EnableDiscoveryClient public class ServiceHiApplication { public static void main(String[] args) { SpringApplication.run(ServiceHiApplication.class, args); } } 接着需要配置spring.application.name和需要注册到eureka的地址eureka.client.serviceUrl.defaultZone, application.yml内容如下：\nserver: port: 8762 eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ spring: application: name: service-a 添加一个Controller接口提供给其他服务，HelloController类：\n@RestController public class HelloController { @Value(\u0026#34;${server.port}\u0026#34;) String port; @RequestMapping(\u0026#34;/hi\u0026#34;) public String home(@RequestParam(value = \u0026#34;name\u0026#34;, defaultValue = \u0026#34;forezp\u0026#34;) String name) { return \u0026#34;hi \u0026#34; + name + \u0026#34; ,i am from port:\u0026#34; + port; } } 启动服务后使用浏览器访问 http://localhost:8761/ 就可以看到service-hi服务已经启动 再使用浏览器访问http://localhost:8762/hi?name=lin将会返回:\nhi lin ,i am from port:8762\n服务间通讯与负载均衡 在微服务架构中，业务都会被拆分成一个独立的服务，服务与服务直接的通讯是基于http restful的，Spring Cloud有两种服务调用方式，一种是Ribbon+RestTemplate，另一个是feign。\nRibbon+RestTemplate 在使用Ribbon之前，先启动eureka-server服务，再利用idea启动两个service-hi服务，端口分别为8762和8763，我们利用两个端口对应的service-hi服务模拟一个小的集群。基于上面小节所介绍的消费者服务搭建基础上新建一个service-ribbon服务，在pom.xml中添加ribbon依赖：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-eureka-client\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-ribbon\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 服务配置文件指定的服务的注册中心地址为http://localhost:8761/eureka/,服务名为service-ribbon，端口为8764，配置文件application.yml如下：\neureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ server: port: 8764 spring: application: name: service-ribbon 使用RestTemplate实现服务间远程调用需要将RestTemplate添加到spring ioc容器中，可以直接在启动类上注入RestTemplate bean或者在Configuration类中注入RestTemplate bean；并通过@LoadBalanced注解表明RestTemplate开启负载均衡的功能。\n@SpringBootApplication @EnableDiscoveryClient public class ServiceRibbonApplication { public static void main(String[] args) { SpringApplication.run(ServiceRibbonApplication.class, args); } /** * 将RestTemplate添加到spring ioc容器里面 * @return */ @Bean @LoadBalanced RestTemplate restTemplate() { return new RestTemplate(); } } 编写一个测试类HelloService，通过使用ioc容器中的RestTemplate调用service-hi服务中的\u0026quot;/hi\u0026quot;接口，这里可以直接永程序名替代具体的url地址，在ribbon中会先根据服务名来选择具体的服务实例，再根据服务实例在请求会用具体的url代替服务名，代码如下：\n@Service public class HelloService { @Autowired RestTemplate restTemplate; public String hiService(String name) { return restTemplate.getForObject(\u0026#34;http://SERVICE-HI/hi?name=\u0026#34;+name,String.class); } } 编写一个HelloController类，在HelloController中调用HelloService：\n@RestController public class HelloController { @Autowired HelloService helloService; @GetMapping(value = \u0026#34;/hi\u0026#34;) public String hi(@RequestParam String name) { return helloService.hiService( name ); } } 此时使用浏览器多次访问 http://localhost:8764/hi?name=lin，浏览器交替显示：\nhi lin ,i am from port:8762 hi lin ,i am from port:8763\n此时的架构 一个服务注册中心，eureka server,端口为8761 service-hi工程跑了两个实例，端口分别为8762,8763，分别向服务注册中心注册 service-ribbon端口为8764，向服务注册中心注册 当service-ribbon通过RestTemplate调用service-hi的hi接口时，因为用ribbon进行了负载均衡，会以轮询的方式调用service-hi：8762和8763两个端口的hi接口； Feign调用 在使用Feign之前，需要先了解feign是集成了ribbon的，feign的负载均衡策略默认为ribbon的轮询策略，也就是说在通过feign调用接口可以实现和ribbon一样的效果，接着在项目中新建service-feign服务，添加spring-cloud-starter-openfeign依赖：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 想要使用feign必须启动类上添加注解@EnableFeignClients\n@SpringBootApplication @EnableDiscoveryClient @EnableFeignClients public class ServiceFeignApplication { public static void main(String[] args) { SpringApplication.run(ServiceFeignApplication.class, args); } } service-feign服务同样需要配置eureka.client.serviceUrl.defaultZone为eureka的地址\neureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ server: port: 8765 spring: application: name: service-feign 编写一个HelloService调用service-hi服务中的接口（之前小节所编写的接口）\n@FeignClient(value = \u0026#34;service-hi\u0026#34;) public interface HelloService { @GetMapping(\u0026#34;/hi\u0026#34;) String sayHiFromClientOne(@RequestParam(value = \u0026#34;name\u0026#34;) String name); } 另外在service-feign服务中添加一个Controller接口给外部调用\n@RestController(\u0026#34;/hi\u0026#34;) public class HelloController { @Autowired private HelloService helloService; @GetMapping(value = \u0026#34;/hi\u0026#34;) public String sayHi(@RequestParam String name) { return helloService.sayHiFromClientOne( name ); } } 使用浏览器访问接口 http://localhost:8765/hi?name=luo，交替返回如下内容：\nhi luo ,i am from port:8762 hi luo ,i am from port:8763 Hystrix 断路器 在微服务架构中，根据业务来拆分成一个个的服务，服务与服务之间可以相互调用（RPC），在Spring Cloud可以用RestTemplate+Ribbon和Feign来调用。为了保证其高可用，单个服务通常会集群部署。由于网络原因或者自身的原因，服务并不能保证100%可用，如果单个服务出现问题，调用这个服务就会出现线程阻塞，此时若有大量的请求涌入，Servlet容器的线程资源会被消耗完毕，导致服务瘫痪。服务与服务之间的依赖性，故障会传播，会对整个微服务系统造成灾难性的严重后果，这就是服务故障的“雪崩”效应。为了解决这个问题，业界提出了断路器模型。\nribbon 使用短路器 hi lin ,i am from port:8762\nhi,lin,sorry,error!\nfeign使用断路器 路由网关 Zuul Zuul的主要功能是路由转发和过滤器。路由功能是微服务的一部分，比如／api/user转发到到user服务，/api/shop转发到到shop服务。zuul默认和Ribbon结合实现了负载均衡的功能。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/springcloud%E6%90%AD%E5%BB%BA/","summary":"SpringCloud简介 Spring Cloud是一系列框架的有序集合。它利用SpringBoot的开发便利性巧妙地简化了分布式系统基础设施的开发，如","title":"SpringCloud搭建"},{"content":"前言 这其实是一道面试题，是我在面试百度的时候被问到的，当时没有答出来(因为自己真的很菜)，后来在网上寻找答案，看到也是一头雾水，直到看到了《Spring in action》这本书，书上有对Bean声明周期的大致解释，但是没有代码分析，所以就自己上网寻找资料，一定要把这个Bean生命周期弄明白！ 网上大部分都是验证的Bean 在面试问的生命周期，其实查阅JDK还有一个完整的Bean生命周期，这同时也验证了书是具有片面性的，最fresh 的资料还是查阅原始JDK!!!\n一、Bean 的完整生命周期 在传统的Java应用中，bean的生命周期很简单，使用Java关键字 new 进行Bean 的实例化，然后该Bean 就能够使用了。一旦bean不再被使用，则由Java自动进行垃圾回收。 相比之下，Spring管理Bean的生命周期就复杂多了，正确理解Bean 的生命周期非常重要，因为Spring对Bean的管理可扩展性非常强，下面展示了一个Bean的构造过程\nBean 的生命周期 如上图所示，Bean 的生命周期还是比较复杂的，下面来对上图每一个步骤做文字描述:\nSpring启动，查找并加载需要被Spring管理的bean，进行Bean的实例化 Bean实例化后对将Bean的引入和值注入到Bean的属性中 如果Bean实现了BeanNameAware接口的话，Spring将Bean的Id传递给setBeanName()方法 如果Bean实现了BeanFactoryAware接口的话，Spring将调用setBeanFactory()方法，将BeanFactory容器实例传入 如果Bean实现了ApplicationContextAware接口的话，Spring将调用Bean的setApplicationContext()方法，将bean所在应用上下文引用传入进来。 如果Bean实现了BeanPostProcessor接口，Spring就将调用他们的postProcessBeforeInitialization()方法。 如果Bean 实现了InitializingBean接口，Spring将调用他们的afterPropertiesSet()方法。类似的，如果bean使用init-method声明了初始化方法，该方法也会被调用 如果Bean 实现了BeanPostProcessor接口，Spring就将调用他们的postProcessAfterInitialization()方法。 此时，Bean已经准备就绪，可以被应用程序使用了。他们将一直驻留在应用上下文中，直到应用上下文被销毁。 如果bean实现了DisposableBean接口，Spring将调用它的destory()接口方法，同样，如果bean使用了destory-method 声明销毁方法，该方法也会被调用。 上面是Spring 中Bean的核心接口和生命周期，面试回答上述过程已经足够了。但是翻阅JavaDoc文档发现除了以上接口外，还有另外的初始化过程涉及的接口： 摘自org.springframework.beans.factory.BeanFactory， 全部相关接口如下，上述已有的就不用着重标注，把额外的相关接口着重标注下\nBean 完整的生命周期 文字解释如下： ————————————初始化————————————\nBeanNameAware.setBeanName() 在创建此bean的bean工厂中设置bean的名称，在普通属性设置之后调用，在InitializinngBean.afterPropertiesSet()方法之前调用 BeanClassLoaderAware.setBeanClassLoader(): 在普通属性设置之后，InitializingBean.afterPropertiesSet()之前调用 BeanFactoryAware.setBeanFactory() : 回调提供了自己的bean实例工厂，在普通属性设置之后，在InitializingBean.afterPropertiesSet()或者自定义初始化方法之前调用 EnvironmentAware.setEnvironment(): 设置environment在组件使用时调用 EmbeddedValueResolverAware.setEmbeddedValueResolver(): 设置StringValueResolver 用来解决嵌入式的值域问题 ResourceLoaderAware.setResourceLoader(): 在普通bean对象之后调用，在afterPropertiesSet 或者自定义的init-method 之前调用，在 ApplicationContextAware 之前调用。 ApplicationEventPublisherAware.setApplicationEventPublisher(): 在普通bean属性之后调用，在初始化调用afterPropertiesSet 或者自定义初始化方法之前调用。在 ApplicationContextAware 之前调用。 MessageSourceAware.setMessageSource(): 在普通bean属性之后调用，在初始化调用afterPropertiesSet 或者自定义初始化方法之前调用，在 ApplicationContextAware 之前调用。 ApplicationContextAware.setApplicationContext(): 在普通Bean对象生成之后调用，在InitializingBean.afterPropertiesSet之前调用或者用户自定义初始化方法之前。在ResourceLoaderAware.setResourceLoader，ApplicationEventPublisherAware.setApplicationEventPublisher，MessageSourceAware之后调用。 ServletContextAware.setServletContext(): 运行时设置ServletContext，在普通bean初始化后调用，在InitializingBean.afterPropertiesSet之前调用，在 ApplicationContextAware 之后调用注：是在WebApplicationContext 运行时 BeanPostProcessor.postProcessBeforeInitialization() : 将此BeanPostProcessor 应用于给定的新bean实例 在任何bean初始化回调方法(像是InitializingBean.afterPropertiesSet或者自定义的初始化方法）之前调用。这个bean将要准备填充属性的值。返回的bean示例可能被普通对象包装，默认实现返回是一个bean。 BeanPostProcessor.postProcessAfterInitialization() : 将此BeanPostProcessor 应用于给定的新bean实例 在任何bean初始化回调方法(像是InitializingBean.afterPropertiesSet或者自定义的初始化方法)之后调用。这个bean将要准备填充属性的值。返回的bean示例可能被普通对象包装 InitializingBean.afterPropertiesSet(): 被BeanFactory在设置所有bean属性之后调用(并且满足BeanFactory 和 ApplicationContextAware)。 ————————————销毁———————————— 在BeanFactory 关闭的时候，Bean的生命周期会调用如下方法:\nDestructionAwareBeanPostProcessor.postProcessBeforeDestruction(): 在销毁之前将此BeanPostProcessor 应用于给定的bean实例。能够调用自定义回调，像是DisposableBean 的销毁和自定义销毁方法，这个回调仅仅适用于工厂中的单例bean(包括内部bean) 实现了自定义的destory()方法 二、Bean 的生命周期验证 为了验证Bean生命周期的过程，有两种形式：一种是为面试而准备的，一种是为了解全过程而准备的，下面来看代码： Book.class\npublic class Book implements BeanNameAware,BeanFactoryAware, ApplicationContextAware,InitializingBean,DisposableBean { private String bookName; public Book(){ System.out.println(\u0026#34;Book Initializing \u0026#34;); } public void setBeanFactory(BeanFactory beanFactory) throws BeansException { System.out.println(\u0026#34;Book.setBeanFactory invoke\u0026#34;); } public void setBeanName(String name) { System.out.println(\u0026#34;Book.setBeanName invoke\u0026#34;); } public void destroy() throws Exception { System.out.println(\u0026#34;Book.destory invoke\u0026#34;); } public void afterPropertiesSet() throws Exception { System.out.println(\u0026#34;Book.afterPropertiesSet invoke\u0026#34;); } public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { System.out.println(\u0026#34;Book.setApplicationContext invoke\u0026#34;); } public String getBookName() { return bookName; } public void setBookName(String bookName) { this.bookName = bookName; System.out.println(\u0026#34;setBookName: Book name has set.\u0026#34;); } public void myPostConstruct(){ System.out.println(\u0026#34;Book.myPostConstruct invoke\u0026#34;); } // 自定义初始化方法 @PostConstruct public void springPostConstruct(){ System.out.println(\u0026#34;@PostConstruct\u0026#34;); } public void myPreDestory(){ System.out.println(\u0026#34;Book.myPreDestory invoke\u0026#34;); System.out.println(\u0026#34;---------------destroy-----------------\u0026#34;); } // 自定义销毁方法 @PreDestroy public void springPreDestory(){ System.out.println(\u0026#34;@PreDestory\u0026#34;); } @Override protected void finalize() throws Throwable { System.out.println(\u0026#34;------inside finalize-----\u0026#34;); } } 自定义实现BeanPostProcessor 的MyBeanPostProcessor：\npublic class MyBeanPostProcessor implements BeanPostProcessor { // 容器加载的时候会加载一些其他的bean，会调用初始化前和初始化后方法 // 这次只关注book(bean)的生命周期 public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { if(bean instanceof Book){ System.out.println(\u0026#34;MyBeanPostProcessor.postProcessBeforeInitialization\u0026#34;); } return bean; } public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { if(bean instanceof Book){ System.out.println(\u0026#34;MyBeanPostProcessor.postProcessAfterInitialization\u0026#34;); } return bean; } } 在resources 目录下新建Bean-Lifecycle.xml\n\u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\u0026#34;\u0026gt; \u0026lt;!-- 扫描bean --\u0026gt; \u0026lt;context:component-scan base-package=\u0026#34;com.bean.lifecycle\u0026#34;/\u0026gt; \u0026lt;!-- 实现了用户自定义初始化和销毁方法 --\u0026gt; \u0026lt;bean id=\u0026#34;book\u0026#34; class=\u0026#34;com.bean.lifecycle.Book\u0026#34; init-method=\u0026#34;myPostConstruct\u0026#34; destroy-method=\u0026#34;myPreDestory\u0026#34;\u0026gt; \u0026lt;!-- 注入bean 属性名称 --\u0026gt; \u0026lt;property name=\u0026#34;bookName\u0026#34; value=\u0026#34;thingking in java\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!--引入自定义的BeanPostProcessor--\u0026gt; \u0026lt;bean class=\u0026#34;com.bean.lifecycle.MyBeanPostProcessor\u0026#34;/\u0026gt; \u0026lt;/beans\u0026gt; 做一个启动类的测试，新建SpringBeanLifecycleApplication\npublic class SpringBeanLifecycleApplication { public static void main(String[] args) throws InterruptedException { // 为面试而准备的Bean生命周期加载过程 ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;Bean-Lifecycle.xml\u0026#34;); Book book = (Book)context.getBean(\u0026#34;book\u0026#34;); System.out.println(\u0026#34;Book name = \u0026#34; + book.getBookName()); ((ClassPathXmlApplicationContext) context).destroy(); } } 启动测试，输出结果如下：\nBook Initializing setBookName: Book name has set. Book.setBeanName invoke Book.setBeanFactory invoke Book.setApplicationContext invoke MyBeanPostProcessor.postProcessBeforeInitialization @PostConstruct Book.afterPropertiesSet invoke Book.myPostConstruct invoke MyBeanPostProcessor.postProcessAfterInitialization Book name = thingking in java @PreDestory Book.destory invoke Book.myPreDestory invoke ---------------destroy----------------- 为了验证Bean完整的生命周期，需要新建一个SubBookClass 继承Book类\npublic class SubBookClass extends Book implements BeanClassLoaderAware, EnvironmentAware,EmbeddedValueResolverAware,ResourceLoaderAware, ApplicationEventPublisherAware,MessageSourceAware{ private String bookSystem; public String getBookSystem() { return bookSystem; } public void setBookSystem(String bookSystem) { System.out.println(\u0026#34;设置BookSystem 的属性值\u0026#34;); this.bookSystem = bookSystem; } public void setBeanClassLoader(ClassLoader classLoader) { System.out.println(\u0026#34;SubBookClass.setBeanClassLoader() 方法被调用了\u0026#34;); } public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) { System.out.println(\u0026#34;SubBookClass.setApplicationEventPublisher() 方法被调用了\u0026#34;); } public void setEmbeddedValueResolver(StringValueResolver resolver) { System.out.println(\u0026#34;SubBookClass.setEmbeddedValueResolver() 方法被调用了\u0026#34;); } public void setEnvironment(Environment environment) { System.out.println(\u0026#34;SubBookClass.setEnvironment() 方法被调用了\u0026#34;); } public void setMessageSource(MessageSource messageSource) { System.out.println(\u0026#34;SubBookClass.setMessageSource() 方法被调用了\u0026#34;); } public void setResourceLoader(ResourceLoader resourceLoader) { System.out.println(\u0026#34;SubBookClass.setResourceLoader() 方法被调用了\u0026#34;); } } 上述SubBookClass类与Book是互补关系。 新建一个SubBean-Lifecycle.xml，注入SubBookClass\n\u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;bookClass\u0026#34; class=\u0026#34;com.bean.lifecycle.SubBookClass\u0026#34; init-method=\u0026#34;myPostConstruct\u0026#34; destroy-method=\u0026#34;myPreDestory\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;bookSystem\u0026#34; value=\u0026#34;Java System\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean class=\u0026#34;com.bean.lifecycle.MyBeanPostProcessor\u0026#34;/\u0026gt; \u0026lt;/beans\u0026gt; 完整的SpringBeanLifecycleApplication 如下：\npublic class SpringBeanLifecycleApplication { public static void main(String[] args) throws InterruptedException { // 为面试而准备的Bean生命周期加载过程 ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;Bean-Lifecycle.xml\u0026#34;); Book book = (Book)context.getBean(\u0026#34;book\u0026#34;); System.out.println(\u0026#34;Book name = \u0026#34; + book.getBookName()); ((ClassPathXmlApplicationContext) context).destroy(); // 完整的加载过程，当然了解的越多越好 ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\u0026#34;SubBean-Lifecycle.xml\u0026#34;); SubBookClass subBookClass = (SubBookClass) applicationContext.getBean(\u0026#34;bookClass\u0026#34;); System.out.println(\u0026#34;BookSystemName = \u0026#34; + subBookClass.getBookSystem()); ((ClassPathXmlApplicationContext) applicationContext).registerShutdownHook(); } } 输出完整的结果：\nBook Initializing setBookName: Book name has set. Book.setBeanName invoke Book.setBeanFactory invoke Book.setApplicationContext invoke MyBeanPostProcessor.postProcessBeforeInitialization @PostConstruct Book.afterPropertiesSet invoke Book.myPostConstruct invoke MyBeanPostProcessor.postProcessAfterInitialization Book name = thingking in java @PreDestory Book.destory invoke Book.myPreDestory invoke ---------------destroy----------------- Book Initializing 设置BookSystem 的属性值 Book.setBeanName invoke SubBookClass.setBeanClassLoader() 方法被调用了 Book.setBeanFactory invoke SubBookClass.setEnvironment() 方法被调用了 SubBookClass.setEmbeddedValueResolver() 方法被调用了 SubBookClass.setResourceLoader() 方法被调用了 SubBookClass.setApplicationEventPublisher() 方法被调用了 SubBookClass.setMessageSource() 方法被调用了 Book.setApplicationContext invoke MyBeanPostProcessor.postProcessBeforeInitialization Book.afterPropertiesSet invoke Book.myPostConstruct invoke MyBeanPostProcessor.postProcessAfterInitialization BookSystemName = Java System Book.destory invoke Book.myPreDestory invoke ---------------destroy----------------- ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/spring%E4%B8%ADbean%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","summary":"前言 这其实是一道面试题，是我在面试百度的时候被问到的，当时没有答出来(因为自己真的很菜)，后来在网上寻找答案，看到也是一头雾水，直到看到了《","title":"Spring中Bean的生命周期"},{"content":"使用spring时，aop可以大幅度减少我们的工作量，这里主要介绍一些spring中aop如何切注解。\n自定义注解： @Target({ElementType.METHOD}) @Retention(RetentionPolicy.RUNTIME) public @interface MyAnnotation { String value(); } 编写切面类，切点在自定义注解上，切面类添加到spring容器中。 @Aspect @Component public class AnnotationAspect { @Pointcut(\u0026#34;@annotation(com.annotation.learn.aop.MyAnnotation)\u0026#34;) public void pointCut(){} @Before(value = \u0026#34;pointCut() \u0026amp;\u0026amp; @annotation(myAnnotation)\u0026#34;) public void start(JoinPoint joinPoint, MyAnnotation myAnnotation){ System.out.println(\u0026#34;Before...\u0026#34;); Object[] args = joinPoint.getArgs(); System.out.print(joinPoint.getSignature().getName()+\u0026#34;运行，参数列表：\u0026#34;+ Arrays.asList(args)); System.out.println(\u0026#34;；注解为：\u0026#34;+myAnnotation); } @After(value = \u0026#34;pointCut()\u0026#34;) public void end(){ System.out.println(\u0026#34;After...\u0026#34;); } @AfterReturning(value = \u0026#34;pointCut()\u0026#34;, returning = \u0026#34;result\u0026#34;) public void logAfterReturning(Object result){ System.out.print(\u0026#34;AfterReturning ....\u0026#34;); System.out.println(\u0026#34;结果为：\u0026#34;+result); } @AfterThrowing(value = \u0026#34;pointCut()\u0026#34;, throwing = \u0026#34;exception\u0026#34;) public void logException(Exception exception){ System.out.print(\u0026#34;exception...\u0026#34;); System.out.println(\u0026#34;异常信息为：\u0026#34;+exception.getMessage()); } } 使用自定义注解： @Service public class PersonServiceImpl implements PersonService { @MyAnnotation(value = \u0026#34;这是PersonServiceImpl,show1()的注解\u0026#34;) public void show1(String p){ System.out.println(\u0026#34;PersonServiceImpl... show1()\u0026#34;+\u0026#34;；参数是：\u0026#34;+p); } } 测试注解： @Test public void test2(){ AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(ConfigOfAOP.class); PersonServiceImpl bean = applicationContext.getBean(PersonServiceImpl.class); bean.show1(\u0026#34;aop\u0026#34;); } 打印结果： Before... show1运行，参数列表：[aop]；注解为：@com.annotation.learn.aop.MyAnnotation(value=这是PersonServiceImpl.show1()的注解) PersonServiceImpl.show1()；参数是：aop After... AfterReturning ....结果为：null ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/spring%E4%B8%AD%E5%88%A9%E7%94%A8aop%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E8%A7%A3/","summary":"使用spring时，aop可以大幅度减少我们的工作量，这里主要介绍一些spring中aop如何切注解。 自定义注解： @Target({ElementType.METHOD}) @Retention(RetentionPolicy.RUNTIME) public @interface MyAnnotation { String value(); } 编写切面","title":"Spring中利用AOP使用自定义注解"},{"content":"Spring事务基本知识点 事务的ACID 事务是区分文件存储系统与NoSql数据库重要特性之一，其存在的意义是为了保证即使在并发情况下也能正确的执行crud操作，怎样才算是正确的呢？这时提出了事务需要保证的四个特性ACID：\nA：原子性（atomicity） 事务中各项操作，要么全做要么全不做，任何一项操作的失败都都会导致整个事务的失败； C：一致性（consistency） 事务结束后系统状态是一致的； I：隔离性（isolation） 并发执行的事务彼此无法看到对方的中间状态； D：持久性（durability） 事务完成后所做的改动都会被持久化，即使发生灾难性的失败； 在高并发的情况下，要完全保证其ACID特性是非常困难的，除非把所有的事务串行化执行，但带来的负面的影响将是性能大打折扣。很多时候我们有些业务对事务的要求是不一样的，所以数据库中设计了四种隔离级别，供用户基于业务进行选择。\n事务隔离级别 在高并发的场景下会出现的事务问题如下**Dirty Reads 脏读：**事务A正在对数据进行更新操作，但是更新还未提交，事务B这时也来操作这组数据，并且读取了事务A还未提交的数据，而事务A如果操作失败进行了回滚，事务B读取的就是错误数据，这样就造成了脏读。**Non-Repeatable Reads 不可重复读：**在同一事务中，多次读取同一数据返回的结果有所不同，换句话说，事务A两次查询中间读取到事务B已提交的更新数据；相反，“可重复读”在同一事务中多次读取数据时，能够保证所读取数据不能读取到另一事务已提交的更新数据。**Phantom Reads 幻读：**查询表中一条数据如果不存在就插入一条；并发的时候却发现数据库中保存了多条先相同的数据，（因为多个线程同时查询数据库时都发现数据不存在，则都进行插入操作）这就是幻读。\n隔离级别 脏读（Dirty Reads） 不可重复读 (NonRepeatable Reads) 幻读(Phantom Reads) 未提交读(isolation = Isolation.READ_UNCOMMITTED)（ 基本不使用） 可能 可能 可能 已提交读 (isolation = Isolation.READ_COMMITTED) 不可能 可能 可能 可重复读 (isolation = Isolation.REPEATABLE_READ) 不可能 不可能 可能 可串行化 (isolation = Isolation.SERIALIZABLE) 不可能 不可能 不可能 不同数据库中的默认隔离级别有所不同：\nMYSQL: 默认为REPEATABLE_READ级别 SQLSERVER: 默认为READ_COMMITTED ORACLE:默认为 READ_COMMITTED mysql 查询事务隔离级别：show variables like '%tx_isolation%'\nSpring事务传播级别 类别 事务传播类型 说明 支持当前事务 PROPAGATION_REQUIRED（必须的） 如果当前没有事务，就新建一个事务，如果已经存在一个事务，则加入到这个事务中，这是最常见的选择，Spring默认使用传播级别。 PROPAGATION_SUPPORTS（支持） 支持当前事务，如果当前没有事务，就以非事务方法执行 PROPAGATION_MANDATORY（强制） 使用当前的事务，如果当前没有事务，就抛出异常。 不支持当前事务 PROPAGATION_REQUIRES_NEW（隔离） 新建事务，如果当前存在事务，把当前事务挂起 PROPAGATION_NOT_SUPPORTED（不支持） 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起 PROPAGATION_NERVER（强制非事务） 以非事务方式执行，如果当前存在事务，则抛出异常 嵌套事务 PROPAGATION_NESTED（嵌套事务） 如果当前存在事务，则在嵌套事务内执行，如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作；PROPAGATION_NESTED 是外部事务的子事务, 如果外部事务 commit, 嵌套事务也会被 commit, 这个规则同样适用于 roll back. Spring事务使用过程中容易混淆的知识点 Spring中使用事务原则 一、假如调用方法是A，被调用方法是B；只要方法B抛出了异常，那么方法A则也会回滚，在执行完方法B之后方法A抛异常，则需要看方法B上的事务传播行为。 二、Spring中本类里面事务方法A调用事务方法B，那么事务方法B上的事务注解将会失效，方法B将会作为方法A的一部分，加入到方法A的事务中。\nSpring中使用PROPAGATION_REQUIRED作为默认传播行为 Spring事务传播行为中PROPAGATION_REQUIRED和PROPAGATION_NESTED是比较像的，对于下面示例代码，funB()上使用PROPAGATION_REQUIRED和PROPAGATION_NESTED都会引起funB回滚 serviceA{ @Transactional funcA(){ serviceB.funcB(); int i = 1/0; // 模拟异常报错 } } serviceB{ @Transactional funcB(){ // 执行insert或update操作 } } 在上面的示例代码中，如果funB使用PROPAGATION_REQUIRES_NEW, 则funcB将会启动一个独立事务，此时funcB提交成功后，funA的异常不会引起funB的回滚。 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/spring%E4%BA%8B%E5%8A%A1%E4%BB%A5%E5%8F%8A%E4%BA%8B%E5%8A%A1%E5%B5%8C%E5%A5%97/","summary":"Spring事务基本知识点 事务的ACID 事务是区分文件存储系统与NoSql数据库重要特性之一，其存在的意义是为了保证即使在并发情况下也能正确","title":"Spring事务以及事务嵌套"},{"content":"Spring IOC与DI IOC：在Spring框架中实现控制反转的是Spring IoC容器，其具体就是由容器来控制对象的生命周期和业务对象之间的依赖关系，而不是像传统方式(new 对象)中由代码来直接控制。 DI，依赖注入；IoC和DI其实是同一个概念，只是从不同的角度描述罢了(IoC是一种思想，而DI则是一种具体的技术实现手段)。 构造函数注入 set方法注入 注解注入 优点 第一，资源集中管理，实现资源的可配置和易管理 第二，降低了使用资源双方的依赖程度，也就是我们说的耦合度 AOP [[Spring中利用AOP使用自定义注解]] [[Spring AOP注解常见问题]]\nBean Bean的作用域 - singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的，对单例设计模式的应用。 - 单例 bean 的线程安全问题 - 单例 bean 存在线程问题，主要是因为当多个线程操作同一个对象的时候是存在资源竞争的。 - prototype : 每次请求都会创建一个新的 bean 实例。 - request : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。 - session : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。 - global-session ： 全局 session 作用域，仅仅在基于 portlet 的 web 应用中才有意义，Spring5 已经没有了。Portlet 是能够生成语义代码(例如：HTML)片段的小型 Java Web 插件。它们基于 portlet 容器，可以像 servlet 一样处理 HTTP 请求。但是，与 servlet 不同，每个 portlet 都有不同的会话。 Bean的生命周期（4个阶段） 实例化 Bean 容器找到配置文件中 Spring Bean 的定义。 实例化一个 bean 对象 属性赋值 为 bean 设置相关属性和依赖 初始化 初始化前 检查Aware相关接口并设置相关依赖【扩展点】 BeanPostProcessor前置处理【扩展点】 初始化 是否实现InitializingBean接口【扩展点】 BeanPostProcessor前置处理后置处理【扩展点】 销毁 注册 Destruction相关回调接口【扩展点】 使用中 是否实现了 DisposableBean 接口，执行 destroy() 方法。【扩展点】 如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的方法。 扩展点： Aware 接口 BeanPostProcessor 是 Spring 为修改 bean提供的强大扩展点，其可作用于容器中所有 bean，初始化 InitializingBean 和 init-method 是 Spring 为 bean 初始化提供的扩展点。 总结一下：\n4个大的阶段：实例化、属性赋值、初始化、销毁 初始化的具体操作，有Aware接口的依赖注入、BeanPostProcessor在初始化前后的处理以及InitializingBean和init-method 的初始化操作 销毁的具体操作，有注册销毁回调接口，最后通过 DisposableBean和 destroy-method 实现销毁 Spring启动流程 初始化Spring容器，注册内置的BeanPostProcessor的BeanDefinition到容器中 实例化BeanFactory【DefaultListableBeanFactory】工厂，用于生成Bean对象 实例化BeanDefinitionReader注解配置读取器，用于对特定注解（如@Service、@Repository）的类进行读取转化成 BeanDefinition 对象，（BeanDefinition 是 Spring 中极其重要的一个概念，它存储了 bean 对象的所有特征信息，如是否单例，是否懒加载，factoryBeanName 等） 实例化ClassPathBeanDefinitionScanner路径扫描器，用于对指定的包目录进行扫描查找 bean 对象 将配置类的BeanDefinition注册到容器中 调用refresh()方法刷新容器 SpringMVC Spring事务 Spring 管理事务的方式 编程式事务 在代码中硬编码(不推荐使用) : 通过 TransactionTemplate或者 TransactionManager 手动管理事务，实际应用中很少使用，但是对于你理解 Spring 事务管理原理有帮助。 声明式事务 在 XML 配置文件中配置或者直接基于注解（推荐使用） : 实际是通过 AOP 实现（基于@Transactional 的全注解方式使用最多） 事务传播行为 Spring是什么？ 谈谈你对AOP的理解 面向切面编程 JDK动态代理 CGLib动态代理 谈谈你对IOC的理解 控制反转 简单理解：传统开发中，我们在对象内部通过new关键字，创建依赖的对象，我们主动控制依赖的对象；而IoC有专门一个容器来创建依赖对象，对象内部只是被动的接受这些依赖的对象。上面就解释了“控制反转”：依赖对象的获取给反转了。之前，依赖对象由对象内部主动创建获取，现在，依赖对象由容器创建，对象从容器中获取依赖对象。 解释下Spring支持的几种bean的作用域 5种作用域 spring事务的实现方式和原理以及隔离级别？ AOP，4个隔离级别，RU、RC、RR、串行 三个问题： 幻读： 脏读： 不可重复读 Spring事务传播机制 Spring事务什么时候会失效？ 什么是bean的自动装配，有哪些方式？ Spring中的Bean创建的生命周期有哪些步骤 Spring中Bean是线程安全的吗 不是线程安全的 ApplicationContext和BeanFactory有什么区别 Spring中的事务是如何实现的 AOP Spring中什么时候@Transactional会失效 Spring容器启动流程是怎样的 Spring用到了哪些设计模式 工厂设计模式：BeanFactory、ApplicationContext 单例模式 代理设计模式 模板方法：jdbcTemplate、hibernateTemplate 观察者模式：ApplicationEvent，ApplicationListener 适配器模式：Spring AOP 的增强或通知(Advice)使用到了适配器模式、SpringMVC中的Controller Spring Boot、 Spring MVC 和 Spring 有什么区别 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E9%9D%A2%E8%AF%95/spring/","summary":"Spring IOC与DI IOC：在Spring框架中实现控制反转的是Spring IoC容器，其具体就是由容器来控制对象的生命周期和业务对象之间的依赖关","title":"Spring知识"},{"content":"spring容器注册组件 通过使用注解方式向spring容器中添加组件是十分简单的，大体有如下方式：\n在config类中通过添加@Bean来添加注解 通过扫描添加组件 使用@Import添加一个外部组件 使用@ImportSelector添加一个组件 使用ImportBeanDefinitionRegistrar添加一个组件 使用FactoryBean注册组件 在config类中通过添加@Bean来添加注解 使用方式如下：\n@Configuration public class MyConfig { @Bean public Target target(){ return new Target(); } } 通过扫描添加组件 使用@ComponentScan+组件注解@Controller/@Service/@Repository/@Component扫描添加组件使用方式如下：\n@ComponentScan(\u0026#34;org.springframework.demo\u0026#34;) @Configuration public class MyConfig { } 另外，通过扫描方式添加组件的方式可以通过一些注解来配置组件：\n@TypeFilter指定过滤规则 @Scope设置组件作用域 @Lazy设置是否懒加载 @Conditional按照条件注册bean 使用@Import添加一个外部组件 使用方式如下：\n@Configuration @Import(value = {Example1.class}) public class MyConfig { } 使用@ImportSelector添加一个组件 使用方式如下：\n@Configuration @Import(value = {MyImportSelector.class}) public class MyConfig { } 使用FactoryBean注册组件 使用方式如下：\n@Configuration @Import(value = {MyBeanDefinitionRegister.class}) public class MyConfig { } public class MyBeanDefinitionRegister implements ImportBeanDefinitionRegistrar { @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Example1.class); registry.registerBeanDefinition(\u0026#34;Dog\u0026#34;,rootBeanDefinition); } } 使用FactoryBean注册组件 使用方式如下：\n// 创建一个FactoryBean的实现类 public class ExampleFactoryBean implements FactoryBean\u0026lt;Example3\u0026gt; { // 返回一个Example3对象，这个对象会被添加到spring容器中 @Override public Example3 getObject() throws Exception { return new Example3(); } @Override public Class\u0026lt;?\u0026gt; getObjectType() { return Example3.class; } // 如果是单例，则返回true，否则返回false @Override public boolean isSingleton() { return true; } } @Configuration public class MyConfig { // 将这个FactoryBean的实现类添加到spring容器中 @Bean public ExampleFactoryBean exampleFactoryBean(){ return new ExampleFactoryBean(); } } AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MyConfig.class); ExampleFactoryBean bean = applicationContext.getBean(ExampleFactoryBean.class); try { // getObject()返回Example3 bean System.out.println(bean.getObject()); } catch (Exception e) { e.printStackTrace(); } ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/spring%E7%BB%84%E4%BB%B6/","summary":"spring容器注册组件 通过使用注解方式向spring容器中添加组件是十分简单的，大体有如下方式： 在config类中通过添加@Bean来添加","title":"Spring组件"},{"content":"DefaultListableBeanFactory 类图 AliasRegistry：定义对alias的简单增删改操作 SimpleAliasRegistry：主要使用map作为alias的缓存，并对接口AliasRegistry进行实现。 SingletonBeanRegistry：定义对单例的注册及获取 BeanFactory：定义获取bean以及bean的各种属性 DefaultSingletonBeanRegistry：对接口SingletonBeanRegistry各方法的实现 FactoryBeanRegistrySupport：在DefaultSingletonBeanRegistry基础上增加对FactoryBean的特殊处理功能 AbstractBeanFactory：综合AbstractBeanRegistorySupport和ConfigurableBeanFactory的功能 AbstractAutowireCapableBeanFactory：综合AbstractBeanFactory并对接口AutowireCapableBeanFactory进行实现 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/spring%E7%BB%93%E6%9E%84%E7%BB%84%E6%88%90/","summary":"DefaultListableBeanFactory 类图 AliasRegistry：定义对alias的简单增删改操作 SimpleAliasRegistry：主要使用map作为alias的缓存","title":"Spring结构组成"},{"content":"测试实例 count(1)测试，sql语句如下： select count(1) from ums_member; 结果如下： count(*)测试，sql语句如下： select count(*) from ums_member; 结果如下： count(主键)测试，sql语句如下： select count(id) from ums_member; --id为主键字段 结果如下： count(普通列)测试，sql语句如下： select count(phone) from ums_member; 结果如下： count(1)、count(*)和count(字段名)执行效果上的区别 count(*)包括了所有的列，相当于行数，在统计结果的时候，不会忽略列值为NULL count(1)包括了忽略所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULL count(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。 count(1)、count(*)和count(字段名)执行效率上的区别 如上可以看出其实四种方式的效率是一样的，但是网上有如下说法：\n列名为主键，count(列名)会比count(1)快 列名不为主键，count(1)会比count(列名)快 如果表多个列并且没有主键，则 count（1） 的执行效率优于 count（*） 如果有主键，则 select count（主键）的执行效率是最优的 如果表只有一个字段，则 select count（*）最优。 具体的情况还是得看业务场景中使用时的效果，在业务场景中可以多试试。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/sql%E4%B8%ADcount1count%2A%E5%92%8Ccount%E5%AD%97%E6%AE%B5%E5%90%8D%E7%9A%84%E5%8C%BA%E5%88%AB/","summary":"测试实例 count(1)测试，sql语句如下： select count(1) from ums_member; 结果如下： count(*)测试，sql语句如下： select count(*) from ums_member; 结果如下： count(主键)测","title":"Sql中count(1)、count(%2A)和count(字段名)的区别"},{"content":"在平时开发中，我们都会遇到数据库中varchar或者char类型字段为null的情况，通常情况我们都会认为数据库中'某个值或者没有值'!=null这个条件的结果是true。但是，我得告诉你，上面说的那个等式的结果是false。首先上结论：\n'某个值或者没有值'!=null这个条件的结果是false '某个值或者没有值'=null这个条件的结果也是false 解释下上面结论中说的‘没有值’，在数据库中存在这样一些值，它们是char类型或者varchar类型字段，但是它的值被删除了。另外它还有个兄弟，就是值为null的情况，大体差异如下：\n可是，有了结论总得有证据证明不是。接下来，上证据，表结构\ncreate table member ( mid int auto_increment, name varchar(50) null, age int null, level_type char(50) null, constraint member_pk primary key (mid) ) comment \u0026#39;会员表\u0026#39;; 表中所有的数据，即select * from member;的执行结果：\nselect * from member where level_type != 'c';的执行结果：\nselect count(*) from member where level_type = 'c';的执行结果：\n另外，char类型的字段，也存在类似的问题，select * from member where name != 'c';的执行结果：\n也就是说，在数据库中，对于varchar或者char类型的字段，null !='c'的结果为false,null = 'c'的结果也为false。这也就给了我们提示：对于刚说的两种类型的字段，如果允许为空，那么对于空值null就需要额外注意，这个时候通常得具体情况具体分析。同时，我们可以观察到，我所说的‘没有值’，和平常字段中存的某个值的表现是差不多的，只是它的值似乎被‘删除’了。注：本文所用数据库为mysql5.7，目前对于sql server和oracle的情况还不是很了解，后续有环境可以测试一下。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/sql%E6%9F%A5%E8%AF%A2%E4%B8%ADchar%E6%88%96%E8%80%85varchar%E7%B1%BB%E5%9E%8B%E5%AD%97%E6%AE%B5%E4%B8%BAnull%E5%92%8C%E6%B2%A1%E6%9C%89%E5%80%BC%E6%97%B6%E5%BC%95%E8%B5%B7%E7%9A%84%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/","summary":"在平时开发中，我们都会遇到数据库中varchar或者char类型字段为null的情况，通常情况我们都会认为数据库中'某个值或者没有值'!=n","title":"Sql查询中char或者varchar类型字段为null和‘没有值’时引起的问题分析"},{"content":"sql中的join（本文仅介绍left join、right join、join on，图片是网上找的，原作者如果不允许使用请联系我）如下：\n测试数据：\n左连接，left join 左连接使用示例：\nselect * from teacher t left join course c on t.tid = c.tid; 结果：\n通过上面的结果可以看出，左连接会将其左边的表作为主表（记为A），右边的表作为从表（记为B），A中的记录必定会存在，B中没有对应记录时显示为空，B中有多条记录对应时则A中的记录会重复显示。\n经过测试有(下面这个仅作记录)：\n-- 下面两种写法结果一样 select * from teacher t left join course c on t.tid = c.tid; select * from teacher t left join course c on c.tid = t.tid; 右连接，right join 右连接与左连接则正好相反，使用如下sql语句：\nselect * from course c right join teacher t on t.tid = c.tid; 结果如下： 此时也得到了如下结论：\n-- 下面两种写法结果一样、只是列的顺序正好反过来的 select * from course c right join teacher t on t.tid = c.tid; select * from teacher t left join course c on c.tid = t.tid; 显然这个结果也印证了我上面说的右连接与左连接正好相反。\n内连接，join on 内连接与上面两种不同，它会将两张表中不符合on后面条件的记录全部筛掉，可以理解为在左连接的基础上将从表中记录为null的记录去除掉（左连接中所说的B表），使用如下sql语句：\nselect * from course c join teacher t on t.tid = c.tid; 结果为：\n多个联表查询 多个联表查询原理其实还是和上面的类似，只要懂了上面所说的内容，那么多个联表查询也就十分简单了，看下面的sql：\nselect * from teacher t join teachercard tc on t.tid = tc.tid left join course c on tc.tid = c.tid; 查询出来的结果如下：\n显然它的结果是根据teacher表和teachercard表联表查出来的结果再去进行左连接查询。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/sql%E8%81%94%E8%A1%A8%E6%9F%A5%E8%AF%A2/","summary":"sql中的join（本文仅介绍left join、right join、join on，图片是网上找的，原作者如果不允许使用请联系我）如下： 测试数","title":"Sql联表查询"},{"content":"ThreadLocal分析 什么是ThreadLocal ThreadLocal是一种变量类型，与普通的局部变量和全局变量所不同的是，ThreadLocal是一种“线程变量”，在jdk中一开始设计是用来存储线程上下文的，作用域与线程绑定。通常使用private 和 static修饰 ThreadLocal变量，此时表示作用域为本类中的线程使用到的方法。当线程被销毁，对应的线程变量也会被清除（个人是这样理解的，因为使用Entry存储对应的value是虚引用，当对应的线程被销毁时，线程）。但是在当前大多数使用线程池来管理线程的场景中，线程是不会被销毁的，这也就代表着使用线程池管理线程的时候，必须要手动清除线程变量， 否则将会造成内存泄漏。\nThreadLocal变量通常被static修饰，好处是它可以避免重复创建TSO(Thread Specific Object，即ThreadLocal所关联的对象)所导致的浪费。坏处是这样做可能正好形成内存泄漏所需的条件。\n在大多数精密的多线程代码中都有ThreadLocal的影子，理解ThreadLocal能帮助我们更好的理解java多线程。\nThreadLocal使用示例 public class ThreadlocalTest { private ThreadLocal\u0026lt;String\u0026gt; threadLocal = new ThreadLocal\u0026lt;\u0026gt;(); public void test() throws InterruptedException { threadLocal.set(\u0026#34;parent\u0026#34;); Thread thread = new Thread(() -\u0026gt; { System.out.println(Thread.currentThread().getName() + \u0026#34; ===\u0026gt; \u0026#34; + threadLocal.get()); threadLocal.set(\u0026#34;child\u0026#34;); System.out.println(Thread.currentThread().getName() + \u0026#34; ===\u0026gt; \u0026#34; + threadLocal.get()); }); thread.start(); thread.join(); System.out.println(Thread.currentThread().getName() + \u0026#34; ===\u0026gt; \u0026#34; + threadLocal.get()); } public static void main(String[] args) throws InterruptedException { new ThreadlocalTest().test(); } } 输出结果：\nThread-0 ===\u0026gt; null Thread-0 ===\u0026gt; child main ===\u0026gt; parent 通过上面的示例，我们可以看到ThreadLocal在每个线程之间独立的，父线程与子线程之间的ThreadLocal与子线程的ThreadLocal之间没有关系，真正的每个线程拥有自己的属性。\n源码分析 首先，我们要清楚，Thread、ThreadLocal、ThreadLocalMap还有ThreadLocalMap.Entry的关系；它们的关系可以理解为每一个线程拥有一个ThreadLocal.ThreadLocalMap属性的变量，而这个ThreadLocalMap变量中有一个内部类Entry，Entry中存储的\u0026lt;referent， value\u0026gt;键值对，其中referent是线程变量的引用，value则是我们通过ThreadLocal.set()设置的内容。多线程环境中，Thread、ThreadLocal、ThreadLocalMap还有ThreadLocalMap.Entry之间的关系如下图所示： Thread中存储ThreadLocal.ThreadLocalMap属性的有两个变量：threadLocals、inheritableThreadLocals；threadLocals不可以在父子线程之间使用，而inheritableThreadLocals可以在父子线程之间使用。\npublic class Thread implements Runnable { /* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ ThreadLocal.ThreadLocalMap threadLocals = null; } ThreadLocal.set()方法以及set相关操作：\npublic class ThreadLocal\u0026lt;T\u0026gt;{ private final int threadLocalHashCode = nextHashCode(); public void set(T value) { // 获取当前调用者线程 Thread t = Thread.currentThread(); // 尝试根据调用者线程获取该线程的ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) // 向ThreadLocalMap插入\u0026lt;ThreadLocal, value\u0026gt;键值对 map.set(this, value); else // 在第一次set()的时候创建该线程的ThreadLocalMap createMap(t, value); } // 在第一次set()或get()的时候创建该线程的ThreadLocalMap void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue); } static class ThreadLocalMap{ /** * 存储Entry的 */ private Entry[] table; // ThreadLocalMap 中用来存储\u0026lt;ThreadLocal引用变量,ThreadLocal 所保存的值\u0026gt;键值对 static class Entry extends WeakReference\u0026lt;ThreadLocal\u0026lt;?\u0026gt;\u0026gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal\u0026lt;?\u0026gt; k, Object v) { super(k); value = v; } } // 初始化ThreadLocalMap ThreadLocalMap(ThreadLocal\u0026lt;?\u0026gt; firstKey, Object firstValue) { // 初始Entry大小为16 table = new Entry[INITIAL_CAPACITY]; // 地址下标 = 第一个（当前）ThreadLocal变量的hash值\u0026amp;15，获取一个必然小于15的值作为下标存储value int i = firstKey.threadLocalHashCode \u0026amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; // 设置扩容阀值 = Entry大小(INITIAL_CAPACITY) * 2/3; 后续扩容大小 = 当前大小*2，扩容阀值=Entry大小* 2/3; setThreshold(INITIAL_CAPACITY); } // 向Entry中插入\u0026lt;ThreadLocal,value\u0026gt;键值对 private void set(ThreadLocal\u0026lt;?\u0026gt; key, Object value) { // We don\u0026#39;t use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; // 计算标 int i = key.threadLocalHashCode \u0026amp; (len-1); // 使用 开放寻址法 解决hash冲突 for (Entry e = tab[i]; e != null; // nextIndex(i,len) = ((i + 1 \u0026lt; len) ? i + 1 : 0) e = tab[i = nextIndex(i, len)]) { // 获取e的ThreadLocal引用 ThreadLocal\u0026lt;?\u0026gt; k = e.get(); // e的ThreadLocal引用 == 当前调用者线程，则将value覆盖原有value if (k == key) { e.value = value; return; } // e的ThreadLocal引用为空，而e不为空，说明当前的ThreadLocal引用已经不可达， // 将需要set的value和对应的ThreadLocal引用设置到当前的Entry中 // 该操作需要先解决ThreadLocal引用失效导致的hash值计算不连续问题，关于这一点可以了解一下hash表开放寻址法查找元素 if (k == null) { replaceStaleEntry(key, value, i); return; } } // 新增结点到Entry tab[i] = new Entry(key, value); int sz = ++size; // 尝试清除后续hash table中的结点 if (!cleanSomeSlots(i, sz) \u0026amp;\u0026amp; sz \u0026gt;= threshold) rehash(); } } } ThreadLocal.get()方法以及get相关操作：\npublic class ThreadLocal\u0026lt;T\u0026gt; { // 获取当前线程变量对应的value public T get() { // 获取当前调用者线程 Thread t = Thread.currentThread(); // 获取线程中的ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) { // 获取ThreadLocalMap中的Entry ThreadLocalMap.Entry e = map.getEntry(this); // Enrty不为空时尝试获取对应的value； // 为空则表示在这之前进行过get()操作创建了ThreadLocalMap if (e != null) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) T result = (T)e.value; return result; } } // 返回默认值，默认返回null,可以通过子类重写该方法修改默认返回值 return setInitialValue(); } // 获取当前线程的ThreadLocalMap ThreadLocalMap getMap(Thread t) { // 返回Thread中的ThreadLocalMap return t.threadLocals; } /** * ThreadLocal中用来存储\u0026lt;当前线程,存储的值\u0026gt;键值对 */ static class ThreadLocalMap { // hash表 private Entry[] table; // 返回ThreadLocalMap中的hash表 private Entry getEntry(ThreadLocal\u0026lt;?\u0026gt; key) { // 计算 hashKey int i = key.threadLocalHashCode \u0026amp; (table.length - 1); // 从hashTable Entry[]中获取对应的ThreadLocal引用 Entry e = table[i]; if (e != null \u0026amp;\u0026amp; e.get() == key) // Entry命中的条件是e存在与Entry \u0026amp;\u0026amp; e的引用和key相同 return e; else // Entry未命中（e不存在||存在hash冲突导致e的引用和key不同），向后寻找可以命中的Entry或者返回最后一个null结点 return getEntryAfterMiss(key, i, e); } // 由于hash冲突导致的未命中，向后寻找可以命中的Entry，或者 private Entry getEntryAfterMiss(ThreadLocal\u0026lt;?\u0026gt; key, int i, Entry e) { Entry[] tab = table; int len = tab.length; // e为空就直接返回null // e不为空则向后寻找可以命中的Entry while (e != null) { ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == key) // hash命中，返回e return e; if (k == null) // 找到最后一个可以存放 expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; } return null; } } /** * 还没有通过set创建ThreadLocalMap时，使用get方法，默认创建一个ThreadLocalMap * @return the initial value */ private T setInitialValue() { // ThreadLocal类默认返回null T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else // 创建一个新的ThreadLocalMap createMap(t, value); return value; } /** * ThreadLocal中value默认值，可以通过子类重写该方法修改get()默认返回的值 * @return the initial value for this thread-local */ protected T initialValue() { return null; } } ThreadLocal.remove()方法以及get相关操作：\npublic class ThreadLocal\u0026lt;T\u0026gt; { public void remove() { ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); } static class ThreadLocalMap { private void remove(ThreadLocal\u0026lt;?\u0026gt; key) { Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode \u0026amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { if (e.get() == key) { e.clear(); expungeStaleEntry(i); return; } } } private int expungeStaleEntry(int staleSlot) { Entry[] tab = table; int len = tab.length; // 清除Entry中staleSlot下标的值 tab[staleSlot].value = null; tab[staleSlot] = null; size--; // 整理hashTable（Entry） Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) { ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == null) { e.value = null; tab[i] = null; size--; } else { int h = k.threadLocalHashCode \u0026amp; (len - 1); if (h != i) { tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; } } } return i; } } } ThreadLocal总结 对于一个Thread来说，ThreadLocal只是其一个属性变量，其中使用ThreadLocalMap存放了该线程所存放的所有线程变量，主要以\u0026lt;ThreadLocal, value\u0026gt;形式存储。 Thread与ThreadLocal是一对一的关系，也就是说Thread与ThreadLocalMap是一对一的关系。 ThreadLocal为什么要使用ThreadLocalMap? 因为一个Thread中可能存放多个线程变量，存在一对多的关系，所以一个Thread要能够对应多个线程变量，线程变量还需要与自己的value一对一对应。 哈希冲突存在两种解决方法：开放寻址法和链表法。ThreadLocalMap中的Entry为什么要使用开放寻址法？使用开放寻址法解决冲突的散列表，装载因子的上限不能太大。这也导致这种方法比链表法更浪费内存空间。但是另一方面，链表法需要额外的空间，当结点规模较小时，开放寻址法较为节省空间。对于ThreadLocal线程变量来讲，将节省的指针空间用来扩大散列表的规模，可使装填因子变小，这又减少了开放寻址法中的冲突，从而提高平均查找速度。 对于ThreadLocal中的ThreadLocalMap、ThreadLocalMap.Entry有疑问，看看hashTable的原理，可以很好的帮助理解ThreadLocal。 下图可以很好的帮助理解ThreadLocal变量、ThreadLocal.ThreadLocalMap以及Entry之间的关系。 InheritableThreadLocal分析 InheritableThreadLocal使用背景 其实上述讲解ThreadLocal的时候，使用到的示例中展示了ThreadLocal无法在父子线程之间传递ThreadLocal变量。但是有些时候我们是需要将父线程中的某些线程变量传递给子线程的，比如父线程的线程变量存储着用户信息，此时父线程开启了多个子线程，子线程需要把用户信息以及一些业务信息存储到数据库中，那么这个时候就需要把用户的信息传递给子线程的；对于这种场景有两种解决方案，方案一就是把用户信息提取为一个普通局部变量，作为参数传递给子线程的方法中；方案二则是将用户信息直接传给子线程，但是单纯凭借ThreadLocal无法实现变量传递，此时InheritableThreadLocal就可以开始发挥作用了。\nInheritableThreadLocal使用实例 public class ThreadlocalTest { private ThreadLocal\u0026lt;String\u0026gt; threadLocal = new InheritableThreadLocal\u0026lt;\u0026gt;(); public void test() throws InterruptedException { threadLocal.set(\u0026#34;parent\u0026#34;); Thread thread = new Thread(() -\u0026gt; { System.out.println(Thread.currentThread().getName() + \u0026#34; ===\u0026gt; \u0026#34; + threadLocal.get()); threadLocal.set(\u0026#34;child\u0026#34;); System.out.println(Thread.currentThread().getName() + \u0026#34; ===\u0026gt; \u0026#34; + threadLocal.get()); }); thread.start(); thread.join(); System.out.println(Thread.currentThread().getName() + \u0026#34; ===\u0026gt; \u0026#34; + threadLocal.get()); } public static void main(String[] args) throws InterruptedException { new ThreadlocalTest().test(); } } 输出结果\nThread-0 ===\u0026gt; parent Thread-0 ===\u0026gt; child main ===\u0026gt; parent 源码分析 先看下InheritableThreadLocal类，以及它所重写ThreadLocal的setMap和getMap方法：\npublic class InheritableThreadLocal\u0026lt;T\u0026gt; extends ThreadLocal\u0026lt;T\u0026gt; { /** * 创建子线程的时候浅拷贝返回父线程持有的InheritableThreadLocal.ThreadLocalMap.Entry.value的引用 * 如果想要深拷贝value，则需要子类重写该方法 * * @param parentValue the parent thread\u0026#39;s value * @return the child thread\u0026#39;s initial value */ protected T childValue(T parentValue) { return parentValue; } /** * 返回线程t的inheritableThreadLocals变量 * 使用时利用向下转型获取InheritableThreadLocal变量，所以InheritableThreadLocal.get()只会获取对应线程的inheritableThreadLocals变量 * * @param t the current thread */ ThreadLocalMap getMap(Thread t) { return t.inheritableThreadLocals; } /** * 设置线程t的inheritableThreadLocals变量 * 使用时利用向下转型设置InheritableThreadLocal变量，所以InheritableThreadLocal.set()只会设置对应线程的inheritableThreadLocals变量 * @param t the current thread * @param firstValue value for the initial entry of the table. */ void createMap(Thread t, T firstValue) { t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue); } } 那子线程又是如何获取到父线程的ThreadLocal变量呢，查看Thread类中新建一个线程源码：\npublic class Thread implements Runnable { /* * InheritableThreadLocal values pertaining to this thread. This map is * maintained by the InheritableThreadLocal class. */ ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; public Thread(Runnable target) { init(null, target, \u0026#34;Thread-\u0026#34; + nextThreadNum(), 0); } private void init(ThreadGroup g, Runnable target, String name, long stackSize) { init(g, target, name, stackSize, null, true); } /** * Initializes a Thread. 初始化线程 * * @param g the Thread group * @param target the object whose run() method gets called * @param name the name of the new Thread * @param stackSize the desired stack size for the new thread, or * zero to indicate that this parameter is to be ignored. * @param acc the AccessControlContext to inherit, or * AccessController.getContext() if null * @param inheritThreadLocals if {@code true}, inherit initial values for * inheritable thread-locals from the constructing thread 是否从调用方继承InheritableThreadLocal变量 */ private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) { if (name == null) { throw new NullPointerException(\u0026#34;name cannot be null\u0026#34;); } this.name = name; // 当前调用者线程为父线程 Thread parent = currentThread(); SecurityManager security = System.getSecurityManager(); if (g == null) { /* Determine if it\u0026#39;s an applet or not */ /* If there is a security manager, ask the security manager what to do. */ if (security != null) { g = security.getThreadGroup(); } /* If the security doesn\u0026#39;t have a strong opinion of the matter use the parent thread group. */ if (g == null) { g = parent.getThreadGroup(); } } /* checkAccess regardless of whether or not threadgroup is explicitly passed in. */ g.checkAccess(); /* * Do we have the required permissions? */ if (security != null) { if (isCCLOverridden(getClass())) { security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION); } } g.addUnstarted(); this.group = g; this.daemon = parent.isDaemon(); this.priority = parent.getPriority(); if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); this.target = target; setPriority(priority); // 如果inheritThreadLocals == true（默认new Thread都是true）并且父线程存在InheritableThreadLocal变量， // 当前线程将会复制父线程的InheritableThreadLocal到本线程中 if (inheritThreadLocals \u0026amp;\u0026amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); /* Stash the specified stack size in case the VM cares */ this.stackSize = stackSize; /* Set thread ID */ tid = nextThreadID(); } } public class ThreadLocal\u0026lt;T\u0026gt; { // 子线程复制父线程的ThreadLocal变量 static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) { return new ThreadLocalMap(parentMap); } static class ThreadLocalMap { // 深拷贝ThreadLocalMap,浅拷贝Entry中的value private ThreadLocalMap(ThreadLocalMap parentMap) { Entry[] parentTable = parentMap.table; int len = parentTable.length; setThreshold(len); table = new Entry[len]; for (int j = 0; j \u0026lt; len; j++) { Entry e = parentTable[j]; if (e != null) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) ThreadLocal\u0026lt;Object\u0026gt; key = (ThreadLocal\u0026lt;Object\u0026gt;) e.get(); if (key != null) { // 拷贝父线程持有的InheritableThreadLocal.ThreadLocalMap.Entry.value // InheritableThreadLocal默认使用浅拷贝（直接返回引用） // 如果需要深拷贝，则需要InheritableThreadLocal子类重写childValue方法 Object value = key.childValue(e.value); Entry c = new Entry(key, value); // 计算下一个hash下标 int h = key.threadLocalHashCode \u0026amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; } } } } } } InheritableThreadLocal 拷贝机制 InheritableThreadLocal与ThreadLocal的区别就在于父线程可以将InheritableThreadLocal变量深拷贝一份到子线程中，但是Entry中的vaue则是浅拷贝，也就是说假如子线程通过get()方法获取到对应的value之后，直接修改value的值，父线程中获取到的value的值也会进行相应的修改，如下：\npublic class ThreadlocalTest { private ThreadLocal\u0026lt;Person\u0026gt; threadLocal = new InheritableThreadLocal\u0026lt;\u0026gt;(); public void test() throws InterruptedException { threadLocal.set(new Person(\u0026#34;a\u0026#34;, 13)); Thread thread = new Thread(() -\u0026gt; { System.out.println(Thread.currentThread().getName() + \u0026#34; ===\u0026gt; \u0026#34; + threadLocal.get().toString() + \u0026#34;===\u0026gt;\u0026#34; +threadLocal.get().hashCode()); threadLocal.get().setAge(15); System.out.println(Thread.currentThread().getName() + \u0026#34; ===\u0026gt; \u0026#34; + threadLocal.get().toString() + \u0026#34;===\u0026gt;\u0026#34; +threadLocal.get().hashCode()); }); thread.start(); thread.join(); System.out.println(Thread.currentThread().getName() + \u0026#34; ===\u0026gt; \u0026#34; + threadLocal.get().toString() + \u0026#34;===\u0026gt;\u0026#34; +threadLocal.get().hashCode()); threadLocal.remove(); System.out.println(); } public static void main(String[] args) throws InterruptedException { new ThreadlocalTest().test(); } } 输出结果：\nThread-0 ===\u0026gt; Person{name=\u0026#39;a\u0026#39;, age=13}===\u0026gt;2024651980 Thread-0 ===\u0026gt; Person{name=\u0026#39;a\u0026#39;, age=15}===\u0026gt;2024651980 main ===\u0026gt; Person{name=\u0026#39;a\u0026#39;, age=15}===\u0026gt;2024651980 在子线程中修改了get()获取到的value中的属性值，父线程通过get()获取到的value也发生了改变，且父子线程中get()获取到的value的地址是相同的。\nInheritableThreadLocal总结 相比较ThreadLocal，InheritableThreadLocal完成了父子线程之间线程变量的传递，实现方案是父线程创建子线程的时候，父线程本身新建了一个InheritableThreadLocal变量存放inheritableThreadLocals中，子线程从父线程拷贝inheritableThreadLocals属性，而InheritableThreadLocal继承自ThreadLocal，使得其完美承载了ThreadLocal的属性，只是重写其中的setMap和getMap方法后使得其返回的map为线程的inheritableThreadLocals变量。 父线程新建子线程的时候，ThreadLocalMap是深拷贝，但是Entry中的value是浅拷贝，也就意味着子线程通过get()获取到的value修改之后，父线程再通过get()获取value也是修改过后的。 思考 目前已经很少出现通过自己手动new Thread启动线程了，一般都是通过ThreadPool实现。在使用线程池的情况下，因为线程池是复用线程，不会重复创建，而InheritableThreadLocal是在创建子线程的时候才会将父线程的值复制到子线程中，但是线程池不会重复创建，所以多次使用后，仍然记录的是第一次提交任务时的外部线程的值，会造成数据的错误。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/threadlocal%E5%92%8Cinheritablethreadlocal%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","summary":"ThreadLocal分析 什么是ThreadLocal ThreadLocal是一种变量类型，与普通的局部变量和全局变量所不同的是，Threa","title":"ThreadLocal和InheritableThreadLocal源码分析"},{"content":"概述 UML是什么 UML 是一种为面向对象开发系统的产品进行说明、可视化、和编制文档的标准语言；作为一种模型语言，它使开发人员专注于建立产品的模型和结构，而不是选用什么程序语言和算法实现；UML 是不同于其他常见的编程语言，如C + +，Java中，COBOL等，它是一种绘画语言，用来做软件蓝图；\nUML的目标 UML 的目标是定义一些通用的建模语言并对这些建模语言做出简单的说明，这样可以让建模者理解与使用。我们不将 UML 作为一个开发方法，而是随着流程做一个成功的系统。现在我们可以明确的了解 UML 的目标就是 UML 被定义为一个简单的建模机制，帮助我们按照实际情况或者按照我们需要的样式对系统进行可视化；提供一种详细说明系统的结构或行为的方法；给出一个指导系统构造的模板；对我们所做出的决策进行文档化。\n用例图（UseCase Diagrams） 用例图主要回答了两个问题：1、是谁用软件。2、软件的功能。从用户的角度描述了系统的功能，并指出各个功能的执行者，强调用户的使用者，系统为执行者完成哪些功能。\n类图（Class Diagrams） 用户根据用例图抽象成类，描述类的内部结构和类与类之间的关系，是一种静态结构图。 在UML类图中，常见的有以下几种关系: 泛化（Generalization）, 实现（Realization），关联（Association)，聚合（Aggregation），组合(Composition)，依赖(Dependency)。　各种关系的强弱顺序： 泛化 = 实现 \u0026gt; 组合 \u0026gt; 聚合 \u0026gt; 关联 \u0026gt; 依赖\n对象图（Object Diagrams） 描述的是参与交互的各个对象在交互过程中某一时刻的状态。对象图可以被看作是类图在某一时刻的实例。\n状态图（Statechart Diagrams） 是一种由状态、变迁、事件和活动组成的状态机，用来描述类的对象所有可能的状态以及时间发生时状态的转移条件。\n活动图（Activity Diagrams） 是状态图的一种特殊情况，这些状态大都处于活动状态。本质是一种流程图，它描述了活动到活动的控制流。　交互图强调的是对象到对象的控制流，而活动图则强调的是从活动到活动的控制流。活动图是一种表述过程基理、业务过程以及工作流的技术。它可以用来对业务过程、工作流建模，也可以对用例实现甚至是程序实现来建模。\n序列图-时序图（Sequence Diagrams） 交互图的一种，描述了对象之间消息发送的先后顺序，强调时间顺序。　序列图的主要用途是把用例表达的需求，转化为进一步、更加正式层次的精细表达。用例常常被细化为一个或者更多的序列图。同时序列图更有效地描述如何分配各个类的职责以及各类具有相应职责的原因。\n协作图（Collaboration Diagrams） 交互图的一种，描述了收发消息的对象的组织关系，强调对象之间的合作关系。时序图按照时间顺序布图，而写作图按照空间结构布图\n构件图（Component Diagrams） 构件图是用来表示系统中构件与构件之间，类或接口与构件之间的关系图。其中，构建图之间的关系表现为依赖关系，定义的类或接口与类之间的关系表现为依赖关系或实现关系。\n部署图（Deployment Diagrams） 描述了系统运行时进行处理的结点以及在结点上活动的构件的配置。强调了物理设备以及之间的连接关系。部署模型的目的：描述一个具体应用的主要部署结构，通过对各种硬件，在硬件中的软件以及各种连接协议的显示，可以很好的描述系统是如何部署的；平衡系统运行时的计算资源分布；可以通过连接描述组织的硬件网络结构或者是嵌入式系统等具有多种硬件和软件相关的系统运行模型。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/uml-unified-modeling-language/","summary":"概述 UML是什么 UML 是一种为面向对象开发系统的产品进行说明、可视化、和编制文档的标准语言；作为一种模型语言，它使开发人员专注于建立产品的模型和","title":"UML统一建模语言"},{"content":"Axure9激活 Licensee:Freecrackdownload.comKey:5vYpJgQZ431X/G5kp6jpOO8Vi3TySCBnAslTcNcKkszfPH7jaM4eKM8CrALBcEC1\nWindows通过cmd查看网络端口占用情况 对于一些使用java后端服务在没有关闭端口的情况下被关闭，则可能导致端口一直占用，处理方案： 一、列出所有端口的情况，找到被占用的端口 ：netstat -ano 二、找对应的PID： netstat -aon|findstr \u0026ldquo;8440\u0026rdquo; 三、查找具体的占用进程：tasklist|findstr \u0026ldquo;28712\u0026rdquo; 四、结束进程：taskkill /f /t /im java.exe\nwin10下idea终端中使用git中文乱码解决方案 方案一 系统变量中添加LESSCHARSET=utf-8 在idea中使用powershell/cmd终端做git操作的时候，git log会显示中文乱码，查阅网上资料后发现是因为git log 默认使用 less 分页，需要 bash 对 less 命令进行 utf-8 编码 ，可以通过在系统环境变量中添加LESSCHARSET=utf-8，如下： 此时再使用idea终端中的powershell进行git log操作，结果如下： 方案二 idea 中使用git bash 这个方法比较粗暴，直接在idea的设置中设置终端为git bash即可 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E5%B7%A5%E5%85%B7/windows-sofrware/","summary":"Axure9激活 Licensee:Freecrackdownload.comKey:5vYpJgQZ431X/G5kp6jpOO8Vi3TySCBnAslTcNcKkszfPH7jaM4eKM8CrALBcEC1 Windows通过cmd查看网络端口占用情况 对于一些使用java后端服务在没有关闭端口的情况下被关闭，则可能导致端口一直占","title":"win10软件使用"},{"content":"这两天在公司优化一个sql的时候碰到了一个诡异的事——一个表中的一个唯一性索引在更换了最左边的字段后，根据最左边字段为where后面的查询条件时，查看执行计划发现有些时候有用到索引，而有些时候则没有用到索引。\n现象具体说明 出现问题的表结构以及其字符集如下： alter table sodr_po_header add UNIQUE KEY sodr_po_header_u1(po_num, po_type_id, snapshot_flag,tenant_id); show index from sodr_po_header; explain select * from sodr_po_header where po_num = \u0026#39;PO20190619000014\u0026#39;;// 复合索引的最左字段 执行上面的sql语句后，有如下结果：sodr_po_header表的索引为： 执行计划结果为： 显然此时是根据索引进行查找的。\n然后更换复合索引字段顺序：\ndrop index sodr_po_header_u1 on sodr_po_header; alter table sodr_po_header add UNIQUE KEY sodr_po_header_u1(po_type_id, po_num, snapshot_flag,tenant_id); show index from sodr_po_header; explain select * from sodr_po_header where po_type_id = 9; // 复合索引的最左字段 执行上面4条sql后，表的索引情况： 执行计划结果： 此时执行计划显示并未使用索引进行查找。\n为什么会有上面这种现象 如上，为了找到会出现这种“bug”的原因，我额外建了一张表teacher用于测试，其表结构和字符集如下： alter table teacher add UNIQUE KEY dept_uk_tt(tname, tid, gender); show index from teacher; explain select * from teacher where tname = \u0026#39;tw\u0026#39;; // 复合索引最左字段 teacher表的索引情况： 执行计划结果： 此时是有用到索引的。\n更换复合索引中字段的顺序：\ndrop index dept_uk_tt on teacher; alter table teacher add UNIQUE KEY dept_uk_tt(tid, tname, gender); show index from teacher; explain select * from teacher where tid = 3; // 复合索引最左字段 teacher表的索引情况： 执行计划结果： 发现还是用到了索引进行查询操作，这个时候真的只能用上“震惊”二字了。\n总结 目前我还是没有什么头绪，如果有大佬看到了这篇文章并且有解决方案或者任何提议，希望在评论里给我留言。当然，如果我找到了原因，同样会更新本文。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/%E4%B8%80%E6%AC%A1%E8%AF%A1%E5%BC%82%E7%9A%84sql%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E5%88%86%E6%9E%90/","summary":"这两天在公司优化一个sql的时候碰到了一个诡异的事——一个表中的一个唯一性索引在更换了最左边的字段后，根据最左边字段为where后面的查询条","title":"一次诡异的sql索引失效分析"},{"content":"mybatis mapper中的注释，查询条件中的注释不建议使用 \u0026ndash;注释符，因为一旦出现后续没有查询条件时，pageHelper分页拼接的sql将会失效，即order by 和limit 会失效\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/%E4%BD%BF%E7%94%A8pagehelper%E5%88%86%E9%A1%B5%E5%A4%B1%E6%95%88/","summary":"mybatis mapper中的注释，查询条件中的注释不建议使用 \u0026ndash;注释符，因为一旦出现后续没有查询条件时，pageHelper分页拼接的sql","title":"使用PageHelper分页失效"},{"content":"单体架构 单体架构就是把所有的功能模块编写在一个项目中，最终打包成一个war/jar包，然后进行部署\n优点 部署简单：由于没有完整的结构体，可以直接部署在一份服务器上即可 技术单一：项目不需要复杂的技术栈，往往一套熟悉的技术栈就可以完成开发 用人成本低：单个程序员可以完成业务接口到数据库的整个流程 缺点 系统启动慢：一个进程包含了所有的业务逻辑，涉及到的启动模块过多，导致系统的启动时间周期过长 系统错误隔离性差：可用性差，任何一个模块的错误均可能造成整个系统的宕机 可伸缩性差：系统的扩容只能对这个应用进行扩容，不能做到对莫讴歌功能点进行扩容 线上问题修复周期长：任何一个线上问题修复需要对整个应用系统全面升级 阻碍技术创新：对于单体应用来说，技术是在开发之前经过慎重评估后选定的，每个团队成员都必须使用相同的开发语言、持久化存储及消息系统。 微服务架构 微服务架构风格是一种将一个单一应用程序开发为一组小型服务的方法，每个服务运行在自己的进程中，服务间通信采用轻量级通信机制。这些服务围绕业务能力构建并且可通过全自动部署机制独立部署。这些服务共用一个最小型的集中式的管理，服务可用不同的语言开发，使用不同的数据存储技术。\n优点 易于开发和维护：一个微服务只会关注一个特定的业务功能，所以他的业务清晰，代码量少，开发和维护单个微服务相当简单，而整个应用是若干个微服务构建而成的，所以整个应用也被维持在一个可控状态 单个微服务启动较快：单个微服务代码量较少，所以启动会比较快 局部修改容易部署 技术栈不受限 按需收缩：可根据需求，实现细粒度的扩展，例如：系统中的某个微服务遇到了瓶颈，可以结合这个微服务的业务特点，增加内存，升级CPU或者增加节点 可以承受高并发 缺点 运维要求较高：更多的服务意味着更多的运维投入，在单体架构中，只需要保证一个应用的正常运行，而在微服务中，需要保证几十甚至几百个服务正常运行与协作，这给运维带来了很大的挑战 分布式固有的复杂性：使用微服务构建的是分布式系统，对于一个分布式系统，系统容错，网络延迟等都会带来巨大的挑战 接口调整成本高：微服务之间通过接口进行通信，如果修改某一微服务API，肯呢个所有使用该接口的微服务都需要调整 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%8D%95%E4%BD%93%E6%9E%B6%E6%9E%84%E5%92%8C%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9/","summary":"单体架构 单体架构就是把所有的功能模块编写在一个项目中，最终打包成一个war/jar包，然后进行部署 优点 部署简单：由于没有完整的结构体，可以直","title":"单体架构和微服务架构的优缺点"},{"content":"对于多个系统之间的数据交互，存在以下场景会出现问题：\n系统A调用系统B，系统B逻辑处理时间过程，导致系统A直接报错回滚，最后系统A action失败，而系统B action成功。 系统A中同一笔数据在并发的情况下可能同时调用系统B，此时系统B在接收到第一次传来的数据进行处理后，处理第二次数据直接报错返回，可能存在系统A先接收到系统B返回的报错信息，而后返回的成功信息由于乐观锁导致直接回滚系统A中对应线程的处理逻辑；从而也导致系统A action失败，系统B action成功 对于上面两种场景问题，比较好的处理方式是：被调用系统B需要进行幂等处理，系统A需要添加一个补偿方法，在不知道成功或失败的情况下，可以再次调用系统B获取最新的结果从而进行相应的业务逻辑操作。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%A4%9A%E7%B3%BB%E7%BB%9F%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/","summary":"对于多个系统之间的数据交互，存在以下场景会出现问题： 系统A调用系统B，系统B逻辑处理时间过程，导致系统A直接报错回滚，最后系统A action","title":"多系统数据一致性问题"},{"content":"在当今分布式架构中，缓存因其高并发、高性能等特点广泛应用。通常，在读取缓存时，我们遵循如下流程：\n然而，当涉及到数据更新时，究竟是先更新缓存还是先更新数据库？或者在更新时是否需要删除缓存？这些问题都需要在实际场景中仔细考量。本文将详细探讨几种常见的缓存更新策略，并对不完善之处进行补充说明。\n一、理论基础：缓存过期策略 从理论上讲，为缓存设置过期时间是一种确保最终数据一致性的手段。\n原理：对写操作始终以数据库为准，缓存仅作为加速手段。如果数据库更新成功，而缓存更新失败，只要数据在缓存中的过期时间到了，后续读请求就会从数据库中读取最新数据并重新填充缓存。 局限：该方法虽然能保证最终一致性，但在业务对实时性要求较高的场景下，依赖过期时间可能会引发短时间内的数据不一致问题。 因此，本文接下来的讨论将不依赖缓存自动过期，而是介绍在业务层面主动保证数据一致性的几种更新策略。\n二、常见的缓存更新策略 1. 更新数据库后直接更新缓存 流程：\n更新数据库。 紧接着更新缓存。 问题分析：\n线程安全性不足：假设两个请求 A 和 B 同时进行数据更新，可能出现如下情况： A 请求先将新数据写入缓存，随后 B 请求更新数据库，但由于更新缓存操作延迟，缓存中依然保存 A 的数据。 最终，数据库中存储的是 B 的数据，而缓存中却仍然保留 A 的数据，导致脏数据出现。 性能浪费：在写操作频繁而读操作较少的场景下，频繁更新缓存反而增加了系统的额外负载，得不偿失。 总结：该策略在实际生产环境中通常不被推荐，除非能确保并发更新的严格顺序和线程安全性。\n2. 先删除缓存后再更新数据库 流程：\n删除缓存数据； 更新数据库数据。 潜在风险：\n设想存在如下并发场景：\n请求 A 执行更新操作，先删除缓存。 请求 B 此时执行查询操作，因缓存已被删除，从数据库中读取旧数据，并将其回写到缓存中。 请求 A 随后更新数据库成功，但缓存中依然存在 B 回填的旧数据，最终导致数据库和缓存数据不一致。 补充改进：延时双删策略\n为解决上述问题，可以引入延时双删：\n在更新数据库后，除了立即删除缓存外，再过一段设定的延时后再次执行删除操作。 此举可确保那些因并发查询而意外写入的脏数据能够被及时清除。 如延时删除依然失败，可以通过引入消息队列（MQ）等重试机制进行异步处理。 3. 更新数据库后直接删除缓存（延迟删除策略） 流程：\n先更新数据库数据； 数据库更新成功后，删除缓存数据。 优势与原理：\n国外提出的 Cache-Aside Pattern 就是这种思路，主要包含以下三个步骤：\n失效：应用程序首先尝试从缓存中获取数据，若未命中则从数据库中加载数据后写入缓存； 命中：直接从缓存返回数据； 更新：先将数据写入数据库，成功后使缓存失效（删除缓存）。 Facebook 在论文 Scaling Memcache at Facebook 中也采用了这种先更新数据库再删除缓存的策略。与“先删除缓存再更新数据库”的方式相比，它少了一次删除缓存操作，从而能有效降低因并发操作而引起的脏数据风险。\n可能出现的极端情况：\n尽管理论上这种方式能保持数据一致，但在如下极端场景下仍可能产生问题：\n请求 A 发起查询操作时，缓存恰好失效； 请求 A 从数据库中读取到旧数据并将其写入缓存； 请求 B 正在更新数据库并随后删除缓存； 如果请求 A 的读取和回写操作延迟超过 B 的缓存删除时间，则有可能将旧数据再次写入缓存。 但实际上，由于数据库的读操作通常比写操作快，这种情况的发生概率较低，通过适当的系统调优可以进一步降低风险。\n4. 基于日志监听的异步删除缓存 核心思想：\n利用数据库的变更日志（如 BigLog 或类似系统）实现缓存的异步删除，具体流程如下：\n当数据库更新后，不立即同步更新缓存； 通过监听数据库变更日志，捕捉数据变更事件； 根据变更事件异步删除相应的缓存数据，确保后续查询能够获取最新的数据。 优势：\n异步化处理：降低了前端更新时的延时，减小了因并发操作引起的不一致概率。 高容错性：结合消息队列等机制，可以实现对删除失败的重试，从而更好地保障数据一致性。 挑战：\n实现复杂度较高，需要部署和维护日志监听、消息队列等中间件。 在高并发场景下，异步延迟可能会导致短暂的不一致，需根据业务需求合理调整延时策略和重试机制。 三、总结与实践建议 不同场景下，选择合适的缓存更新策略至关重要，以下是几点建议：\n读多写少场景：\n缓存能显著提升读取性能。推荐采用“更新数据库后直接删除缓存”的策略，并结合延时删除机制，降低并发时脏数据产生的可能性。\n写操作频繁场景：\n为减少频繁更新缓存带来的性能开销，可以考虑使用“延时双删”策略或基于日志监听的异步删除方式，以确保数据在并发写入情况下的最终一致性。\n综合保障：\n除了更新策略之外，合理设置缓存过期时间作为补充手段，也是确保数据一致性的重要措施。此外，针对具体业务场景，可引入分布式锁、幂等性设计等手段进一步提升系统的可靠性。\n总之，在设计分布式缓存更新方案时，需要权衡性能、实时性与数据一致性三者之间的关系，选择最适合业务需求的策略，并根据实际运行情况不断进行调优和优化。\n","permalink":"https://luolin1024.github.io/2024/02/how-to-ensure-consistency-between-database-and-cache-double-writing/","summary":"在当今分布式架构中，缓存因其高并发、高性能等特点广泛应用。通常，在读取缓存时，我们遵循如下流程： 然而，当涉及到数据更新时，究竟是先更新缓存还","title":"如何保证数据库与缓存双写一致：策略解析与实践指南"},{"content":"循环依赖 对于java来讲，我们一般都是通过set来达到循环依赖的效果，比如我们存在两个类A、B，这两个类中互有属性：\nclass A{ private B b; public B getB() { return b; } public void setB(B b) { this.b = b; } } class B{ private A a; public A getA() { return a; } public void setA(A a) { this.a = a; } } 这个时候我们使用到了如下代码：\nA a = new A(); B b = new B(); a.setB(b); b.setA(a); System.out.println(a == a.getB().getA()); // true 此时我们就通过简单的set达到了循环依赖的效果\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/spring/%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E5%92%8Cspring%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/","summary":"循环依赖 对于java来讲，我们一般都是通过set来达到循环依赖的效果，比如我们存在两个类A、B，这两个类中互有属性： class A{ private B b; public B getB() { return b; }","title":"循环依赖和Spring循环依赖"},{"content":"类型 1. 基础类型 1.1. 布尔类型 //布尔类型的关键字为bool,值为true或false，不可写为0或1 var v1 bool v1=true //接受表达式判断赋值，不支持自动或强制类型转换 v2:=(1==2) 1.2. 整型 //1、类型表示 //int和int32为不同类型，不会自动类型转换需要强制类型转换 //强制类型转换需注意精度损失（浮点数→整数），值溢出（大范围→小范围） var v2 int32 v1:=64 v2=int32(v1) //2、数值运算,支持“+,-,*,/和%” 5%3 //求余 //3、比较运算,“\u0026lt;,\u0026gt;,==,\u0026gt;=,\u0026lt;=,!=” //不同类型不能进行比较例如int和int8，但可以与字面常量（literal）进行比较 var i int32 var j int64 i,j=1,2 if i==j //编译错误，不同类型不能进行比较 if i==1 || j==2 //编译通过，可以与字面常量（literal）进行比较 //4、位运算 //Go(^x)取反与C语言(~x)不同，其他类似，具体见下表 1.3. 浮点型 //1、浮点型分为float32(类似C中的float)，float64(类似C中的double) var f1 float32 f1=12 //不加小数点，被推导为整型 f2:=12.0 //加小数点，被推导为float64 f1=float32(f2) //需要执行强制转换 //2、浮点数的比较 //浮点数不是精确的表达方式，不能直接使用“==”来判断是否相等，可以借用math的包math.Fdim 1.4. 复数类型 //1、复数的表示 var v1 complex64 v1=3.2+12i //v1 v2 v3 表示为同一个数 v2:=3.2+12i v3:=complex(3.2,12) //2、实部与虚部 //z=complex(x,y),通过内置函数实部x=real(z),虚部y=imag(z) 1.5. 字符串 //声明与赋值 var str string str=\u0026#34;hello world\u0026#34; 1.6. 字符类型 //1、byte，即uint8的别名 //2、rune，即Unicode 1.7. 错误类型（error） 2. 复合类型 2.1. 数组(array) 数组表示同一类型数据，数组长度定义后就不可更改，长度是数组内的一个内置常量，可通过len()来获取。\n//1、创建数组 var array1 [5]int //声明：var 变量名 类型 var array2 [5]int=[5]int{1,2,3,4,5} //初始化 array3：=[5]int{1,2,3,4,5} //直接用“：=”赋值 [3][5]int //二维数组 [3]*float //指针数组 //2、元素访问 for i,v:=range array{ //第一个返回值为数组下标，第二个为元素的值 } //3、值类型 //数组在Go中作为一个值类型，值类型在赋值和函数参数传递时，只复制副本，因此在函数体中并不能改变数组的内容，需用指针来改变数组的值。 2.2. 切片(slice) 数组在定义了长度后无法改变，且作为值类型在传递时产生副本，并不能改变数组元素的值。因此切片的功能弥补了这个不足，切片类似指向数组的一个指针。可以抽象为三个变量：指向数组的指针；切片中元素的个数(len函数)；已分配的存储空间(cap函数)。 //1、创建切片 //a)基于数组创建 var myArray [5]int=[5]{1,2,3,4,5} var mySlice []int=myArray[first:last] slice1=myArray[:] //基于数组所有元素创建 slice2=myArray[:3] //基于前三个元素创建 slice3=myArray[3:] //基于第3个元素开始后的所有元素创建 //b)直接创建 slice1:=make([]int,5) //元素初始值为0，初始个数为5 slice2:=make([]int,5,10) //元素初始值为0，初始个数为5，预留个数为10 slice3:=[]int{1,2,3,4,5} //初始化赋值 //c)基于切片创建 oldSlice:=[]int{1,2,3,4,5} newSlice:=oldSlice[:3] //基于切片创建，不能超过原切片的存储空间(cap函数的值) //2、元素遍历 for i,v:=range slice{ //与数组的方式一致，使用range来遍历 //第一个返回值(i)为索引，第二个为元素的值(v) } //3、动态增减元素 //切片分存储空间(cap)和元素个数(len)，当存储空间小于实际的元素个数，会重新分配一块原空间2倍的内存块，并将原数据复制到该内存块中，合理的分配存储空间可以以空间换时间，降低系统开销。 //添加元素 newSlice:=append(oldSlice,1,2,3) //直接将元素加进去，若存储空间不够会按上述方式扩容。 newSlice1:=append(oldSlice1,oldSlice2...) //将oldSlice2的元素打散后加到oldSlice1中，三个点不可省略。 //4、内容复制 //copy()函数可以复制切片，如果切片大小不一样，按较小的切片元素个数进行复制 slice1:=[]int{1,2,3,4,5} slice2:=[]int{6,7,8} copy(slice2,slice1) //只会复制slice1的前三个元素到slice2中 copy(slice1,slice1) //只会复制slice2的三个元素到slice1中的前三个位置 2.3. 键值对(map) map是一堆键值对的未排序集合。\n//1、先声明后创建再赋值 var map1 map[键类型] 值类型 //创建 map1=make(map[键类型] 值类型) map1=make(map[键类型] 值类型 存储空间) //赋值 map1[key]=value // 直接创建 m2 := make(map[string]string) // 然后赋值 m2[\u0026#34;a\u0026#34;] = \u0026#34;aa\u0026#34; m2[\u0026#34;b\u0026#34;] = \u0026#34;bb\u0026#34; // 初始化 + 赋值一体化 m3 := map[string]string{ \u0026#34;a\u0026#34;: \u0026#34;aa\u0026#34;, \u0026#34;b\u0026#34;: \u0026#34;bb\u0026#34;, } //2、元素删除 //delete()函数删除对应key的键值对，如果key不存在，不会报错；如果value为nil，则会抛出异常(panic)。 delete(map1,key) //3、元素查找 value,ok:=myMap[key] if ok{//如果找到 //处理找到的value值 } //遍历 for key,value:=range myMap{ //处理key或value } map可以用来判断一个值是否在切片或数组中。\n// 判断某个类型（假如为myType）的值是否在切片或数组（假如为myList）中 // 构造一个map,key的类型为myType,value为bool型 myMap := make(map[myType]bool) myList := []myType{value1, value2} // 将切片中的值存为map中的key（因为key不能重复）,map的value都为true for _, value := range myList { myMap[value] = true } // 判断valueX是否在myList中，即判断其是否在myMap的key中 if _, ok := myMap[valueX]; ok { // 如果valueX 在myList中，执行后续操作 } 2.4. 指针(pointer) 具体参考Go语言指针详解\n2.5. 结构体(struct) 具体参考Go面向对象编程之结构体\n2.6. 接口(interface) 具体参考Go面向对象编程之接口\n2.7. 通道(chan) 具体参考Go并发编程之channel\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/golang/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","summary":"类型 1. 基础类型 1.1. 布尔类型 //布尔类型的关键字为bool,值为true或false，不可写为0或1 var v1 bool v1=true //接受表达式判断赋值，不支持自动或","title":"数据类型"},{"content":"mysql查看所有表的索引:\nSELECT a.TABLE_SCHEMA, a.TABLE_NAME, a.index_name, GROUP_CONCAT(column_name ORDER BY seq_in_index) AS `Columns` FROM information_schema.statistics a GROUP BY a.TABLE_SCHEMA,a.TABLE_NAME,a.index_name 查询索引： select * from (SELECT a.TABLE_SCHEMA, a.TABLE_NAME, a.index_name, GROUP_CONCAT(column_name ORDER BY seq_in_index) AS `Columns` FROM information_schema.statistics a GROUP BY a.TABLE_SCHEMA,a.TABLE_NAME,a.index_name) as b where b.index_name like \u0026#39;%req_id_3%\u0026#39; ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%9F%A5%E8%AF%A2mysql%E4%B8%AD%E7%9A%84%E6%89%80%E6%9C%89%E7%B4%A2%E5%BC%95/","summary":"mysql查看所有表的索引: SELECT a.TABLE_SCHEMA, a.TABLE_NAME, a.index_name, GROUP_CONCAT(column_name ORDER BY seq_in_index) AS `Columns` FROM information_schema.statistics a GROUP BY a.TABLE_SCHEMA,a.TABLE_NAME,a.index_name 查询索引： select * from (SELECT a.TABLE_SCHEMA, a.TABLE_NAME, a.index_name, GROUP_CONCAT(column_name ORDER BY seq_in_index) AS `Columns` FROM information_schema.statistics a GROUP BY a.TABLE_SCHEMA,a.TABLE_NAME,a.index_name) as b where b.index_name like \u0026#39;%req_id_3%\u0026#39;","title":"查询mysql中的所有索引"},{"content":"关于Redis的其他的一些面试问题已经写过了，比如常见的缓存穿透、雪崩、击穿、热点的问题，但是还有一个比较麻烦的问题就是如何保证缓存一致性。对于缓存和数据库的操作，主要有以下两种方式。\n删除缓存，更新数据库 删除缓存，更新数据库，sleep一段时间后再次删除缓存数据 先删缓存，再更新数据库 先删除缓存，数据库还没有更新成功，此时如果读取缓存，缓存不存在，去数据库中读取到的是旧值，缓存不一致发生。 解决方案 延时双删 延时双删的方案的思路是，为了避免更新数据库的时候，其他线程从缓存中读取不到数据，就在更新完数据库之后，再sleep一段时间，然后再次删除缓存。sleep的时间要对业务读写缓存的时间做出评估，sleep时间大于读写缓存的时间即可。流程如下：\n线程1删除缓存，然后去更新数据库 线程2来读缓存，发现缓存已经被删除，所以直接从数据库中读取，这时候由于线程1还没有更新完成，所以读到的是旧值，然后把旧值写入缓存 线程1，根据估算的时间，sleep，由于sleep的时间大于线程2读数据+写缓存的时间，所以缓存被再次删除 如果还有其他线程来读取缓存的话，就会再次从数据库中读取到最新值 先更新数据库，再删除缓存 如果反过来操作，先更新数据库，再删除缓存呢？这个就更明显的问题了，更新数据库成功，如果删除缓存失败或者还没有来得及删除，那么，其他线程从缓存中读取到的就是旧值，还是会发生不一致。 解决方案 消息队列 这是网上很多文章里都有写过的方案。但是这个方案的缺陷会更明显一点。先更新数据库，成功后往消息队列发消息，消费到消息后再删除缓存，借助消息队列的重试机制来实现，达到最终一致性的效果。 这个解决方案其实问题更多。\n引入消息中间件之后，问题更复杂了，怎么保证消息不丢失更麻烦 就算更新数据库和删除缓存都没有发生问题，消息的延迟也会带来短暂的不一致性，不过这个延迟相对来说还是可以接受的 进阶版消息队列 为了解决缓存一致性的问题单独引入一个消息队列，太复杂了。其实，一般大公司本身都会有监听binlog消息的消息队列存在，主要是为了做一些核对的工作。这样，我们可以借助监听binlog的消息队列来做删除缓存的操作。这样做的好处是，不用你自己引入，侵入到你的业务代码中，中间件帮你做了解耦，同时，中间件的这个东西本身就保证了高可用。当然，这样消息延迟的问题依然存在，但是相比单纯引入消息队列的做法更好一点。而且，如果并发不是特别高的话，这种做法的实时性和一致性都还算可以接受的。 其他解决方案 设置缓存过期时间 每次放入缓存的时候，设置一个过期时间，比如5分钟，以后的操作只修改数据库，不操作缓存，等待缓存超时后从数据库重新读取。如果对于一致性要求不是很高的情况，可以采用这种方案。这个方案还会有另外一个问题，就是如果数据更新的特别频繁，不一致性的问题就很大了。在实际生产中，我们有一些活动的缓存数据是使用这种方式处理的。因为活动并不频繁发生改变，而且对于活动来说，短暂的不一致性并不会有什么大的问题。\n为什么是删除，而不是更新缓存？ 我们以先更新数据库，再删除缓存来举例。如果是更新的话，那就是先更新数据库，再更新缓存。举个例子：如果数据库1小时内更新了1000次，那么缓存也要更新1000次，但是这个缓存可能在1小时内只被读取了1次，那么这1000次的更新有必要吗？反过来，如果是删除的话，就算数据库更新了1000次，那么也只是做了1次缓存删除，只有当缓存真正被读取的时候才去数据库加载。\n总结 首先，我们要明确一点，缓存不是更新，而应该是删除。删除缓存有两种方式：\n先删除缓存，再更新数据库。解决方案是使用延迟双删。 先更新数据库，再删除缓存。解决方案是消息队列或者其他binlog同步，引入消息队列会带来更多的问题，并不推荐直接使用。 针对缓存一致性要求不是很高的场景，那么只通过设置超时时间就可以了。其实，如果不是很高的并发，无论你选择先删缓存还是后删缓存的方式，都几乎很少能产生这种问题，但是在高并发下，你应该知道怎么解决问题。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3/","summary":"关于Redis的其他的一些面试问题已经写过了，比如常见的缓存穿透、雪崩、击穿、热点的问题，但是还有一个比较麻烦的问题就是如何保证缓存一致性。","title":"缓存一致性问题怎么解决"},{"content":"缓存 Java本地缓存 [[Java本地缓存]]\nRedis [[redis实现分布式锁——setnx]]\n什么是RDB和AOF Redis的过期键的删除策暖 Redis线程模型、单线程快的原因 简述Redis事务实现 Redis 主从复制的核心原理 Redis有哪些数据结构？分别有哪些典型的应用场景？ Redis分布式锁底层是如何实现的？ Redis主从复制的核心原理 Redis集群策略 缓存穿透、缓存击穿、缓存雪崩分别是什么 Redis和Mysql如何保证数据一致 Redis的持久化机制 Redis单线程为什么这么快 简述Redis事务实现 如何保证缓存和数据库数据的一致性 [[数据库与缓存双写一致性方案解析]]\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E9%9D%A2%E8%AF%95/%E7%BC%93%E5%AD%98/","summary":"缓存 Java本地缓存 [[Java本地缓存]] Redis [[redis实现分布式锁——setnx]] 什么是RDB和AOF Redis的过期键的删除策暖 R","title":"缓存知识"},{"content":"1. 概述 在高并发系统中，缓存是提升性能、降低数据库压力的重要组件。然而，在实际应用中，缓存可能会遇到三种典型问题：缓存穿透、缓存击穿和缓存雪崩。这些问题如果不加以妥善处理，可能会导致数据库负载激增，甚至影响整个系统的稳定性。本文将详细介绍这三种问题的区别，并探讨相应的解决方案。\n2. 什么是缓存穿透、缓存击穿和缓存雪崩？ 2.1 缓存穿透（Cache Penetration） 现象：指的是缓存和数据库中都没有的数据，但却被大量请求访问，导致请求直接落到数据库上，增加数据库的压力。\n速记口诀：恶意请求绕过缓存，访问数据库中不存在的数据，导致数据库负载增加。\n2.2 缓存击穿（Cache Breakdown） 现象：某个热点数据在缓存中过期的瞬间，刚好有大量请求同时到达，此时所有请求都会直接访问数据库，可能会导致数据库压力激增。\n速记口诀：缓存数据突然失效，大量请求瞬间涌向数据库。\n2.3 缓存雪崩（Cache Avalanche） 现象：大量缓存在同一时间过期，使得所有原本应命中缓存的请求都直接访问数据库，造成数据库负载飙升，甚至引发全局性故障。\n速记口诀：大量缓存同时失效，流量直击数据库，引发系统风险。\n3. 解决方案 3.1 缓存穿透解决方案 方案 1：使用布隆过滤器（Bloom Filter）\n在缓存层引入布隆过滤器，提前存储可能存在的数据标识，对于不存在的数据，直接拦截请求，避免打到数据库。 方案 2：缓存空值\n针对数据库和缓存均不存在的数据，可以在缓存中存储一个短时间有效的空值（如 5 分钟），减少对数据库的冲击。 3.2 缓存击穿解决方案 方案 1：设置热点数据永不过期\n对于高频访问的热点数据，可以设置永不过期，确保缓存始终存在，避免瞬间失效造成数据库负载激增。 方案 2：互斥锁机制\n在缓存数据为空时，采用互斥锁（如 setnx 方式），确保只有一个请求能查询数据库并更新缓存，其他请求需等待或短暂休眠后重试。 public static String getProductDescById(String id) { String desc = redis.get(id); if (desc == null) { if (redis.setnx(\u0026#34;lock_id\u0026#34;, 1, 60) == 1) { try { desc = getFromDB(id); redis.set(id, desc, 60 * 60 * 24); } catch (Exception ex) { LogHelper.error(ex); } finally { redis.del(\u0026#34;lock_id\u0026#34;); return desc; } } else { Thread.sleep(200); return getProductDescById(id); } } return desc; } 3.3 缓存雪崩解决方案 方案 1：设置缓存过期时间随机化\n避免大量缓存同时过期，可以在设定缓存时增加一个随机波动值。例如，原定 10 分钟 过期的缓存，可以随机增加 1~3 分钟，使过期时间分布在 7~13 分钟 之间。 redis.set(id, value, 60 * 60 + Math.random() * 1000); 方案 2：热点数据分片存储\n通过分布式缓存架构（如 Redis Cluster），将不同热点数据分布存储在不同的节点/机房，防止单点故障引发缓存雪崩。 方案 3：双层缓存机制（A/B 缓存）\n维护两层缓存：A 缓存（正常过期） 和 B 缓存（不过期）。当 A 缓存失效时，读取 B 缓存，并异步更新 **A** 缓存，确保数据一致性。 4. 总结 问题 定义 触发条件 影响 解决方案 缓存穿透 访问数据库中不存在的数据，导致所有请求直接打到数据库 缓存和数据库都无数据 数据库负载增加 布隆过滤器、缓存空值 缓存击穿 热点数据过期的瞬间，大量请求同时访问数据库 高并发下，某个热点数据突然失效 数据库瞬时压力飙升 设置永不过期、互斥锁机制 缓存雪崩 大量缓存数据同时过期，导致数据库负载剧增 大量缓存数据设定相同的过期时间 可能影响整个系统 随机化过期时间、热点数据分片、双层缓存 缓存作为高并发架构中的重要组成部分，合理的缓存设计可以极大提升系统的性能，降低数据库负载。然而，面对缓存穿透、缓存击穿和缓存雪崩等问题，我们需要根据具体场景采取相应的防范措施，确保系统的稳定性和可靠性。\n","permalink":"https://luolin1024.github.io/2024/02/cache-penetration-and-cache-breakdown-and-cache-avalanche-and-the-solution/","summary":"1. 概述 在高并发系统中，缓存是提升性能、降低数据库压力的重要组件。然而，在实际应用中，缓存可能会遇到三种典型问题：缓存穿透、缓存击穿和缓存雪崩","title":"缓存穿透，缓存击穿和缓存雪崩的区别以及解决方案"},{"content":"问题背景 最近在项目中发现了一则报错：“org.springframework.transaction.UnexpectedRollbackException: Transaction rolled back because it has been marked as rollback-only”。根据报错信息来看是spring框架中的事务管理报错：事务回滚了，因为它被标记为回滚状态。\n报错原因 多层嵌套事务中，如果使用了默认的事务传播方式，当内层事务抛出异常，外层事务捕捉并正常执行完毕时，就会报出rollback-only异常。\nspring框架是使用AOP的方式来管理事务，如果一个被事务管理的方法正常执行完毕，方法结束时spring会将方法中的sql进行提交。如果方法执行过程中出现异常，则回滚。spring框架的默认事务传播方式是PROPAGATION_REQUIRED：如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。在项目中，一般我们都会使用默认的传播方式，这样无论外层事务和内层事务任何一个出现异常，那么所有的sql都不会执行。在嵌套事务场景中，内层事务的sql和外层事务的sql会在外层事务结束时进行提交或回滚。如果内层事务抛出异常e，在内层事务结束时，spring会把事务标记为“rollback-only”。这时如果外层事务捕捉了异常e，那么外层事务方法还会继续执行代码，直到外层事务也结束时，spring发现事务已经被标记为“rollback-only”，但方法却正常执行完毕了，这时spring就会抛出“org.springframework.transaction.UnexpectedRollbackException: Transaction rolled back because it has been marked as rollback-only”。代码示例如下：\nClass ServiceA { @Resource(name = \u0026#34;serviceB\u0026#34;) private ServiceB b; @Transactional public void a() { try { b.b(); } catch (Exception e) { }final{ } // 执行其他sql操作引起事务提交 } } Class ServiceB { @Transactional public void b() { throw new RuntimeException(); } } 当调用a()时，就会报出“rollback-only”异常。\n解决方案 如果希望内层事务抛出异常时中断程序执行，直接在外层事务的catch代码块中抛出e. 如果希望程序正常执行完毕，并且希望外层事务结束时全部提交，需要在内层事务中做异常捕获处理。 如果希望内层事务回滚，但不影响外层事务提交，需要将内层事务的传播方式指定为PROPAGATION_NESTED。注：PROPAGATION_NESTED基于数据库savepoint实现的嵌套事务，外层事务的提交和回滚能够控制嵌内层事务，而内层事务报错时，可以返回原始savepoint，外层事务可以继续提交。 在我的项目中之所以会报“rollback-only”异常的根本原因是代码风格不一致的原因。外层事务对错误的处理方式是执行自己代码逻辑来告诉上游执行结果，而内层事务是通过抛出异常来告诉上游（这里指外层事务）执行结果，这种差异就导致了“rollback-only”异常。虽然最后事务依然是回滚了，不影响程序对sql的处理，但外层事务的上游本期望返回true和false，却收到了UnexpectedRollbackException异常。\n@see org.springframework.transaction.annotation.Propagation| 事务传播方式 | 说明 | | ——– | —– || PROPAGATION_REQUIRED | 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是默认的传播方式 || PROPAGATION_SUPPORTS | 支持当前事务，如果当前没有事务，就以非事务方式执行|| PROPAGATION_MANDATORY | 使用当前的事务，如果当前没有事务，就抛出异常 || PROPAGATION_REQUIRES_NEW | 新建事务，如果当前存在事务，把当前事务挂起 || PROPAGATION_NOT_SUPPORTED | 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起 || PROPAGATION_NEVER | 以非事务方式执行，如果当前存在事务，则抛出异常 || PROPAGATION_SUPPORTS | 支持当前事务，如果当前没有事务，就以非事务方式执行。 || PROPAGATION_NESTED | 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E6%95%B0%E6%8D%AE%E5%BA%93/%E8%AE%B0%E4%B8%80%E6%AC%A1%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%9D%91transaction-rolled-back-because-it-has-been-marked-as-rollback-only/","summary":"问题背景 最近在项目中发现了一则报错：“org.springframework.transaction.UnexpectedRollbackE","title":"记一次事务的坑：Transaction rolled back because it has been marked as rollback-only"},{"content":"背景 本人从2020年初开始使用语雀，在这段时间中通过语雀做了大量的笔记，也写了一些自己的博客，十分感谢语雀，给了我一个干净整洁的mark在线笔记。在最近这一个月内，起因是某天在b站看到了对Obsidian的介绍，本来自己也是十分想要记日记的，但是无奈语雀不可以定制日记模版，以及其他模版。另外语雀也不支持个人任务管理以及个人okr管理，因此对Obsidian和logseq，语雀，思源和notion等笔记软件十分感兴趣，想要实现All in one，在了解了这些软件之后，发现每个软件都有自己的长处和短处，开始逐渐反思或许不应该追求所谓的all in all，而是用不同的软件组合实现，整理了一下自己的需求：\n记日记 做好GTD 个人目标管理 读书笔记 记录工作相关笔记 知识沉淀 编写博客并发布至网上 支持本地化，避免软件丢失 最好可以支持双链(这样我就可以看到我的知识图谱，然后满满的成就感，嘿嘿) 具体工具使用方式 按照这个思路确定了我之后的将要使用的工具，主要有语雀，微软todo和obsidian，其中语雀主要是博客的载体，微软todo作为认为管理工具参考effie任务管理，obsidian主要解决我的日记、笔记以及其他事项。\nGTD：微软todo 首先是微软todo，我为啥要用微软todo呢，因为他免费、好用、支持多平台同步。先给大家看下我的微软todo 我将我的todo按照四象限的思路建立了不同的list，以及收集箱list主要用于收集每天的任务，然后进行分类，如果是当天要完成的就放到我的一天中快速搞定。另外，每个任务最好都有对应的计划完成时间，毕竟有句话叫做如果计划没有截止时间，那么他将无限期推迟,我的还有些没有加计划完成，这个别学我～\n博客：语雀 语雀，主要会是我编写博客并发布至网上、组建对外公布的个人知识库主要工具，另外因为语雀本身\n知识图谱：Obsidian 首先Obsidian其实是一块白板，需要自己有自己的定制化内容，github上也有一些主页可以fork过来之后自己直接使用，但是那些对我来讲太过花里胡哨了，我不喜欢，所以参考了Obsidian社区的另一位老哥的工作区，我也对我的Obsidian工作区进行了规划，通过目录文件夹分好每一个文件的内容，将收集箱，okr，daily，工作相关，博客相关进行拆分，看起来有条理些，自己也更舒服，这个是我目前的工作区：\n我的需求都是怎么实现的呢？记日记：Obsidian的day planer工具可以结合日记模版，提前规划好每天的时间块，按照自己的实际动态调整，本地化、记录工作相关笔记、个人目标管理、读书笔记、知识沉淀、本地化、双链组成个人知识图谱\n语雀导出到本地Markdown 语雀目前官方批量导出只支持导出pdf获取和自主研发文本类型导出，不支持markdow导出，所以想要本地备份需要稍微花点功夫，通过脚本将文件下载下来 建议使用如下脚本：\ntruda8/ExportMD: 语雀知识库自动导出为 Markdown 格式 (github.com)\n本人使用的是python版本为3.8.19，另外注意使用bash执行，使用pycharm会报错\n图片导入个人图床 这一步可以直接使用obsidian的插件Image auto upload(插件市场已有)组合picGo全量上传，他会自动替换好上传后的图片位置\n随想 其实折腾个工具还是挺蛋疼的，俗话是磨刀不误砍柴工，一直折腾这玩意就像是一直在磨刀，一磨就是老半天，以后再也不想折腾笔记软件了～\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E5%B7%A5%E5%85%B7/the-sparrow-migrates-to-obsidian/","summary":"背景 本人从2020年初开始使用语雀，在这段时间中通过语雀做了大量的笔记，也写了一些自己的博客，十分感谢语雀，给了我一个干净整洁的mark在线","title":"语雀迁移至Obsidian"},{"content":"[[UML统一建模语言]]\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/","summary":"[[UML统一建模语言]]","title":"软件工程"},{"content":"M1 破解Idea2024.1 下载ja-netfilter并进行配置 ja-netfilter 发行版 - Gitee.com\n下载到本地，将解压后的文件夹放到合适的位置，编辑以下三个文件 dns.conf\n[DNS] EQUAL,jetbrains.com; EQUAL,dbeaver.com power.conf\n[Result] EQUAL,120506319308405029943033101198259523557651500267734599270782782071425072541184605728867830395125412768750966448411447392137801711908001958831204692561738046570955709184538088569271703484602917023462976408329100293802371486063140115775311907530943821345005598057265747678100463689973450156515895355214983079672467769169324175533323801179755544364921063654340185317077965735659865485150734884110709760680757502730007505995422237875348017761382234951127263548660889969621730944377739766734765769747684457663965611896398862841334032542726392699785677440644859509166466497325071885386505404431787167239320957696896447925472784312642576835792921100239616617639216190447230487878404191838684279341834945197861631446454083984351911070798505031973496634229907567362853550735007045265430703581336189733180744888091740381912913980707537008943084904260746266383019688346709856215660232636334604552145129775009725685598798774376749830567219982166661918408832945395290223853748014160473876195098438959881711585152480525870219408398012002829112863175041709512032251930709608035158747101960447898838942705485214217426612863919268749874079707310181890737049603255938886865558759802593500502795018952114650332765839003032013708006750600413455628536259,65537,860106576952879101192782278876319243486072481962999610484027161162448933268423045647258145695082284265933019120714643752088997312766689988016808929265129401027490891810902278465065056686129972085119605237470899952751915070244375173428976413406363879128531449407795115913715863867259163957682164040613505040314747660800424242248055421184038777878268502955477482203711835548014501087778959157112423823275878824729132393281517778742463067583320091009916141454657614089600126948087954465055321987012989937065785013284988096504657892738536613208311013047138019418152103262155848541574327484510025594166239784429845180875774012229784878903603491426732347994359380330103328705981064044872334790365894924494923595382470094461546336020961505275530597716457288511366082299255537762891238136381924520749228412559219346777184174219999640906007205260040707839706131662149325151230558316068068139406816080119906833578907759960298749494098180107991752250725928647349597506532778539709852254478061194098069801549845163358315116260915270480057699929968468068015735162890213859113563672040630687357054902747438421559817252127187138838514773245413540030800888215961904267348727206110582505606182944023582459006406137831940959195566364811905585377246353-\u0026gt;31872219281407242025505148642475109331663948030010491344733687844358944945421064967310388547820970408352359213697487269225694990179009814674781374751323403257628081559561462351695605167675284372388551941279783515209238245831229026662363729380633136520288327292047232179909791526492877475417113579821717193807584807644097527647305469671333646868883650312280989663788656507661713409911267085806708237966730821529702498972114194166091819277582149433578383639532136271637219758962252614390071122773223025154710411681628917523557526099053858210363406122853294409830276270946292893988830514538950951686480580886602618927728470029090747400687617046511462665469446846624685614084264191213318074804549715573780408305977947238915527798680393538207482620648181504876534152430149355791756374642327623133843473947861771150672096834149014464956451480803326284417202116346454345929350148770746553056995922154382822307758515805142704373984019252210715650875853634697920708113806880196144197384637328982263167395073688501517286678083973976140696077590122053014085412828620051470085033364773099146103525313018873319293728800442101520384088109603555959893639842091339193857485407672132882577840295039058621747654642202620767068924079813640067442975 EQUAL,8028659553836119901593655311677865290672387540027895708985570867455842278776015838142490556122515317003830575671206217290165955723210315889275621408086645995280770696135307020454887097794294273869941097888549275028604248332746117479367032100139091095818169444690976206636597409322539276252570779516636180497560345090851316373570301807158645002654208816162902430571101092599540795501152368695431168224953320283502815852695423193526255836776240019085157444254721864134058745605280085897450952937893645487302683006269553010996013513395044612932182772364336368242146044741660443063207438830622376694839772096688572619877,65537,21052260334349247097390263197515551021430500095747078612475171670547647379514624742422155617118382403386162585789957995106937640909858927441120214136124618650916253946431099279059999234690271861285094667690686174087562943995337813383652323725628494261414287817117703355799303086256914782640807165021059760198249458510362432176960683009890989990086614909076853502936665842869163947730574085863127445475967466399017447434906719734480523659879746056728772390182338236187070557277461449143752467418310063647027554915213099799725713708651142505590086828211040619445941301844994775362846837122335522584661592447560060751169-\u0026gt;986236757547332986472011617696226561292849812918563355472727826767720188564083584387121625107510786855734801053524719833194566624465665316622563244215340671405971599343902468620306327831715457360719532421388780770165778156818229863337344187575566725786793391480600129482653072861971002459947277805295727097226389568776499707662505334062639449916265137796823793276300221537201727072401742985542559596685092673521228140822200236743113743661549252453726123450722876929538747702356573783116197523966334991563351853851212597377279504828784687920949198341066450537230593608440475006386024448307924665012521692416658191 url.conf\n[URL] PREFIX,https://account.jetbrains.com/lservice/rpc/validateKey.action PREFIX,https://dbeaver.com/lmp/checkLicense PREFIX,https://store.smartgit.com/check 激活idea 通过finder找到应用程序后IntelliJ IDEA通过显示包内容进入/Contents/bin文件夹下， 修改idea.vmoptions\n尾部添加\n--add-opens=java.base/jdk.internal.org.objectweb.asm=ALL-UNNAMED --add-opens=java.base/jdk.internal.org.objectweb.asm.tree=ALL-UNNAMED -javaagent:/Users/luolin/locaDevTool/ja-netfilter/ja-netfilter.jar=jetbrains 注意：/Users/luolin/locaDevTool/ja-netfilter是我电脑中的位置，此处需要改为自己的电脑位置 打开idea，编辑VM Options，添加上面的参数\n完成后点击注册，选择如下配置： 配置激活服务器：\nhttps://jetbra.in/ 参考： macOS如何给idea安装ja-netfilter插件-CSDN博客 ja-netfilter 发行版 - Gitee.com\n新的激活方法：\nhttps://blog.csdn.net/qq251708339/article/details/134105044 JRebel 激活 :生成 GUID 的网址 https://www.guidgen.com/ :用这个网址 + 生成的 GUID 激活 https://jrebel.qekang.com/ 例如: https://jrebel.qekang.com/f11c305b-a88b-454b-8bb5-0c280f3b6257\n:设置离线模式 来防止失效 File -\u0026gt; Settings -\u0026gt; JRebel -\u0026gt; [Work offline]按钮\nIdea报错java: -source 1.6 中不支持 diamond 运算符 D:\\document\\IdeaProjects\\how-about-study\\how-about-basic\\src\\com\\lin\\io\\bio\\BioServerWithPool.java:27:72 java: -source 1.6 中不支持 diamond 运算符 (请使用 -source 7 或更高版本以启用 diamond 运算符) 打开module setting，更新language level为8\n接着报错：\njava: Compilation failed: internal java compiler error ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E5%B7%A5%E5%85%B7/%E9%AB%98%E6%95%88%E7%8E%87idea/","summary":"M1 破解Idea2024.1 下载ja-netfilter并进行配置 ja-netfilter 发行版 - Gitee.com 下载到本地，将解压后的文件夹放到合适的位置，编辑以下三个文件 dns.conf [DNS]","title":"高效率Idea"},{"content":"ubuntu使用官方安装脚本自动安装\nsudo apt-get update curl -fsSL https://test.docker.com -o test-docker.sh sudo sh test-docker.sh 要使用 Docker 作为非 root 用户，则应考虑使用类似以下方式将用户添加到 docker 组： sudo usermod -aG docker your-user dockert 镜像\n- docker ps - docker logs 2b1b7a428627[docker id] 查看容器内的标准输出： - docker stop mysql-test停止容器 - docker pull ubuntu 如果我们本地没有 ubuntu 镜像，我们可以使用 docker pull 命令来载入 ubuntu 镜像 - docker stop \u0026lt;容器 ID\u0026gt; - docker restart \u0026lt;容器 ID\u0026gt; - docker exec \u0026lt;容器 ID\u0026gt; # 进入容器 运行容器\ndocker run -itd --name mysql-test -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql 各个参数解析： - docker: Docker 的二进制执行文件 - run: 与前面的 docker 组合来运行一个容器。 - -t: 在新容器内指定一个伪终端或终端。 - -i: 允许你对容器内的标准输入 (STDIN) 进行交互。 - -d 指定容器的运行模式:后台运行。加了 -d 参数默认不会进入容器，想要进入容器需要使用指令 docker exec（下面会介绍到）。 - --name mysql-test:容器名称 - -P:前一个为主机端口，后一个为容器端口 进入容器：\ndocker exec -it mysql-test /bin/bash 各个参数解析： - exec：进入容器 - /bin/bash: 在启动的容器里执行的命令为bash 容器中的命令：\n和**ls**分别查看当前系统的版本信息和当前目录下的文件列表 cat /proc/version ls 运行 exit 命令退出容器 exit 快速安装并启动mysql8.0 docker pull mysql:8.0 # 3308是主机对外端口，3306是容器内端口 docker run --name mysql8-container -e MYSQL_ROOT_PASSWORD=123456 -p 3308:3306 -d mysql:8.0 docker ps #支持所有ip连接 #进入容器： docker exec -it mysql8-container mysql -u root -p #容器内运行 CREATE USER \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;123456\u0026#39;; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; WITH GRANT OPTION; FLUSH PRIVILEGES; #退出容器后重启 docker restart mysql8-container ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/%E5%B7%A5%E5%85%B7/docker%E5%AD%A6%E4%B9%A0/","summary":"ubuntu使用官方安装脚本自动安装 sudo apt-get update curl -fsSL https://test.docker.com -o test-docker.sh sudo sh test-docker.sh 要使用 Docker 作为非 root 用户，则应考虑使用类似以下方式将用户添加到 docker 组： sudo usermod -aG docker your-user dockert 镜像 -","title":"Docker学习"},{"content":"消息队列 什么是消息队列 它的本质，就是个转发器，包含发消息、存消息、消费消息的过程。 消息队列的应用场景 应用解耦 流量削峰 异步处理 消息通讯 远程调用 消息队列如何解决消息丢失问题 RocketMQ消息中间件提供了三种发送消息的方式 同步发送 异步发送 单向发送 生产者要想发消息时保证消息不丢失，可以： 采用同步方式发送，send消息方法返回成功状态，就表示消息正常到达了存储端Broker。 如果send消息异常或者返回非成功状态，可以重试。 可以使用事务消息，RocketMQ的事务消息机制就是为了保证零丢失来设计的 消息队列如何保证消息的顺序性。 消息队列有可能发生重复消费吗？如何幂等处理？ 如何处理消息队列的消息积压问题 消息队列技术选型，Kafka还是RocketMQ，还是RabbitMQ 消息中间件如何做到高可用？ 如何保证数据一致性，事务消息如何实现 如果让你写一个消息队列，该如何进行架构设计？ 如何保证消息顺序消费 如何保证消息不重复消费 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E9%9D%A2%E8%AF%95/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","summary":"消息队列 什么是消息队列 它的本质，就是个转发器，包含发消息、存消息、消费消息的过程。 消息队列的应用场景 应用解耦 流量削峰 异步处理 消息通讯 远程调用","title":"消息队列知识"},{"content":"Mybatis 拦截器 $和#\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E9%9D%A2%E8%AF%95/mybatis/","summary":"Mybatis 拦截器 $和#","title":"MyBatis知识"},{"content":"Mysql 事务 事务的特性ACID 隔离级别 产生死锁的四个必要条件： （1） 互斥条件：一个资源每次只能被一个进程使用。 （2） 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 （3） 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。 （4） 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。\n索引 索引的类别 Primary Key（聚集索引）：InnoDB存储引擎的表会存在主键（唯一非null），如果建表的时候没有指定主键，则会使用第一非空的唯一索引作为聚集索引，否则InnoDB会自动帮你创建一个不可见的、长度为6字节的row_id用来作为聚集索引。 单列索引：单列索引即一个索引只包含单个列 组合索引：组合索引指在表的多个字段组合上创建的索引，只有在查询条件中使用了这些字段的左边字段时，索引才会被使用。使用组合索引时遵循最左前缀集合 Unique（唯一索引）：索引列的值必须唯一，但允许有空值。若是组合索引，则列值的组合必须唯一。主键索引是一种特殊的唯一索引，不允许有空值 Key（普通索引）：是MySQL中的基本索引类型，允许在定义索引的列中插入重复值和空值 FULLTEXT（全文索引）：全文索引类型为FULLTEXT，在定义索引的列上支持值的全文查找，允许在这些索引列中插入重复值和空值。全文索引可以在CHAR、VARCHAR或者TEXT类型的列上创建 SPATIAL（空间索引）：空间索引是对空间数据类型的字段建立的索引，MySQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING和POLYGON。MySQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类似的语法创建空间索引。创建空间索引的列必须声明为NOT NULL 索引的优缺点 优点 使用索引可以大大加快 数据的检索速度（大大减少检索的数据量）, 这也是创建索引的最主要的原因。 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 缺点 创建索引和维护索引需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率。 索引需要使用物理文件存储，也会耗费一定空间。 索引的底层数据结构 Hash表 通过键(key)即可快速取出对应的值(value)，因此哈希表可以快速检索数据（接近 O（1））。 B+树 多路平衡查找树 ，B+ 树是 B 树的一种变体。B 树和 B+树中的 B 是 Balanced （平衡）的意思。 B 树\u0026amp; B+树两者有何异同呢？ B 树的所有节点既存放键(key) 也存放 数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。 B 树的叶子节点都是独立的;B+树的叶子节点有一条引用链指向与它相邻的叶子节点。 B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。 性能优化 执行计划\nid\tSELECT查询的序列标识符；id越大的越先执行，相同id大小时从上到下执行 select_type\tSELECT关键字对应的查询类型； table\t用到的表名 partitions\t匹配的分区，对于未分区的表，值为 NULL type\t表的访问方法；描述了查询是如何执行的。所有值的顺序从最优到最差排序为：system \u0026gt; const \u0026gt; eq_ref \u0026gt; ref \u0026gt; fulltext \u0026gt; ref_or_null \u0026gt; index_merge \u0026gt; unique_subquery \u0026gt; index_subquery \u0026gt; range \u0026gt; index \u0026gt; ALL possible_keys\t可能用到的索引； MySQL 执行查询时可能用到的索引。如果这一列为 NULL ，则表示没有可能用到的索引 key\t实际用到的索引；列表示 MySQL 实际使用到的索引。如果为 NULL，则表示未用到索引。 key_len\t所选索引的长度 ref\t当使用索引等值查询时，与索引作比较的列或常量； rows\t预计要读取的行数；数值越小越好。 filtered\t按表条件过滤后，留存的记录数的百分比；一般越高越好 Extra\t附加信息； Using filesort：在排序时使用了外部的索引排序，没有用到表内索引进行排序。 Using temporary：MySQL 需要创建临时表来存储查询的结果，常见于 ORDER BY 和 GROUP BY。 Using index：表明查询使用了覆盖索引，不用回表，查询效率非常高。 Using index condition：表示查询优化器选择使用了索引条件下推这个特性。 Using where：表明查询使用了 WHERE 子句进行条件过滤。一般在没有使用到索引的时候会出现。 Using join buffer (Block Nested Loop)：连表查询的方式，表示当被驱动表的没有使用索引的时候，MySQL 会先将驱动表读出来放到 join buffer 中，再遍历被驱动表与驱动表进行查询。 当 Extra 列包含 Using filesort 或 Using temporary 时，MySQL 的性能可能会存在问题，需要尽可能避免。 行锁\u0026amp;表锁 MySQL三大日志(binlog、redo log和undo log) MySql Mvcc MVCC的机制？ MVCC怎么解决幻读问题的？ 临键锁的范围是怎么确定的？\n索引的基本原理 Mysql聚簇和非聚簇索引的区别 Mysql索引的数据结构，各自优劣 索引设计的原则？ InnoDB存储引擎的锁的算法 关心过业务系统里面的sql耗时吗？统计过慢查询吗？对慢查询都怎 么优化过？ 事务的基本特性和隔离级别 什么是MVCC 分表后非sharding key的查询怎么处理，分表后的排序？ Mysql主从同步原理 简述MyISAM和InnoDB的区别 简述Mysql中索引类型及对数据库的性能的影响 Explain语句结果中各个字段分表表示什么 索引覆盖是什么 最左前缀原则是什么 Innodb是如何实现事务的 B树和B+树的区别，为什么Mysql使用B+树 Mysql锁有哪些，如何理解 Mysql慢查询该如何优化？ ","permalink":"https://luolin1024.github.io/blog_prepublish/%E9%9D%A2%E8%AF%95/mysql/","summary":"Mysql 事务 事务的特性ACID 隔离级别 产生死锁的四个必要条件： （1） 互斥条件：一个资源每次只能被一个进程使用。 （2） 请求与保持条件：一个进程因请求","title":"Mysql知识"},{"content":"Java基础 Java中的基本类型都有哪些 数字类型 4 种整数型：byte、short、int、long，int:4个字节 2 种浮点型：float、double 字符类型 char：2个字节 布尔型 boolean 包装类型 常量池技术 自动装箱与拆箱 装箱：将基本类型用它们对应的引用类型包装起来； 拆箱：将包装类型转换为基本数据类型； \u0026amp; 和\u0026amp;\u0026amp; 的区别 \u0026amp;：按位与 \u0026amp;\u0026amp;：与\n面向对象三大特征 封装 继承 多态 值传递\u0026amp;引用传递 [[Java传参机制]] [[Java浅拷贝和深拷贝]] Object hashCode() 与 equals()与== 这三者的区别 == : 它的作用是判断两个对象的地址是不是相等。即，判断两个对象是不是同一个对象。 equals() : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况： 情况1，类没有覆盖equals()方法。则通过equals()比较该类的两个对象时，等价于通过“ == ”比较这两个对象。 情况2，类覆盖了equals()方法。一般，我们都覆盖equals()方法来两个对象的内容相等；若它们的内容相等，则返回true(即，认为这两个对象相等)。 hashCode() 的作用是获取哈希码，hashCode() 在散列表中才有用，在其它情况下没用。 为什么重写 equals() 时必须重写 hashCode() 方法？ 因为两个相等的对象的 hashCode 值必须是相等。也就是说如果 equals 方法判断两个对象是相等的，那这两个对象的 hashCode 值也要相等。 如果重写 equals() 时没有重写 hashCode() 方法的话就可能会导致 equals 方法判断是相等的两个对象，hashCode 值却不相等。 重写 equals() 时没有重写 hashCode() 方法的话，使用 HashMap 可能会出现什么问题? hashCode() 在散列表中才有用，在其它情况下没用。 散列表，指的是：Java集合中本质是散列表的类，如HashMap，Hashtable，HashSet。 重载和重写 重载：同名方法不同参数数量 重写：子类重写父类的同名方法，目的：提高扩展性 泛型 泛型中extends和super的区别 String、StringBuffer、StringBuilder String 为什么是不可变的? 保存字符串的数组被 final 修饰且为私有的，并且String 类没有提供/暴露修改这个字符串的方法。 String 类被 final 修饰导致其不能被继承，进而避免了子类破坏 String 不可变。 线程安全性 String 线程安全 StringBufffer线程安全 StringBuilder非线程安全 性能 每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 StringBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。 操作少量的数据: 适用 String 单线程操作字符串缓冲区下操作大量数据: 适用 StringBuilder 多线程操作字符串缓冲区下操作大量数据: 适用 StringBuffer 参数 可变长参数 泛型 泛型类、泛型接口、泛型方法。 反射 优点 可以让咱们的代码更加灵活、为各种框架提供开箱即用的功能提供了便利 缺点 让我们在运行时有了分析操作类的能力，这同样也增加了安全问题。比如可以无视泛型参数的安全检查（泛型参数的安全检查发生在编译时）。另外，反射的性能也要稍差点，不过，对于框架来说实际是影响不大的。 代码可读性 应用场景 框架中以及动态代理 注解 编译期直接扫描 运行期通过反射处理 自定义注解 异常 Throwable\nError Exception try-catch-finally\nfinally 中的代码一定会执行吗 不一定的！在某些情况下，finally 中的代码不会被执行。 就比如说 finally 之前虚拟机被终止运行的话，finally 中的代码就不会被执行。 OOM jstack heap dump I/O 序列化\n将数据结构或对象转换成二进制字节流的过程 反序列化\n将在序列化过程中所生成的二进制字节流转换成数据结构或者对象的过程 Java 序列化中如果有些字段不想进行序列化，怎么办？\n对于不想进行序列化的变量，使用 transient 关键字修饰。 字节流,为什么还要有字符流?\n不管是文件读写还是网络发送接收，信息的最小存储单元都是字节，那为什么 I/O 流操作要分为字节流操作和字符流操作呢？ 字符流是由 Java 虚拟机将字节转换得到的，问题就出在这个过程还算是非常耗时，并且，如果我们不知道编码类型就很容易出现乱码问题。所以， I/O 流就干脆提供了一个直接操作字符的接口，方便我们平时对字符进行流操作。如果音频文件、图片等媒体文件用字节流比较好，如果涉及到字符的话使用字符流比较好。 Stream 函数式接口 集合类 List ArrayList LinkedLst HashTable hashmap和hashtable的区别 哈希计算方法不同 HashMap计算hash对key的hashcode进行了二次hash，以获得更好的散列值，然后对table数组长度取模。 Hashtable计算hash是直接使用key的hashcode对table数组的长度直接进行取模。 负载因子：0.75 尽量不使用，推荐使用ConcurrentHashMap Map HashMap 重写equals不重写hashCode会怎样？ HashMap如何实现线程安全？ HashMap本身底层是非线程安全的，在多线程条件下，容易导致死循环，具体表现为CPU使用率100%。实现线程安全方法 使用 java.util.Hashtable 类，此类是线程安全的。【通过方法上添加synchronized实现线程安全，建议使用ConcurrentHashMap】 使用 java.util.concurrent.ConcurrentHashMap，此类是线程安全的。【put元素时使用synchronized关键字修饰】 使用 java.util.Collections.synchronizedMap() 方法包装 HashMap object，得到线程安全的Map，并在此Map上进行操作。【方法返回SynchronizedMap】 自己在程序的关键方法或者代码段加锁，保证安全性，当然这是严重的不推荐。 ConcurrentHashMap ConcurrentHashMap与HashMap的区别 基本概念不同；ConcurrentHashMap是一个支持高并发更新与查询的哈希表；而HashMap是基于哈希表的Map接口的实现。 底层数据结构不同；HashMap的底层数据结构主要是：数组+链表，确切的说是由链表为元素的数组。ConcurrentHashMap的底层数据结构是：Segments数组+HashEntry数组+链表。ConcurrentHashMap是线程安全的数组，它采用分段锁保证安全性。容器中有多把锁，每一把锁锁一段数据，这样在多线程访问时不同段的数据时，就不会存在锁竞争了，这样便可以有效地提高并发效率。而HashMap不是线程安全，没有锁机制，在多线程环境下会导致数据覆盖之类的问题，所以在多线程中使用HashMap是会抛出异常的。 线程安全属性不同； 对整个桶数组的处理方式不同。 谈谈ConcurrentHashMap的扩容机制 Java 并发 线程的生命周期？线程有几种状态 Java里面synchronized锁的底层实现原理？ 对象锁[[synchronized 实现原理]] 介绍一下悲观锁、乐观锁、自旋锁，适用场景？ 对于传统的重量级锁（synchronized）提供一系列优化操作——自旋与自适应自旋（Adaptive Spinning）、锁消除（Lock Elimination）、锁粗化（Lock Coarsening）、轻量级锁（Lightweight Locking）和偏向锁（Biased Locking）。 sleep()、 wait()、 join()、 yielo()红超间的的区别 对线程安全的理解 线程安全可以理解为内存安全，堆是内存共享，可以被所有的内存访问。 当多个线程访问同一个对象时，如果不进行额外的同步控制或者其他的协调操作，调用这个对象的行为都可以获得正确的结果，我们就说这个对象是线程安全的。 为什么出现现场不安全？ 其中一个线程修改了堆内存区域的对象属性，或者某个值，导致其他线程拿到错误的对象属性 Thread和Runable的区别 对守护线程的理解 ThreadLocal的底层原理 每个Thread都维护自己的一个ThreadLocalMap ，所以是线程隔离的。 并发、并行、串行之间的区别 Java死锁如何避免？ 死锁的四个必要不充分条件 禁止抢占 持有和等待 互斥 循环等待 如何理解volatile关键字 为什么用线程池？解释下线程池参数？（7个线程池参数） corePoolSize：核心线程数。 maximumPoolSize：最大线程数。 keepAliveTime：空闲线程存活时间。 TimeUnit：时间单位。 BlockingQueue：线程池任务队列。 ThreadFactory：创建线程的工厂。 RejectedExecutionHandler：拒绝策略。（4个拒绝策略） AbortPolicy：拒绝并抛出异常。 CallerRunsPolicy：使用当前调用的线程来执行此任务。 DiscardOldestPolicy：抛弃队列头部（最旧）的一个任务，并执行当前任务。 DiscardPolicy：忽略并抛弃当前任务。 最大任务数量=maximumPoolSize+BlockingQueue 线程池的底层工作原理 线程池中阻塞队列的作用？为什么是先添加列队而不是先创建最大线程? 线程池中线程复用原理 线程池将线程和任务进行解耦，线程是线程，任务是任务，摆脱了之前通过 Thread 创建线程时的一个线程必须对应一个任务的限制。在线程池中，同一个线程可以从阻塞队列中不断获取新任务来执行，其核心原理在于线程池对 Thread 进行了封装，并不是每次执行任务都会调用 Thread.start() 来创建新线程，而是让每个线程去执行一个“循环任务”，在这个“循环任务”中不停的检查是否有任务需要被执行，如果有则直接执行，也就是调用任务中的 run 方法，将 run 方法当成一个普通的方法执行，通过这种方式将只使用固定的线程就将所有任务的 run 方法串联起来。 ReentrantLock中的公平锁和非公平锁的底层实现 ReentrantLock中tryLocko和lock0方法的区别 CountDownLatch和Semaphore的区别和底层原理 Sychronized的偏向锁、轻量级锁、重量级锁 Sychronized和ReentrantLock的区别 谈谈你对AQS的理解，AQS如何实现可重入锁？ JVM 一个JVM进程的内存布局空间？ 线程共享内存区 Java堆： 虚拟机启动时创建，用来存放对象实例 新生代 1. 老年代 方法区 永久代（元空间），大多是静态方法 线程私有内存区 Java虚拟机栈 Java虚拟机栈也是线程私有的，虚拟机栈描述的是Java方法执行的内存模型：每个方法执行的时候都会创建一个栈帧，用于存放局部变量表，操作数栈，动态链接，方法出口等信息。每一个方法从调用直到执行完成的过程都对应着一个栈帧在虚拟机中的入栈到出栈的过程。我们平时把内存分为堆内存和栈内存，其中的栈内存就指的是虚拟机栈的局部变量表部分。局部变量表存放了编译期可以知道的基本数据类型(boolean、byte、char、short、int、float、long、double)，对象引用(可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置)，和返回后所指向的字节码的地址。其中64 位长度的long 和double 类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。当递归层次太深时，会引发java.lang.StackOverflowError，这是虚拟机栈抛出的异常。 本地方法栈 native方法栈 程序计数器 函数返回的时候，return语句的执行过程？ Java中有哪些类加载器 引导（Bootstrap）类加载器 扩展（Extensions）类加载器 Apps类加载器（也称系统类加载器） 自定义类加载器 类加载器之间的关系 启动类加载器，由C++实现，没有父类。 拓展类加载器(ExtClassLoader)，由Java语言实现，父类加载器为null 系统类加载器(AppClassLoader)，由Java语言实现，父类加载器为ExtClassLoader 自定义类加载器，父类加载器肯定为AppClassLoader。 说说类加载器双亲委派模型 其工作原理的是：如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式，即每个儿子都很懒，每次有活就丢给父亲去干，直到父亲说这件事我也干不了时，儿子自己想办法去完成。 作用： 避免类的重复加载； 防止核心API库被随意篡改 GC如何判断对象可以被回收 引用计数法 优点：引用计数收集器执行简单，判定效率高，交织在程序运行中。对程序不被长时间打断的实时环境比较有利。 缺点：难以检测出对象之间的循环引用。同时，引用计数器增加了程序执行的开销。所以Java语言并没有选择这种算法进行垃圾回收。 可达性分析法 可达性分析是用来判断对象是否存活，通过\u0026quot;GC Roots\u0026quot;作为起点，从这个节点往下搜索，如果有有引用，则这个对象是存活的，如果没有则判定可回收的对象。 垃圾回收算法 标记-清除算法 标记-清除算法对根集合进行扫描，对存活的对象进行标记。标记完成后，再对整个空间内未被标记的对象扫描，进行回收。 优点：实现简单，不需要进行对象进行移动。 缺点：标记、清除过程效率低，产生大量不连续的内存碎片，提高了垃圾回收的频率。 复制算法 它将内存区域划分成相同的两个内存块。每次仅使用一半的空间，JVM生成的新对象放在一半空间中。当一半空间用完时进行GC，把可到达对象复制到另一半空间，然后把使用过的内存空间一次清理掉。 优点：按顺序分配内存即可，实现简单、运行高效，不用考虑内存碎片。 缺点：可用的内存大小缩小为原来的一半，对象存活率高时会频繁进行复制。 标记-整理算法 标记-整理算法 采用和 标记-清除算法 一样的方式进行对象的标记，但后续不直接对可回收对象进行清理，而是将所有的存活对象往一端空闲空间移动，然后清理掉端边界以外的内存空间。 优点：解决了标记-清理算法存在的内存碎片问题。 缺点：仍需要进行局部对象移动，一定程度上降低了效率。 分代收集算法 总结 JDK8堆内存一般是划分为年轻代和老年代，不同年代 根据自身特性采用不同的垃圾收集算法。 对于新生代，每次GC时都有大量的对象死亡，只有少量对象存活。考虑到复制成本低，适合采用复制算法。因此有了From Survivor和To Survivor区域。 对于老年代，因为对象存活率高，没有额外的内存空间对它进行担保。因而适合采用标记-清理算法和标记-整理算法进行回收。 JVM中哪些是线程共享区 堆区和⽅法区是所有线程共享的，栈、本地⽅法栈、程序计数器是每个线程独有的 堆: 不用多说了,放对象的地方 方法区: 类定义的成员变量丶常量丶静态变量丶方法都在这里 栈: 程序运行才有的,会把运行时的方法压入栈,里面有局部变量等东西 本地方法栈: 操作系统方法 程序计数器: 标记代码走到哪里了 你们项目如何排查JVM问题 一个对象从加载到JVM，再到被GC清除，都经历了什么过程？ 什么是三色标记？ CMS怎么进行垃圾回收的？ 官方名称：最大-并发-标记-清除-垃圾收集器 作用范围：老年代 算法：并发标记清除算法。 阶段 初始标记（CMS initial mark） STW 并发标记（CMS concurrent mark） 重新标记（CMS remark） 并发清除（CMS concurrent sweep） JVM参数有哪些？ 1. -Xms：设置初始分配大小，默认为物理内存的1/64 2. -Xmx：最大分配内存，默认为物理内存的1/4 3. -XX:+PrintGCDetails：输出详细的GC处理日志 4. -XX:+PrintGCTimeStamps：输出GC的时间戳信息 5. -XX:+PrintGCDateStamps：输出GC的时间戳信息（以日期的形式） 6. -XX:+PrintHeapAtGC：在GC进行处理的前后打印堆内存信息 7. -Xloggc:(SavePath)：设置日志信息保存文件 8. 在堆内存的调整策略中，基本上只要调整两个参数：-Xms和-Xmx GC具体过程 当现在有一个新的对象产生，JvM需要为该对象进行内存空间的申请 先判断Eden区是否有内存空间，如果有，直接将新对象保存在Eden区 如果Eden区的内存空间不足，会自动执行一个MinorGC操作，将Eden区的无用内存空间进行清理 清理Eden区之后继续判断Eden区内存空间情况，如果充足，则将新对象直接保存在Eden区 如果执行了Minor GC之后发现Eden区的内存依然不足，那就判断存活区的内存空间，并将Eden区的部 分活跃对象保存在存活区 活跃对象迁移到存活区后，继续判断Eden区内存空间情况，如果充足，则将新对象直接保存在Eden区 如果存活区也没有空间了，则继续判断老年区，如果老年区充足，则将存活区的部分活跃对象保存在老 年区 存活区的活跃对象迁移到老年区后，则将Eden区的部分活跃对象保存在存活区 活跃对象迁移到存活区后，继续判断Eden区内存空间情况，如果充足，则将新对象直接保存在Eden区 如果老年区也满了，这时候产生Major GC (Ful GC)进行老年区的内存清理 如果老年区执行了 Major GC之后发现无法进行对象保存，会产生OutofMemoryError异常 GC的区别 1、部分收集（Partial GC）：只针对部分区域进行垃圾收集。其中又分为： 1.1、新生代收集（Minor GC/Young GC）：只针对新生代的垃圾收集。具体点的是Eden区满时触发GC。 Survivor满不会触发Minor GC 。 1.2、老年代收集（Major GC/Old GC）：只针对 老年代的垃圾收集。 目前，只有CMS收集器会有单独收集老年代的行为。 注意，很多时候，Major GC 会和Full GC混淆使用，需要具体分辨是老年代的回收还是整堆回收。 1.3、混合收集（Mixed GC）：指目标是收集整个新生代以及部分老年代的垃圾收集。 目前只有G1收集器会有这种行为。 2、整堆收集（Full GC）：收集整个Java堆和方法区的垃圾收集。\t","permalink":"https://luolin1024.github.io/blog_prepublish/%E9%9D%A2%E8%AF%95/java/","summary":"Java基础 Java中的基本类型都有哪些 数字类型 4 种整数型：byte、short、int、long，int:4个字节 2 种浮点型：float、","title":"Java知识"},{"content":"在目标设定和绩效管理中，SMART 原则是一种被广泛应用的工具。它帮助我们制定出既明确又可执行的目标，使得个人和团队能够聚焦于真正重要的事情，从而提高工作效率。本文将详细介绍 SMART 原则的内涵，并通过一个实例说明如何将其应用于实际工作中。\n一、什么是 SMART 原则？ SMART 原则是一种目标设定的方法论，其名称来源于五个英文单词首字母的缩写，每个字母代表一个目标应具备的关键特征：\nS (Specific) —— 具体性\n目标必须明确、具体，不能含糊其辞。只有明确了目标内容，才能知道该朝哪个方向努力。 M (Measurable) —— 可衡量性\n目标应当可以量化，通过数据或具体标准衡量进展和结果。这样可以及时检查执行情况，判断目标是否达成。 A (Achievable) —— 可实现性\n目标应当现实可行，既不能太过简单，也不能脱离实际。设定的目标需要在现有资源和能力范围内能够实现。 R (Relevant) —— 相关性\n目标需要与组织或个人的长远规划和核心任务紧密相关，只有具有实际意义的目标才能激励人们去努力实现。 T (Time-bound) —— 时限性\n目标必须设定明确的时间期限。明确的截止日期可以促使及时行动和跟踪进度，避免目标无限期拖延。 这种结构化的目标设定方法使得目标不仅更具指导性，也更容易在执行过程中进行监督和调整。 二、SMART 原则的应用实例 —— 新增会员抽奖活动目标设定 假设某个 APP 为了提升会员活跃度和用户粘性，计划新增一项会员抽奖活动。如何利用 SMART 原则制定出清晰有效的目标？下面给出一个详细示例：\n1. Specific（具体性） 目标描述：在 APP 内推出一项会员抽奖活动。 具体要求：活动针对注册会员，要求用户在活动期间内累计达到一定活跃度（如连续登录或消费满额）后获得抽奖资格，并最终可赢取积分、优惠券或实物奖品。 2. Measurable（可衡量性） 衡量指标： 用户参与率：活动期间，至少有 30% 的会员参与抽奖。 活跃度提升：活动结束后，新注册会员数提升 20%，老会员日均活跃度提升 15%。 转化率：通过活动直接带动的消费提升 10%。 通过这些具体的数据指标，团队能够在活动实施过程中和结束后，通过数据来评估目标达成情况。 3. Achievable（可实现性） 资源评估： 技术团队确认 APP 抽奖功能开发周期为 3 周，活动上线后预计系统稳定运行。 市场部经过调研，认为现有的推广渠道足以吸引目标用户参与。 奖品预算经过核算，既能吸引用户，也在预算范围内合理分配。 目标合理性：以上指标在参考历史数据和现有资源的基础上，均处于一个既有挑战性又能实际达成的范围内。 4. Relevant（相关性） 战略契合： 此次活动的目标与 APP 提升用户活跃度、增加用户粘性以及促进消费的整体战略高度契合。 活动还能够为后续产品改进提供宝贵的用户反馈数据，支持企业长期发展目标。 5. Time-bound（时限性） 时间安排： 开发与测试期：活动功能在未来 3 周内完成开发和内部测试。 活动周期：活动定于下个月的第 1 周上线，持续 2 周，之后进行效果评估和数据总结。 明确截止：所有目标的达成情况将在活动结束后 1 周内完成汇总，并提交管理层评估报告。 三、总结 通过以上实例可以看出，利用 SMART 原则为活动设定目标，不仅使目标具体、可量化，还确保目标在实现过程中具有可操作性和时效性。无论是团队项目还是个人发展，SMART 原则都能帮助我们在设定目标时做到有的放矢，从而更好地聚焦资源、追踪进展并最终达成预期成果。\n希望这篇文章能为你在实际工作中设定和实现目标提供有价值的参考，欢迎在评论区分享你对 SMART 原则的理解与应用经验！\n","permalink":"https://luolin1024.github.io/2023/04/smart-principle/","summary":"在目标设定和绩效管理中，SMART 原则是一种被广泛应用的工具。它帮助我们制定出既明确又可执行的目标，使得个人和团队能够聚焦于真正重要的事情，","title":"深度解析 SMART 原则 —— 从理论到实战案例解析"},{"content":"在工作、项目管理甚至日常生活中，如何快速而全面地理解一个问题、制定方案或做出决策一直是大家关注的重点。5W2H 分析法（又称七问分析法）则是一种简单、系统且富有启发性的思考工具。本文将详细阐述 5W2H 分析法的基本原理、各部分含义及实际应用案例，帮助你全面掌握这一方法。\n一、什么是 5W2H 分析法？ 5W2H 分析法起源于二战时期的美国军队，由陆军兵器修理部首先提出。其核心思想是通过七个基本问题来对任何任务或问题进行全面的剖析，从而找出关键环节并制定出合理的解决方案。具体包括：\nWhat（是什么）\n确定需要做什么工作或要解决的是什么问题。 Why（为什么）\n分析为什么要这么做，探究背后的原因和目的。 Who（谁来做）\n明确涉及到哪些人员、责任人或目标群体。 When（何时做）\n规划任务的时间节点，确定执行的时间或最佳时机。 Where（在哪里做）\n确定任务发生的地点或实施地点。 How（怎么做）\n设计实施方案和具体操作步骤，说明如何完成任务。 How Much（需要多少资源/费用）\n评估所需投入的成本、时间、人力或其他资源。 这种七问模式能够帮助我们从多个角度全面了解问题，避免遗漏关键信息。在实际场景中，通过对这个七问进行回答后将形成一套切实可行的执行计划。 二、各个问题的详细解析 1. What —— 做什么？ 含义：描述任务或问题的核心内容，明确目标和要求。\n提问示例：\n我们需要完成什么工作？ 这次项目的主要目标是什么？ 具体要做哪些具体内容？ 2. Why —— 为什么做？ 含义：分析行动的背景、目的和动因。\n提问示例：\n为什么要做这件事情？ 这样做的意义和价值何在？ 存在哪些问题或机遇促使我们采取这一行动？ 3. Who —— 谁来做？ 含义：明确责任主体、参与者或受影响的群体。\n提问示例：\n谁负责具体的执行？ 哪些人是主要的目标受众？ 团队中哪些成员具备执行该任务的能力？ 4. When —— 何时做？ 含义：确定实施的时间节点或时机。\n提问示例：\n任务什么时候启动？ 有无时间节点或截止期限？ 何时能取得阶段性成果？ 5. Where —— 在哪里做？ 含义：确定行动发生的地点或相关环境。\n提问示例：\n任务在什么场所或区域进行？ 需要在哪些地点配合实施？ 是否涉及线上或线下的场景？ 6. How —— 怎么做？ 含义：设计具体的操作步骤、方法和流程。\n提问示例：\n采用什么方法和步骤来执行任务？ 需要哪些工具、技术或流程来支持？ 如何确保任务按计划顺利完成？ 7. How Much —— 需要多少？ 含义：评估所需资源、成本以及可能产生的效益。\n提问示例：\n实施该方案需要多少资金投入？ 人力、物力和时间的成本如何分配？ 预期的投入产出比是多少？ 三、实战案例 —— 为 APP 新增会员抽奖活动策划 针对“会员抽奖活动”这一活动目标，我们分别从 7 个方面展开分析：\n1. What —— 活动内容是什么？ 活动定义：在 APP 内推出会员抽奖活动。用户只需满足一定条件（如连续登录、消费满额、邀请好友注册等），即可获得抽奖机会，赢取积分、优惠券或实物奖励。 目标：提高会员活跃度，增强用户粘性，促进消费和传播。 2. Why —— 为什么要举办此活动？ 提升用户活跃：通过抽奖激励，鼓励会员频繁使用 APP，增加每日活跃量。 增强用户忠诚：为忠实用户提供额外福利，提升会员满意度，降低流失率。 促进传播营销：用户分享抽奖活动，可帮助 APP 获得更多自然流量和新用户注册。 数据反馈：活动期间还能通过用户参与数据，了解用户行为和偏好，为后续活动优化提供依据。 3. Who —— 谁来参与或负责？ 目标用户：主要面向已有会员（如VIP 用户或达到一定等级的用户），也可设置新用户试用抽奖资格。 执行团队： 市场部：负责活动宣传、规则制定和推广策略。 产品/技术部：负责活动功能的设计与开发，确保系统稳定和公平性。 客服团队：解答用户疑问，并及时处理活动中可能出现的问题。 财务部门：预算制定与奖品成本控制。 4. When —— 何时举行活动？ 活动时间：建议选择流量高峰期，例如节假日前夕或特殊纪念日。具体时间可设定为下月第一周至第二周，为期一至两周。 准备时间：提前 3-4 周开始筹备，包括系统开发、测试、宣传材料制作和奖品采购。 5. Where —— 活动在哪里进行？ 活动平台：直接在 APP 内嵌入活动专区或通过首页弹窗推送。可设计独立页面展示活动规则、抽奖入口和中奖公告。 宣传渠道：利用 APP 内推送、社交媒体、邮件营销等多渠道宣传，确保目标用户群体知晓活动详情。 6. How —— 如何实施活动？ 活动设计与开发： 制定详细规则：如抽奖资格获取方式、抽奖次数、奖品种类及中奖概率等。 功能开发：设计抽奖页面、抽奖动画效果、中奖通知与后台数据统计系统。 安全机制：确保抽奖过程随机公正，防止作弊或刷单现象。 推广策略： 制作宣传海报、短视频等宣传资料，通过社交平台、APP推送吸引用户参与。 联合 KOL 或合作伙伴进行联合推广。 流程管理： 分阶段进行内测、上线、数据监控和效果评估。 活动期间实时监控系统表现，确保高并发下系统稳定。 用户体验优化：通过用户反馈及时调整活动细节，例如页面加载速度、抽奖规则说明是否清晰等。 7. How Much —— 预算和资源投入是多少？ 预算制定： 奖品费用：依据奖品种类（积分、优惠券、实物奖品）制定总预算，建议预留总预算的 40%-50%。 技术开发费用：包括开发、测试和上线的投入，可依据项目复杂度预估。 宣传费用：线上推广、广告投放等费用，以及可能的线下宣传成本。 成本效益分析： 预期投入与用户增长、活跃度提升的比率。 通过活动后统计用户参与数据和转化率，评估活动 ROI。 四、5W2H 分析法的优势与注意事项 优势 全面性：通过七个角度进行提问，确保问题描述全面，降低遗漏风险。 结构化：形成固定的思维框架，有助于快速整理思路。 简单易用：不需要复杂的工具和培训，人人都能上手。 促进沟通：明确分工和责任，有助于团队协作和信息共享。 注意事项 避免表面化：对于复杂问题，仅靠简单提问可能不足以深入剖析，需要结合其他方法。 灵活运用：应根据实际情况灵活调整，不必拘泥于固定模式。 经验积累：熟练掌握需要多次实践，结合具体场景不断改进。 五、总结 5W2H 分析法作为一种简单而高效的问题解决工具，能够帮助我们从多个维度了解问题并制定实施方案。无论是在企业管理、市场营销、项目策划还是日常生活决策中，只要能熟练运用这一方法，都能让我们的思考更加系统和深入。希望本文的理论解析和实战案例能为你在实际工作中提供借鉴和启发，助你更快找到问题的关键、制定出切实可行的解决方案。\n","permalink":"https://luolin1024.github.io/2023/04/5w2h-analytical-method/","summary":"在工作、项目管理甚至日常生活中，如何快速而全面地理解一个问题、制定方案或做出决策一直是大家关注的重点。5W2H 分析法（又称七问分析法）则是一","title":"深入解读 5W2H 分析法 —— 从理论到实战案例"},{"content":"Java设计模式概述 设计模式（Design pattern）是软件开发人员在软件开发过程中面临的一般问题的解决方案模板，这些模板是经过相当长的一段时间的试验和错误总结出来的。 为什么要使用设计模式？ 使用设计模式是为了重用代码、提高代码的可读性和可靠性。 在项目中合理地运用设计模式可以完美地解决很多问题，每种模式在现实中都有相应的原理来与之对应，每种模式都描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案。 常见的设计模式分为三大类：创建型模式、结构型模式和行为型模式。\n设计模式的六大原则 1、开闭原则（Open Close Principle）\n开闭原则的意思是：对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点。\n2、里氏代换原则（Liskov Substitution Principle）\n里氏代换原则是面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP 是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。\n3、依赖倒转原则（Dependence Inversion Principle）\n这个原则是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。\n4、接口隔离原则（Interface Segregation Principle）\n这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。它还有另外一个意思是：降低类之间的耦合度。由此可见，其实设计模式就是从大型软件架构出发、便于升级和维护的软件设计思想，它强调降低依赖，降低耦合。\n5、迪米特法则，又称最少知道原则（Demeter Principle）\n最少知道原则是指：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。\n6、合成复用原则（Composite Reuse Principle）\n合成复用原则是指：尽量使用合成/聚合的方式，而不是使用继承。\n创建型模式（Creational Patterns） 创建型模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。\n单例模式（Singleton Pattern）\n适用场景：需要确保某一个类只有一个实例，且自行实例化并向整个系统提供这个实例。 示例：数据库连接池、配置文件读取类。 工厂方法模式（Factory Method Pattern）\n适用场景：定义一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法使一个类的实例化延迟到其子类。 示例：日志记录器、读取不同类型文件的解析器。 抽象工厂模式（Abstract Factory Pattern）\n适用场景：提供一个创建一系列相关或互相依赖对象的接口，而无需指定它们具体的类。 示例：GUI工具包中的按钮、文本框、菜单等。 建造者模式（Builder Pattern）\n适用场景：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 示例：构建复杂对象如文档、计算机硬件配置。 原型模式（Prototype Pattern）\n适用场景：用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 示例：对象复制、需要大量相似对象的创建。 结构型模式（Structural Patterns） 结构型模式设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。\n适配器模式（Adapter Pattern）\n适用场景：将一个类的接口转换成客户希望的另一个接口，使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 示例：旧系统与新系统的集成。 桥接模式（Bridge Pattern）\n适用场景：将抽象部分与它的实现部分分离，使它们都可以独立地变化。 示例：图形绘制程序中的形状和颜色分离。 组合模式（Composite Pattern）\n适用场景：将对象组合成树形结构以表示“部分-整体”的层次结构，使得用户对单个对象和组合对象的使用具有一致性。 示例：文件系统中的文件和文件夹。 装饰器模式（Decorator Pattern）\n适用场景：动态地给一个对象添加一些额外的职责，就增加功能来说，装饰模式比生成子类更为灵活。 示例：流处理中的BufferedReader和BufferedWriter。 外观模式（Facade Pattern）\n适用场景：为子系统中的一组接口提供一个一致的界面，使得子系统更加容易使用。 示例：简化复杂系统的接口，如简化的数据库接口。 享元模式（Flyweight Pattern）\n适用场景：运用共享技术有效地支持大量细粒度对象的复用。 示例：文本编辑器中的字符对象管理。 代理模式（Proxy Pattern）\n适用场景：为其他对象提供一种代理以控制对这个对象的访问。 示例：虚拟代理、远程代理、保护代理。 行为型模式（Behavioral Patterns） 行为型设计模式特别关注对象之间的通信。\n责任链模式（Chain of Responsibility Pattern）\n适用场景：为请求创建一个接收对象的链，这样多个对象都有机会处理请求，避免请求的发送者和接收者之间的耦合。 示例：事务处理中的审批流程。 命令模式（Command Pattern）\n适用场景：将请求封装成对象，从而使你可以用不同的请求对客户进行参数化；对请求排队或者记录请求日志，以及支持可撤销的操作。 示例：菜单命令、操作日志、撤销操作。 解释器模式（Interpreter Pattern）\n适用场景：给定一种语言，定义它的文法表示，并定义一个解释器，这个解释器使用该表示来解释语言中的句子。 示例：编译器、正则表达式处理。 迭代器模式（Iterator Pattern）\n适用场景：提供一种方法顺序访问一个聚合对象中的各个元素，而又不暴露其内部的表示。 示例：遍历集合对象，如列表、栈、队列等。 中介者模式（Mediator Pattern）\n适用场景：用一个中介对象来封装一系列对象的交互，使得这些对象不需要显式地相互引用，从而使它们可以松散耦合。 示例：聊天室中的消息传递。 备忘录模式（Memento Pattern）\n适用场景：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。 示例：撤销功能、历史记录。 观察者模式（Observer Pattern）\n适用场景：定义对象间的一种一对多的依赖关系，使得每当一个对象改变状态，则所有依赖于它的对象都会得到通知并被自动更新。 示例：事件监听机制。 状态模式（State Pattern）\n适用场景：允许对象在其内部状态改变时改变它的行为，对象看起来似乎修改了它的类。 示例：状态机实现、界面导航。 策略模式（Strategy Pattern）\n适用场景：定义一系列算法，把它们一个个封装起来，并且使它们可互相替换。本模式使得算法可独立于使用它的客户而变化。 示例：各种排序算法、支付方式选择。 模板方法模式（Template Method Pattern）\n适用场景：定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重新定义该算法的某些特定步骤。 示例：数据处理中的标准处理流程。 访问者模式（Visitor Pattern）\n适用场景：表示一个作用于某对象结构中的各元素的操作。它使你可以在不改变各元素类的前提下定义作用于这些元素的新操作。 示例：对象结构如文件系统中的文件和文件夹，编译器中的语法树。 创建型模式 工厂模式（Factory Pattern） 问题背景 假设你正在开发一款物流管理应用。 最初版本只能处理卡车运输， 因此大部分代码都在位于名为 卡车的类中。一段时间后， 这款应用变得极受欢迎，同时 你每天都能收到十几次来自海运公司的请求， 希望应用能够支持海上物流功能。 这可是个好消息。 但是代码问题该如何处理呢？目前， 大部分代码都与 卡车类相关。 在程序中添加 轮船类需要修改全部代码。 更糟糕的是， 如果你以后需要在程序中支持另外一种运输方式， 很可能需要再次对这些代码进行大幅修改。 最后， 你将不得不编写繁复的代码， 根据不同的运输对象类， 在应用中进行不同的处理。\n解决方案 工厂方法模式建议使用特殊的_工厂_方法代替对于对象构造函数的直接调用 （即使用 new运算符）。 不用担心， 对象仍将通过 new运算符创建， 只是该运算符改在工厂方法中调用罢了。 工厂方法返回的对象通常被称作 “产品”。\n乍看之下， 这种更改可能毫无意义： 我们只是改变了程序中调用构造函数的位置而已。 但是， 仔细想一下， 现在你可以在子类中重写工厂方法， 从而改变其创建产品的类型。 但有一点需要注意:仅当这些产品具有共同的基类或者接口时， 子类才能返回不同类型的产品， 同时基类中的工厂方法还应将其返回类型声明为这一共有接口。 举例来说， ​ 卡车Truck和 轮船Ship类都必须实现 运输Transport接口， 该接口声明了一个名为 deliver交付的方法。 每个类都将以不同的方式实现该方法： 卡车走陆路交付货物， 轮船走海路交付货物。 ​ 陆路运输Road­Logistics类中的工厂方法返回卡车对象， 而 海路运输Sea­Logistics类则返回轮船对象。\n工厂方法模式代码实现 // 工厂方法模式 package com.lin.factorypattern; public class FactoryMethodTest { public static void main(String[] args) { // 假设有4个订单,分别为卡车运输、卡车加速运输、海陆运输、海陆加速运输 Factory factory = new TruckFactory(); factory.deliver(); Factory factory2 = new ShipFactory(); factory.deliver(); Factory factory3 = new TruckFactory(); factory.speedDeliver(); Factory factory4 = new ShipFactory(); factory.speedDeliver(); } } /** * 通用产品接口 */ interface Transport{ void deliver(); void speedDeliver(); } /** * 具体产品:Truck */ class Truck implements Transport{ @Override public void deliver() { System.out.println(\u0026#34;在盒子中以陆路运输。\u0026#34;); } @Override public void speedDeliver() { System.out.println(\u0026#34;卡车加速1倍运输。\u0026#34;); } } /** * 具体产品:Ship */ class Ship implements Transport{ @Override public void deliver() { System.out.println(\u0026#34;在集装箱中以海路运输。\u0026#34;); } @Override public void speedDeliver() { System.out.println(\u0026#34;ship 无法加速。以原速度运输\u0026#34;); } } /** * 通用创建者（工厂） */ abstract class Factory{ public void deliver(){ Transport product = createProduct(); product.deliver(); } public void speedDeliver(){ Transport product = createProduct(); product.speedDeliver(); } protected abstract Transport createProduct(); } /** * 具体创建者:Truck */ class TruckFactory extends Factory { @Override protected Transport createProduct() { return new Truck(); } } /** * 具体创建者:Ship */ class ShipFactory extends Factory { @Override protected Transport createProduct() { return new Truck(); } } 简单工厂 简单工厂模式 描述了一个类， 它拥有一个包含大量条件语句的构建方法， 可根据方法的参数来选择对何种产品进行初始化并将其返回。 人们通常会将简单工厂与普通的工厂或其它创建型设计模式混淆。 在绝大多数情况下， 简单工厂是引入工厂方法或抽象工厂模式时的一个中间步骤。 简单工厂通常没有子类。 但当从一个简单工厂中抽取出子类后， 它看上去就会更像经典的工厂方法模式了。 顺便提一句， 如果你将一个简单工厂声明为 abstract类型， 它并不会神奇地变成抽象工厂模式。\npublic class FactoryMethodTest { public static void main(String[] args) { new Application().getProduct(\u0026#34;1\u0026#34;).method1(); /** * ProductA.method1 executed.. */ } } interface Product{ void method1(); } class ProductFactory{ static Product getProduct(String type){ if(\u0026#34;1\u0026#34;.equals(type)){ return new ProductA(); } else { return new ProductB(); } } } class ProductA implements Product{ @Override public void method1(){ System.out.println(\u0026#34;ProductA.method1 executed..\u0026#34;); } } class ProductB implements Product{ @Override public void method1(){ System.out.println(\u0026#34;ProductB.method1 executed..\u0026#34;); } } class Application{ Product createProduct(String type){ return ProductFactory.getProduct(type); } Product getProduct(String type){ Product product = createProduct(type); // 一系列操作共同的预处理操作。。。 return product; } } 抽象工厂模式（Abstract Factory Pattern） 问题背景 解决方案 抽象工厂模式代码实现 本文借助jdk中实现jdbc的原理来描述描述一下抽象工厂模式，首先定义两个抽象接口：连接接口和命令接口。\ninterface IConnect{ void connect(); } interface ICommand{ void command(); } 此时再定义一个数据库操作util用来对数据库进行抽象对数据库进行处理。\ninterface IDatabaseUtils{ IConnect getConnect(); ICommand getCommand(); } 此时如果我们使用mysql作为数据库使用，那么具体实现一下数据库连接接口、数据库命令接口和mysql工具类。\nclass MysqlConnect implements IConnect{ @Override public void connect() { System.out.println(\u0026#34;connect mysql ...\u0026#34;); } } class MysqlCommand implements ICommand{ @Override public void command() { System.out.println(\u0026#34;mysql command...\u0026#34;); } } class MysqlUtils implements IDatabaseUtils{ @Override public IConnect getConnect() { return new MysqlConnect(); } @Override public ICommand getCommand() { return new MysqlCommand(); } } 假如封装到一个jar包中给所有人使用时，缺少oracle处理工具，我们只需要再具体实现一下数据库连接接口、数据库命令接口和oracle工具类，而不需要去动原有代码\nclass OracleConnect implements IConnect{ @Override public void connect() { System.out.println(\u0026#34;connect oracle ...\u0026#34;); } } class OracleCommand implements ICommand{ @Override public void command() { System.out.println(\u0026#34;oracle command...\u0026#34;); } } class OracleUtils implements IDatabaseUtils{ @Override public IConnect getConnect() { return new OracleConnect(); } @Override public ICommand getCommand() { return new OracleCommand(); } } 对于上面的示例代码，我们可以通过下面这种方式简单调用，通过IDatabaseUtils引用而不需要关注被调用的具体实现细节\npublic class AbstractFactoryTest { public static void main(String[] args) { IDatabaseUtils iDatabaseUtils = new OracleUtils(); // 不再需要关注被调用的具体细节 iDatabaseUtils.getConnect().connect(); iDatabaseUtils.getCommand().command(); } } 总结：抽象工厂模式就是一种为访问类提供一个创建一组相关或相互依赖对象的接口，且访问类无须指定所要产品的具体类就能得到同族的不同等级的产品的模式结构。优点：1.可以在类的内部对产品族中相关联的多等级产品共同管理，而不必专门引入多个新的类来进行管理；2.当增加一个新的产品族时不需要修改原代码，满足开闭原则。\n单例模式（Singleton Pattern） 建造者模式（Builder Pattern） class Product{ private String productName; private String part1; private String part2; public Product(String productName, String part1, String part2){ this.productName = productName; this.part1 = part1; this.part2 = part2; } static class Builder{ private String productName; private String part1; private String part2; public Builder productName(String productName) { this.productName = productName; return this; } public Builder part1(String part1) { this.part1 = part1; return this; } public Builder part2(String part2) { this.part2 = part2; return this; } public Product build(){ return new Product(this.productName, this.part1, this.part2); } } @Override public String toString() { return \u0026#34;Product{\u0026#34; + \u0026#34;productName=\u0026#39;\u0026#34; + productName + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, part1=\u0026#39;\u0026#34; + part1 + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, part2=\u0026#39;\u0026#34; + part2 + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } 原型模式（Prototype Pattern） /** * 模型定义： * 指原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 * * @date 2020/3/23 23:11 */ public class ProtoTypeTest { public static void main(String[] args) throws CloneNotSupportedException { Product product = new Product(\u0026#34;part1\u0026#34;, \u0026#34;part2\u0026#34;, \u0026#34;part3\u0026#34;, \u0026#34;part4\u0026#34;, new Part(\u0026#34;xxx\u0026#34;)); Product clone = product.clone(); System.out.println(product); System.out.println(clone); System.out.println(\u0026#34;---------------对部分数据进行修改----------------\u0026#34;); clone.setPart1(\u0026#34;part1A\u0026#34;); clone.getPart().setName(\u0026#34;YYY\u0026#34;); System.out.println(product); System.out.println(clone); } } class Part implements Cloneable{ String name; @Override protected Part clone() throws CloneNotSupportedException { return (Part) super.clone(); } public Part(String name) { this.name = name; } public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public String toString() { return \u0026#34;Part{[\u0026#34; + hashCode() + \u0026#34;]\u0026#34;+ \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } class Product implements Cloneable{ String part1; String part2; String part3; String part4; public Part getPart() { return part; } public void setPart(Part part) { this.part = part; } Part part; // ... public Product(String part1, String part2, String part3, String part4,Part part) { this.part1 = part1; this.part2 = part2; this.part3 = part3; this.part4 = part4; this.part = part; } @Override protected Product clone() throws CloneNotSupportedException { // 进行深拷贝 Product product = (Product) super.clone(); product.setPart(product.getPart().clone()); return product; } public String getPart1() { return part1; } public void setPart1(String part1) { this.part1 = part1; } public String getPart2() { return part2; } public void setPart2(String part2) { this.part2 = part2; } public String getPart3() { return part3; } public void setPart3(String part3) { this.part3 = part3; } public String getPart4() { return part4; } public void setPart4(String part4) { this.part4 = part4; } @Override public String toString() { return \u0026#34;Product{[\u0026#34; + hashCode() + \u0026#34;]\u0026#34;+ \u0026#34;part1=\u0026#39;\u0026#34; + part1 + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, part2=\u0026#39;\u0026#34; + part2 + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, part3=\u0026#39;\u0026#34; + part3 + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, part4=\u0026#39;\u0026#34; + part4 + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, part=\u0026#34; + part + \u0026#39;}\u0026#39;; } } 结构型模式 适配器模式（Adapter Pattern） 桥接模式（Bridge Pattern） 过滤器模式（Filter、Criteria Pattern） 组合模式（Composite Pattern） 装饰器模式（Decorator Pattern） /** * 装饰者模式：扩展一个类的功能或给一个类附加职责 * * 优点： * 在不改变原有对象的基础上给一个对象扩展功能 * 使用不同的组合可以实现不同的效果 * 符合开闭原则 * * * @author lin.luo@hand-china.com * @date 2020/3/31 0:11 */ public class DecoratorTest { public static void main(String[] args) { Component component = new ConcreteComponent(); // component.operation(); // 在原有的基础上添加功能 component = new ConcreteDecorator1(component); // component.operation(); component = new ConcreteDecorator2(component); component.operation(); } } interface Component{ void operation(); } class ConcreteComponent implements Component{ @Override public void operation() { System.out.println(\u0026#34;拍照\u0026#34;); } } abstract class Decorator implements Component{ Component component; public Decorator(Component component) { this.component = component; } } class ConcreteDecorator1 extends Decorator{ public ConcreteDecorator1(Component component) { super(component); } @Override public void operation() { component.operation(); System.out.println(\u0026#34;美颜\u0026#34;); } } class ConcreteDecorator2 extends Decorator{ public ConcreteDecorator2(Component component) { super(component); } @Override public void operation() { component.operation(); System.out.println(\u0026#34;滤镜\u0026#34;); } } 享元模式（Flyweight Pattern） /** * 享元模式：运用共享技术有效地支持大量细粒度的对象 * 借助全局变量完成对对象的共享 * 对于大量相同的对象，可以节省系统内存 * * @date 2020/3/30 23:58 */ public class FlyWeightTest { public static void main(String[] args) { TreeNode treeNode1 = new TreeNode(3, 4, TreeFactory.getTree(\u0026#34;A\u0026#34;, \u0026#34;XXXX\u0026#34;)); TreeNode treeNode2 = new TreeNode(3, 4, TreeFactory.getTree(\u0026#34;A\u0026#34;, \u0026#34;XXXX\u0026#34;)); TreeNode treeNode3 = new TreeNode(3, 4, TreeFactory.getTree(\u0026#34;B\u0026#34;, \u0026#34;XXXX\u0026#34;)); } } class TreeFactory{ private static HashMap\u0026lt;String, Tree\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); public static Tree getTree(String name, String data){ if(map.containsKey(name)){ return map.get(name); } Tree tree = new Tree(name, data); map.put(name, tree); return tree; } } class TreeNode{ private int x; private int y; private Tree tree; public TreeNode(int x, int y, Tree tree) { this.x = x; this.y = y; this.tree = tree; } } class Tree{ private String name; private String data; public Tree(String name, String data) { this.name = name; this.data = data; System.out.println(\u0026#34;create tree\u0026#34;+name); } public String getName() { return name; } public String getData() { return data; } } 代理模式（Proxy Pattern） 门面模式（Facade Pattern） public class FacadeTest { public static void main(String[] args) { new Facade().facadeDoSomething(); } } class client{ } class Facade{ void facadeDoSomething(){ new SubSystem1().method1(); new SubSystem2().method2(); new SubSystem3().method3(); } } class SubSystem1{ public void method1(){ System.out.println(\u0026#34;sub system1 method1\u0026#34;); } } class SubSystem2{ public void method2(){ System.out.println(\u0026#34;sub system2 method2\u0026#34;); } } class SubSystem3{ public void method3(){ System.out.println(\u0026#34;sub system3 method3\u0026#34;); } } 行为型模式 责任链模式（Chain of Responsibility Pattern） class Request{ private boolean loggedOn; private boolean frequentOk; private boolean isPermits; private boolean containsSensitiveWords; private String requestBody; public Request(boolean loggedOn, boolean frequentOk, boolean isPermits, boolean containsSensitiveWords, String requestBody) { this.loggedOn = loggedOn; this.frequentOk = frequentOk; this.isPermits = isPermits; this.containsSensitiveWords = containsSensitiveWords; this.requestBody = requestBody; } public boolean isLoggedOn() { return loggedOn; } public void setLoggedOn(boolean loggedOn) { this.loggedOn = loggedOn; } public boolean isFrequentOk() { return frequentOk; } public void setFrequentOk(boolean frequentOk) { this.frequentOk = frequentOk; } public boolean isPermits() { return isPermits; } public void setPermits(boolean permits) { isPermits = permits; } public boolean isContainsSensitiveWords() { return containsSensitiveWords; } public void setContainsSensitiveWords(boolean containsSensitiveWords) { this.containsSensitiveWords = containsSensitiveWords; } public String getRequestBody() { return requestBody; } public void setRequestBody(String requestBody) { this.requestBody = requestBody; } } abstract class Handler{ Handler next; public Handler(Handler next) { this.next = next; } public Handler getNext() { return next; } public void setNext(Handler next) { this.next = next; } abstract boolean process(Request request); } class FequentOkHandler extends Handler{ public FequentOkHandler(Handler next) { super(next); } @Override boolean process(Request request) { System.out.print(\u0026#34;访问频率控制:\u0026#34;); if(request.isFrequentOk()){ System.out.println(\u0026#34;ok\u0026#34;); Handler next = getNext(); if(next == null){ return true; } if(!next.process(request)){ return false; } else { return true; } } System.out.println(\u0026#34;error\u0026#34;); return false; } } class IsPermitsHandler extends Handler{ public IsPermitsHandler(Handler next) { super(next); } @Override boolean process(Request request) { System.out.print(\u0026#34;权限访问控制:\u0026#34;); if(request.isPermits()){ System.out.println(\u0026#34;ok\u0026#34;); Handler next = getNext(); if(next == null){ return true; } if(!next.process(request)){ return false; } else { return true; } } System.out.println(\u0026#34;error\u0026#34;); return false; } } class LoggedOnHandler extends Handler{ public LoggedOnHandler(Handler next) { super(next); } @Override boolean process(Request request) { System.out.print(\u0026#34;登录权限控制:\u0026#34;); if(request.isLoggedOn()){ System.out.println(\u0026#34;ok\u0026#34;); Handler next = getNext(); if(next == null){ return true; } if(!next.process(request)){ return false; } else { return true; } } System.out.println(\u0026#34;error\u0026#34;); return false; } } class ContainsSensitiveWordsHandler extends Handler{ public ContainsSensitiveWordsHandler(Handler next) { super(next); } @Override boolean process(Request request) { System.out.print(\u0026#34;敏感词权限控制:\u0026#34;); if(request.isContainsSensitiveWords()){ System.out.println(\u0026#34;ok\u0026#34;); Handler next = getNext(); if(next == null){ return true; } if(!next.process(request)){ return false; } else { return true; } } System.out.println(\u0026#34;error\u0026#34;); return false; } } public class ChainOfResponsibilityTest { public static void main(String[] args) { Request request = new Request(true, true, false, true, \u0026#34;hha\u0026#34;); Handler handler = new FequentOkHandler(new LoggedOnHandler(new ContainsSensitiveWordsHandler(new IsPermitsHandler(null)))); if(handler.process(request)){ System.out.println(\u0026#34;开始进行业务处理\u0026#34;); }else { System.out.println(\u0026#34;请求异常\u0026#34;); } } } 命令模式（Command Pattern） 解释器模式（Interpreter Pattern） 迭代器模式（Iterator Pattern） 迭代器模式是一种用于顺序访问集合对象的元素，但是不需要知道集合对象的底层表示的模式。主要目的是在不暴露聚合对象的内部结构的情况下，让外部代码透明地访问聚合的内部数据。\n迭代器模式主要包含以下角色。\n抽象聚合（Container）角色：定义存储、添加、删除聚合对象以及创建迭代器对象的接口。 具体聚合（MyRepository）角色：实现抽象聚合类，返回一个具体迭代器的实例。 抽象迭代器（Iterator）角色：定义访问和遍历聚合元素的接口，通常包含 hasNext()、next() 等方法。 具体迭代器（MyIterator）角色：实现抽象迭代器接口中所定义的方法，完成对聚合对象的遍历，记录遍历的当前位置。 类图表示如下； 具体实现代码：\n/** * 接口容器 */ public interface Container { Iterator getIterator(); } /** * 接口迭代器 */ public interface Iterator { boolean hasNext(); Object next(); } /** * 具体容器 */ public class MyRepository implements Container { public Object arr[] = {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;}; @Override public Iterator getIterator() { return new MyIterator(); } /** * 具体迭代器 */ private class MyIterator implements Iterator{ int index; @Override public boolean hasNext() { return index \u0026lt; arr.length; } @Override public Object next() { if(this.hasNext()){ return arr[index++]; } return null; } } } /** * 测试类 */ public class IteratorTest { public static void main(String[] args) { Container container = new MyRepository(); Iterator iterator = container.getIterator(); while (iterator.hasNext()){ System.out.println(iterator.next()); } } } 中介者模式（Mediator Pattern） 备忘录模式（Memento Pattern） 观察者模式（Observer Pattern） package com.lin.observe_pattern; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; public class ObservePatternTest { public static void main(String[] args) { EventManager eventManager = new EventManager(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;); eventManager.subscribe(\u0026#34;A\u0026#34;, new ListenerA()); eventManager.subscribe(\u0026#34;A\u0026#34;, new ListenerB()); eventManager.subscribe(\u0026#34;B\u0026#34;, new ListenerA()); eventManager.subscribe(\u0026#34;B\u0026#34;, new ListenerB()); eventManager.notify(\u0026#34;B\u0026#34;, \u0026#34;改变世界\u0026#34;); } } class EventManager{ Map\u0026lt;String, List\u0026lt;EventListener\u0026gt;\u0026gt; listeners = new HashMap\u0026lt;\u0026gt;(); public EventManager(String... operations) { for (String operation : operations) { this.listeners.put(operation, new ArrayList\u0026lt;\u0026gt;()); } } public void subscribe(String eventType, EventListener listener) { List\u0026lt;EventListener\u0026gt; users = listeners.get(eventType); users.add(listener); } public void unsubscribe(String eventType, EventListener listener) { List\u0026lt;EventListener\u0026gt; users = listeners.get(eventType); users.remove(listener); } public void notify(String eventType, String msg) { List\u0026lt;EventListener\u0026gt; users = listeners.get(eventType); for (EventListener listener : users) { listener.comsumer(eventType, msg); } } } /** * 通用观察者接口,定义comsumer方法，消费通知的消息 */ interface EventListener{ void comsumer(String eventType, String msg); } class ListenerA implements EventListener{ @Override public void comsumer(String eventType, String msg) { System.out.println(\u0026#34;ListenerA收到通知:\u0026#34;+eventType+\u0026#34;-\u0026#34;+msg+\u0026#34;,准备xxx\u0026#34;); } } class ListenerB implements EventListener{ @Override public void comsumer(String eventType, String msg) { System.out.println(\u0026#34;ListenerB收到通知:\u0026#34;+eventType+\u0026#34;-\u0026#34;+msg+\u0026#34;,准备yyy\u0026#34;); } } 状态模式（State Pattern） 空对象模式（Null Object Pattern） 策略模式（Strategy Pattern） public class StrategyTest { public static void main(String[] args) { Animal dog = new Dog(); dog.move(); dog.setMoveable(new DogMove()); dog.move(); } } interface Moveable{ void move(); } interface Attackable{ void attack(); } class Runable implements Moveable{ @Override public void move() { System.out.println(\u0026#34;------ run -----\u0026#34;); } } class DogMove implements Moveable{ @Override public void move() { System.out.println(\u0026#34;狗摇着尾巴移动\u0026#34;); } } abstract class Animal{ Moveable moveable; Attackable attackable; public Animal() { } public Animal(Moveable moveable, Attackable attackable) { this.moveable = moveable; this.attackable = attackable; } abstract public void display(); abstract void move(); abstract void attack(); public Moveable getMoveable() { return moveable; } public void setMoveable(Moveable moveable) { this.moveable = moveable; } public Attackable getAttackable() { return attackable; } public void setAttackable(Attackable attackable) { this.attackable = attackable; } } class Dog extends Animal{ public Dog() { super(new Runable(), null); } public Dog(Moveable moveable, Attackable attackable) { super(moveable, attackable); } @Override public void display() { System.out.println(\u0026#34;------ 狗 ----------\u0026#34;); } @Override void move() { moveable.move(); } @Override void attack() { attackable.attack(); } } 模板模式（Template Pattern） 模板方法模式的目的就是在不改变现有类的算法结构下，将一些具体步骤延迟到子类中，\n/** * 模式定义： * 定义一个操作的算法骨架，而将一些步骤延迟到子类中。 * Template Method 使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤 * * Servlet Api \u0026amp; Spring中的应用 * javax.servlet.http.HttpServlet * org.springframework.web.servlet.mvc.AbstractController * * @author 2493468168@qq.com * @date 2020/3/22 14:55 */ public class TemplateMethodTest { public static void main(String[] args) { AbstractClass abstractClass = new SubClass(); abstractClass.operate(); System.out.println(\u0026#34;--------------\u0026#34;); AbstractClass abstractClass2 = new SubClass2(); abstractClass2.operate(); /** * pre... * step1.. * templateMethod1() * step final... * -------------- * pre... * step1.. * templateMethod2() * step final... */ } } abstract class AbstractClass{ public void operate(){ System.out.println(\u0026#34;pre...\u0026#34;); System.out.println(\u0026#34;step1..\u0026#34;); templateMethod(); System.out.println(\u0026#34;step final...\u0026#34;); } abstract void templateMethod(); } class SubClass extends AbstractClass{ @Override void templateMethod() { System.out.println(\u0026#34;templateMethod1()\u0026#34;); } } class SubClass2 extends AbstractClass{ @Override void templateMethod() { System.out.println(\u0026#34;templateMethod2()\u0026#34;); } } 访问者模式（Visitor Pattern） 参考资料： 设计模式目录：22种设计模式 (refactoringguru.cn)\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","summary":"Java设计模式概述 设计模式（Design pattern）是软件开发人员在软件开发过程中面临的一般问题的解决方案模板，这些模板是经过相当长的","title":"设计模式"},{"content":"什么是HashTable 对比其他数据结构，HashTable是一种典型的空间换时间思想的结构，大体思路就是创建一个数组，通过一个hash函数以及关键字计算出所要存值的数组下标，之后取值的时候再通过hash函数计算出所要取值的数组下标，下标地址index = hash(key)。但是使用hash函数计算出的下标可能会存在重复，也就是hash冲突，如何处理hash冲突是需要我们思考的。\nHash函数 直接地址法 取关键字或关键字的某个线性函数值为哈希地址，即 H(key)=key或H(key)=a*key+b\n数字分析法 假设关键字是以r为基的数，并且哈希表中可能出现的关键字都是事先知道的，则可取关键字的若干数位组成哈希地址。\n平方取中法 去关键字平方后的中间几位为哈希地址。\n折叠法 将关键字分割成位数相同的几部分（最后一部分的位数可以不同），然后取这几部分的叠加和（舍去进位）作为哈希地址。在折叠法中数位叠加可以有移位叠加和间界叠加两种方法。移位叠加是将分割后的每一部分的最低位对齐，然后相加；间界叠加是从一端向另一端沿分隔界来回折叠，然后对齐相加。\n除留余数法 取关键字被某个不大于哈希表表长m的数p除后所得余数为哈希地址，即H(key)=key%p，p≤m。\n随机数法 选择一个随机函数，去关键字的随机函数值为它的哈希地址，即H(key)=random(key)，其中random为随机函数。\nHash函数设计的考虑因素 计算散列地址所需要的时间（即hash函数本身不要太复杂） 关键字的长度 表长 关键字分布是否均匀，是否有规律可循 设计的hash函数在满足以上条件的情况下尽量减少冲突 Hash冲突 通过hash(key)计算出来的结果是有可能存在重复的，也就是hash冲突，也就是说我们需要解决hash冲突。\n开放定址法 如果H（key1）=H（keyi） 那么keyi存储位置H i = ( H ( k e y ) + d i ) % m ，m为表长。di有三种取法 其中H(key)为hash函数，m为hash表表长，\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/hashtable/","summary":"什么是HashTable 对比其他数据结构，HashTable是一种典型的空间换时间思想的结构，大体思路就是创建一个数组，通过一个hash函数","title":"HashTable"},{"content":"List接口 An ordered collection (also known as a sequence). The user of this interface has precise control over where in the list each element is inserted. The user can access elements by their integer index (position in the list), and search for elements in the list.\n上面这段引用就是jdk8对List的定义-一个有序的集合。\nArrayList、LinkedList、Vector的异同 三个实现类都存储有序的、可重复的数据 ArrayList相当于数据结构中的线性表，是List接口的主要实现类；具有线程不安全、效率高的特点；底层使用Object[] elementData存储数据。 LinkedList相当于数据结构中的链表；处理插入、删除操作时，效率比ArrayList高；底层使用双向链表存储数据。 Vector是List接口的比较老的实现类；线程安全但是效率低；底层使用Object[] elementData存储数据。 由于List下面的三个实现类都比较简单，这里就不做过多的赘述。主要是注意一下如果遍历的过程中要对List进行删除操作的时候最好是使用Iterator，不要使用for（不管是普通for还是增强for），会出现错误，具体错误如下：\n@Test public void test4(){ List\u0026lt;Employee\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(16); for(int i = 0; i \u0026lt; 5; i++){ list.add(new Employee(\u0026#34;test\u0026#34;,i,i)); } for(int i = 0; i \u0026lt; list.size(); i++){ Employee employee = list.get(i); if(employee.age == employee.salary) { list.remove(i); } } for(Employee employee:list){ System.out.println(employee); } /** * 打印结果： * Employee{name=\u0026#39;test\u0026#39;, age=1, salary=1} * Employee{name=\u0026#39;test\u0026#39;, age=3, salary=3} */ } 上面的代码使用普通for循环进行删除操作，按照我们的本意是会将所有元素都删除，但是结果还剩下2个，原因是因为每次删除i位置的元素后，List中i之后的元素向前走一步，然后执行了一次i++，于是乎跳过了一个元素，慢慢的会积累多个出来。再看下增强for：\n@Test public void test4(){ List\u0026lt;Employee\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(16); for(int i = 0; i \u0026lt; 5; i++){ list.add(new Employee(\u0026#34;test\u0026#34;,i,i)); } for(Employee employee:list){ if(employee.age == employee.salary){ if(list.remove(employee)){ System.out.println(\u0026#34;remove success\u0026#34;); } } } for(Employee employee:list){ System.out.println(employee); } /** * 打印结果： * run equals().... * remove success * * java.util.ConcurrentModificationException * at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:907) * at java.util.ArrayList$Itr.next(ArrayList.java:857) * at com.chapter12_collection.CollectionTest.test4(CollectionTest.java:70) */ } 发现增强for的确删除一个元素成功了，但是删除第二个元素的时候报错ConcurrentModificationException,于是乎增强for中删除元素也是不可行的。那我们再来看下正确的做法：\n@Test public void test4(){ List\u0026lt;Employee\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(16); for(int i = 0; i \u0026lt; 5; i++){ list.add(new Employee(\u0026#34;test\u0026#34;,i,i)); } Iterator\u0026lt;Employee\u0026gt; iterator = list.iterator(); while (iterator.hasNext()){ Employee employee = iterator.next(); if(employee.age == employee.salary){ iterator.remove(); } } /** * 打印结果为空 */ } @Test public void test5(){ List\u0026lt;Employee\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(16); for(int i = 0; i \u0026lt; 5; i++){ list.add(new Employee(\u0026#34;test\u0026#34;+i,i*2,i*3)); } Iterator\u0026lt;Employee\u0026gt; iterator = list.iterator(); while (iterator.hasNext()){ Employee employee = iterator.next(); if(employee.age == 0){ iterator.remove(); continue; } System.out.println(employee); } /** * 打印结果： * Employee{name=\u0026#39;test1\u0026#39;, age=2, salary=3} * Employee{name=\u0026#39;test2\u0026#39;, age=4, salary=6} * Employee{name=\u0026#39;test3\u0026#39;, age=6, salary=9} * Employee{name=\u0026#39;test4\u0026#39;, age=8, salary=12} */ } 踩坑一 List中所有元素指向同一个地址内存 ArrayList中的每一个元素存储的实际上是对象引用（之前在公司写代码的时候，做过类似下面的事），假如按照下面的方式使用ArrayList，则最后list中存储的元素都相同且都是最后一个元素，原因是list中所有的元素都指向同一块内存。\n@Test public void test1(){ List\u0026lt;Person\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(16); Person p = new Person(); for(int i = 0; i \u0026lt; 10; i++){ p.setName(\u0026#34;test\u0026#34;+i); p.setAge(i); list.add(p); } System.out.println(list); } 结果所有list中的元素都指向同一个Person实例\n[Person{name=\u0026#39;test9\u0026#39;, age=9}, Person{name=\u0026#39;test9\u0026#39;, age=9}, ...,Person{name=\u0026#39;test9\u0026#39;, age=9}, Person{name=\u0026#39;test9\u0026#39;, age=9}] 踩坑二 List中存储了一个元素null 这个坑出现了两次，一次是使用stream之后collect转为list，但是结果为List[null]，另外一次就是使用Mybatis查询数据库返回的结果为List[null]；\n使用stream之后collect转为list结果为List[null] stream通过流映射出list中为null的值，转为为list，此时就会出现List中有null的值。 @Test public void testStream(){ List\u0026lt;Person\u0026gt; list = Arrays.asList(new Person(\u0026#34;cc\u0026#34;), new Person(\u0026#34;abc\u0026#34;)); List\u0026lt;Long\u0026gt; collect = list.stream().map(Person::getAge).collect(Collectors.toList()); System.out.println(\u0026#34;stream操作之后：\u0026#34;+collect); collect.removeAll(Collections.singleton(null)); System.out.println(\u0026#34;removeAll之后：\u0026#34;+collect); } 上面代码执行结果： stream操作之后：[null, null] removeAll之后：[] 数据库返回的结果为List[null] SELECT NULL AS a.col1, b.* FROM a LEFT JOIN b ON a.id = b.id where a.col2= \u0026#39;AAA\u0026#39;; 假如此时a表查到了数据，而b表没有查询到数据，那么此时返回的是每一行是[null]，具体行数则由a的行数来决定；如果使用的是mybatis查询，返回的结果应该是一个list，只不过这个list里面所有的元素都是null。 对于上面说的两种List[null]情况，如果是不需要list中有null值得话，都可以借助collect.removeAll(Collections.singleton(null));来去除list中的null。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java-list/","summary":"List接口 An ordered collection (also known as a sequence). The user of this interface has precise control over where in the list each element is inserted. The user can access elements by their integer index (position in the list), and search for elements in the list. 上面这段引用就是jdk8对List的定","title":"Java List"},{"content":"本文主要介绍Map接口以及其主要实现类：HashMap、LinkedHashMap、TreeMap、Hashtable、Properties，其中包括HashMap、TreeMap的底层实现原理。\nMap的遍历方式 方式一,这是最常见的并且在大多数情况下也是最可取的遍历方式。在键值都需要时使用:\nMap\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;Integer, Integer\u0026gt;(); for (Map.Entry\u0026lt;Integer, Integer\u0026gt; entry : map.entrySet()) { System.out.println(\u0026#34;Key = \u0026#34; + entry.getKey() + \u0026#34;, Value = \u0026#34; + entry.getValue()); } 方式二，在for-each循环中遍历keys或values(据说该方法比entrySet遍历在性能上稍好（快了10%），我还没有测试过)：\nMap\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;Integer, Integer\u0026gt;(); //遍历map中的键 for (Integer key : map.keySet()) { System.out.println(\u0026#34;Key = \u0026#34; + key); } //遍历map中的值 for (Integer value : map.values()) { System.out.println(\u0026#34;Value = \u0026#34; + value); } 方式三，使用迭代器遍历（该种方式看起来冗余却有其优点所在。首先，在老版本java中这是惟一遍历map的方式。另一个好处是，你可以在遍历时调用iterator.remove()来删除entries，另两个方法则不能。）：\n// 不使用泛型 Map map = new HashMap(); Iterator entries = map.entrySet().iterator(); while (entries.hasNext()) { Map.Entry entry = (Map.Entry) entries.next(); Integer key = (Integer)entry.getKey(); Integer value = (Integer)entry.getValue(); System.out.println(\u0026#34;Key = \u0026#34; + key + \u0026#34;, Value = \u0026#34; + value); } // 使用泛型 Map\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); Iterator\u0026lt;Map.Entry\u0026lt;Integer, Integer\u0026gt;\u0026gt; iterator = map.entrySet().iterator(); while (iterator.hasNext()){ Map.Entry\u0026lt;Integer, Integer\u0026gt; next = iterator.next(); System.out.println(next); } 方式四，通过键找值遍历（循环中通过key来拿到value效率低）：\nMap\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;Integer, Integer\u0026gt;(); for (Integer key : map.keySet()) { Integer value = map.get(key); System.out.println(\u0026#34;Key = \u0026#34; + key + \u0026#34;, Value = \u0026#34; + value); } JDK HashMap源码分析 HashMap初始化：\nstatic final int MAXIMUM_CAPACITY = 1 \u0026lt;\u0026lt; 30; static final float DEFAULT_LOAD_FACTOR = 0.75f; public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity \u0026lt; 0) throw new IllegalArgumentException(\u0026#34;Illegal initial capacity: \u0026#34; + initialCapacity); if (initialCapacity \u0026gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\u0026#34;Illegal load factor: \u0026#34; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); } public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted } public HashMap(Map\u0026lt;? extends K, ? extends V\u0026gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); } static final int tableSizeFor(int cap) { int n = cap - 1; n |= n \u0026gt;\u0026gt;\u0026gt; 1; n |= n \u0026gt;\u0026gt;\u0026gt; 2; n |= n \u0026gt;\u0026gt;\u0026gt; 4; n |= n \u0026gt;\u0026gt;\u0026gt; 8; n |= n \u0026gt;\u0026gt;\u0026gt; 16; return (n \u0026lt; 0) ? 1 : (n \u0026gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } 显然，在初始化时如果没有传入Map的大小，则只是改了下了一个加载因子；而在传入initialCapacity时则会计算出threshold（临界值），用于判断是否进行扩容。然后在使用put()的时候才会真正创建hashTable：\nstatic final int DEFAULT_INITIAL_CAPACITY = 1 \u0026lt;\u0026lt; 4; // aka 16 /** * Associates the specified value with the specified key in this map. * If the map previously contained a mapping for the key, the old * value is replaced. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with \u0026lt;tt\u0026gt;key\u0026lt;/tt\u0026gt;, or * \u0026lt;tt\u0026gt;null\u0026lt;/tt\u0026gt; if there was no mapping for \u0026lt;tt\u0026gt;key\u0026lt;/tt\u0026gt;. * (A \u0026lt;tt\u0026gt;null\u0026lt;/tt\u0026gt; return can also indicate that the map * previously associated \u0026lt;tt\u0026gt;null\u0026lt;/tt\u0026gt; with \u0026lt;tt\u0026gt;key\u0026lt;/tt\u0026gt;.) */ public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } /** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don\u0026#39;t change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node\u0026lt;K,V\u0026gt; e; K k; // 此时p == tab[i = (n - 1) \u0026amp; hash] if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) // 向红黑树中插入结点 e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value); else { for (int binCount = 0; ; ++binCount) { //没有终止条件的循环用于查看该索引上所有的node结点 if ((e = p.next) == null) { //下一个为空时新建一个结点 p.next = newNode(hash, key, value, null); if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) // 此时需要进行替换value break; p = e; } } if (e != null) { // existing mapping for key，key的hash值发生冲突 V oldValue = e.value; // key的hash发生冲突后必然会进行一次替换（onlyIfAbsent默认为false） if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size \u0026gt; threshold) resize(); afterNodeInsertion(evict); return null; } /** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */ final Node\u0026lt;K,V\u0026gt;[] resize() { Node\u0026lt;K,V\u0026gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap \u0026gt; 0) { if (oldCap \u0026gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr \u0026lt;\u0026lt; 1; // double threshold } else if (oldThr \u0026gt; 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; //默认16 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); // 默认0.75*16 = 12 } if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({\u0026#34;rawtypes\u0026#34;,\u0026#34;unchecked\u0026#34;}) Node\u0026lt;K,V\u0026gt;[] newTab = (Node\u0026lt;K,V\u0026gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { for (int j = 0; j \u0026lt; oldCap; ++j) { Node\u0026lt;K,V\u0026gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash \u0026amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode\u0026lt;K,V\u0026gt;)e).split(this, newTab, j, oldCap); else { // preserve order Node\u0026lt;K,V\u0026gt; loHead = null, loTail = null; Node\u0026lt;K,V\u0026gt; hiHead = null, hiTail = null; Node\u0026lt;K,V\u0026gt; next; do { next = e.next; if ((e.hash \u0026amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } 从上面的代码以及部分我自己标注的中文注释可以看到：默认是创建了一个长度为16的表(Node\u0026lt;K,V\u0026gt;[])new Node[newCap]；其临界值threshold为12。在后面每次调用put操作时也是调用上面三个方法。当然，上面的代码也是可以看出，put首先调用key1所在类的hashCode()计算key1的哈希值，过程如下：\nstatic final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); } 此哈希值经过i = ((tab = resize()).length - 1) \u0026amp; hash后获得插入到哈希数组中的index，在put过程中会有如下情况：\n如果此位置的数据为空，此时的key1-value1添加成功。 如果此位置的数据不为空，（意味这此位置有一个或者多个数据存在），比较key1和已经存在数据的哈希值： 如果key1的哈希值与已经存在的数据的哈希值都不相同，此时key1-value1添加到第一个位置，后续为原来的链表数据。 如果key1的哈希值与已经存在的的某个数据(key2-value2)的hash值相同，继续比较；调用key对象的equals()方法， 如果equals()返回false：，此时key1-value1添加到第一个位置，后续为原来的链表数据。 如果equals()返回true:此时使用value1替换value2并返回value2具体比较代码如下： if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) 当然，在这里还是得说下jdk1.8相较与jdk1.7在底层实现方面还是的一些不同：\n初始化时jdk1.7时直接创建了一个长度为16的数组，而1.8没有。 jdk1.8底层的数组时Node[]而非Entry[],当他们实际是差不多的。 jdk1.8是在首次调用put()方法的时候创建数组。 jdk1.7的底层结构只有数组+链表；jdk1.8的底层结构为数组+链表+红黑树当数组的某一个索引位置上的元素以链表的形式存在的数据个数\u0026gt;8且当前数组的长度\u0026gt;64时，此时此索引位置上的所有数据改为使用红黑树存储。 JDK LinkedHashMap源码分析 LinkedHashMap初始化：\npublic class LinkedHashMap\u0026lt;K,V\u0026gt; extends HashMap\u0026lt;K,V\u0026gt; implements Map\u0026lt;K,V\u0026gt; { public LinkedHashMap(int initialCapacity, float loadFactor) { super(initialCapacity, loadFactor); accessOrder = false; } public LinkedHashMap(int initialCapacity) { super(initialCapacity); accessOrder = false; } public LinkedHashMap() { super(); accessOrder = false; } public LinkedHashMap(Map\u0026lt;? extends K, ? extends V\u0026gt; m) { super(); accessOrder = false; putMapEntries(m, false); } public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) { super(initialCapacity, loadFactor); this.accessOrder = accessOrder; } } 在初始化的过程中，我们发现LinkedHashMap就是HashMap，那么它和HashMap有什么区别呢，我们还是得看它的put()方法，然后在LinkedHashMap中却没有找到put()方法，这个时候怎么办呢？看它的父类，查看父类中的put()方法：\npublic V put(K key, V value) { return putVal(hash(key), key, value, false, true); } 发现还是得找putVal方法，于是接着看：\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node\u0026lt;K,V\u0026gt; e; K k; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value); else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size \u0026gt; threshold) resize(); afterNodeInsertion(evict); return null; } 初始化的过程中我们必定java必定会执行：tab[i] = newNode(hash, key, value, null);这句代码，于是去看newNode,点进去，发现HashMap中的newNode方法是这样子的：\nNode\u0026lt;K,V\u0026gt; newNode(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; next) { return new Node\u0026lt;\u0026gt;(hash, key, value, next); } 那LinkedHashMap怎么和HashMap一样啊，这个时候就该思考，会不会是子类中还有什么是我们没有看到的，接着看子类LinkedHashMap，发现LinkedHashMap中也有newNode方法，原来是重写了：\nNode\u0026lt;K,V\u0026gt; newNode(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; e) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = new LinkedHashMap.Entry\u0026lt;K,V\u0026gt;(hash, key, value, e); linkNodeLast(p); return p; } 再接着点进Entry看看是什么东西：\nstatic class Entry\u0026lt;K,V\u0026gt; extends HashMap.Node\u0026lt;K,V\u0026gt; { Entry\u0026lt;K,V\u0026gt; before, after; Entry(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; next) { super(hash, key, value, next); } } 哦，原来它生成了一个和HashMap一样的结点，还在Entry\u0026lt;K,V\u0026gt; before, after;这里使用了before和after去记录生成的结点的前后顺序。\nJDK TreeMap源码分析 A Red-Black tree based NavigableMap implementation. The map is sorted according to the Comparable natural ordering of its keys, or by a Comparator provided at map creation time, depending on which constructor is used.\n上面这段话是java官方给出的说明，显然，TreeMap底层就是使用红黑树来实现的，并且是一个可以排序的Map，其中既可以使用自然排序，也可以是使用Comparator比较器来进行排序。自然排序：\n@Test public void test9(){ Map\u0026lt;Integer, Object\u0026gt; map = new TreeMap\u0026lt;\u0026gt;(); map.put(11, \u0026#34;dasd\u0026#34;); map.put(-1, \u0026#34;dasda\u0026#34;); map.put(22, \u0026#34;dasd\u0026#34;); map.put(33, \u0026#34;dasd\u0026#34;); map.put(44, \u0026#34;dasd\u0026#34;); map.put(44, \u0026#34;dad\u0026#34;); Iterator\u0026lt;Map.Entry\u0026lt;Integer, Object\u0026gt;\u0026gt; iterator = map.entrySet().iterator(); while (iterator.hasNext()){ Map.Entry\u0026lt;Integer, Object\u0026gt; next = iterator.next(); System.out.println(next); } /** * 打印结果： * -1=dasda * 11=dasd * 22=dasd * 33=dasd * 44=dad */ } Comparetor比较器排序：\n@Test public void test10(){ Map\u0026lt;Employee, Object\u0026gt; map = new TreeMap\u0026lt;\u0026gt;(); for(int i = 5; i \u0026gt; 0; i--){ map.put(new Employee(\u0026#34;test\u0026#34;+i, i, i), \u0026#34;dasd\u0026#34;); } Iterator\u0026lt;Map.Entry\u0026lt;Employee, Object\u0026gt;\u0026gt; iterator = map.entrySet().iterator(); while (iterator.hasNext()){ Map.Entry\u0026lt;Employee, Object\u0026gt; next = iterator.next(); System.out.println(next); } /** * 打印结果： * Employee{name=\u0026#39;test1\u0026#39;, age=1, salary=1}=dasd * Employee{name=\u0026#39;test2\u0026#39;, age=2, salary=2}=dasd * Employee{name=\u0026#39;test3\u0026#39;, age=3, salary=3}=dasd * Employee{name=\u0026#39;test4\u0026#39;, age=4, salary=4}=dasd * Employee{name=\u0026#39;test5\u0026#39;, age=5, salary=5}=dasd */ } Java Properties使用实例——HashMap应用 Properties是HashMap的重要应用，利用了HashMap通过key查找迅速的特点，将这一特点用在了读取配置文件上，具体的使用如下：在项目的资源文件夹下新建test.properties文件：\nname=1baidu 测试代码：\n@Test public void test1() throws Exception{ Properties properties = new Properties(); FileInputStream fileInputStream= new FileInputStream(\u0026#34;test.properties\u0026#34;); properties.load(fileInputStream); System.out.println(\u0026#34;name=\u0026#34;+properties.getProperty(\u0026#34;name\u0026#34;)); /** * 打印结果： * name=1baidu */ } [[Java后端面试题]]\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java-map/","summary":"本文主要介绍Map接口以及其主要实现类：HashMap、LinkedHashMap、TreeMap、Hashtable、Properties","title":"Java Map"},{"content":"Set接口 HashSet、LinkedHashSet、TreeSet HashSet是Set接口的典型实现，大多数时候Set集合都使用这个实现类。HashSet是按Hash算法来存储集合中的元素，因此具有很好的存取、查找、删除性能。底层就是HashMap;HashSet具有以下特点：不能保证元素的排列顺序；HashSet不是线程安全的；集合元素可以是null；HashSet集合判断两个元素相等的标准：两个对象通过hashCode()方法比较相等，并且两个对象的equals()方法返回值也相等。对于存放在Set容器中的对象，对应的类一定要重写equals()和hashCode()方法，以实现对象相等规则。既“相等的对象必须具有相同的hashCode” LinkedHashSet是HaseSet的子类LinkedHashSet根据元素的hashCode值来决定元素的存储位置，但它同时使用双向链表维护元素的次序，这使得元素看起来是以插入顺序保存的。LinkedHashSet插入性能略低于HashSet，但在迭代访问Set里的全部元素时有很好的性能。LinkedHashSet不允许集合元素重复。 TreeSet是SortedSet接口的实现类，TreeSet可以确保集合元素处于排序状态。TreeSet底层就是TreeMap，而TreeMap底层使用红黑树结构（JDK1.8以后）存储key,TreeSet只是使用TreeMap的keyTreeSet两种排序方法：自然排序和Comparetor比较器排序，默认使用自然排序。 HashSet HashSet的底层初始化：\nprivate transient HashMap\u0026lt;E,Object\u0026gt; map; public HashSet() { map = new HashMap\u0026lt;\u0026gt;(); } public HashSet(Collection\u0026lt;? extends E\u0026gt; c) { map = new HashMap\u0026lt;\u0026gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c); } public HashSet(int initialCapacity, float loadFactor) { map = new HashMap\u0026lt;\u0026gt;(initialCapacity, loadFactor); } public HashSet(int initialCapacity) { map = new HashMap\u0026lt;\u0026gt;(initialCapacity); } 可以看到HashSet底层就是一个HashMap，那这里就不多关于HashMap的东西，主要看下对HashSet的测试:\n@Test public void test6(){ Set\u0026lt;Employee\u0026gt; set = new HashSet\u0026lt;\u0026gt;(10); System.out.println(set.size()); for(int i = 0; i \u0026lt; 5; i++){ set.add(new Employee(\u0026#34;test\u0026#34;,(i%2 == 0) ? 2 : 1,(i%2 == 0) ? 2 : 1)); } Iterator\u0026lt;Employee\u0026gt; iterator = set.iterator(); while (iterator.hasNext()){ Employee employee = iterator.next(); System.out.println(employee); } /** * 打印结果： * 0 * run hashCode ... * run hashCode ... * run hashCode ... * run equals().... * run hashCode ... * run equals().... * run hashCode ... * run equals().... * Employee{name=\u0026#39;test\u0026#39;, age=2, salary=2} * Employee{name=\u0026#39;test\u0026#39;, age=1, salary=1} * 2 */ /** * Employee的equals()重写时加了一句: * System.out.println(\u0026#34;run equals()....\u0026#34;); * Employee的hashCode()重写时加了一句: * System.out.println(\u0026#34;run hashCode ... \u0026#34;); * 上面对List进行测试的时候也加了。。。 */ } 从上面的打印结果可以看到，初始化后set的size为0，后面每次添加一个元素size都会增长1，而再添加过程中如果遇到hashCode相同情况下会进行equals判断，元素内的值相同会导致添加失败。所以最终set中只有2个元素。\nLinkedHashSet LinkedHashSet的底层初始化：\npublic class LinkedHashSet\u0026lt;E\u0026gt; extends HashSet\u0026lt;E\u0026gt; implements Set\u0026lt;E\u0026gt;, Cloneable, java.io.Serializable { public LinkedHashSet(int initialCapacity, float loadFactor) { super(initialCapacity, loadFactor, true); } public LinkedHashSet(int initialCapacity) { super(initialCapacity, .75f, true); } public LinkedHashSet() { super(16, .75f, true); } public LinkedHashSet(Collection\u0026lt;? extends E\u0026gt; c) { super(Math.max(2*c.size(), 11), .75f, true); addAll(c); } } 父类HashSet下的带有三个参数的构造器：\nHashSet(int initialCapacity, float loadFactor, boolean dummy) { map = new LinkedHashMap\u0026lt;\u0026gt;(initialCapacity, loadFactor); } 显然，LinkedHashSet底层是使用LinkedHashMap实现的，也就是说它带有LinkedHashMap的特点——可以找到添加过程中的前后元素。具体可以看LinkedHashMap\nTreeSet TreeSet的底层初始化：\npublic TreeSet() { this(new TreeMap\u0026lt;E,Object\u0026gt;()); } public TreeSet(Comparator\u0026lt;? super E\u0026gt; comparator) { this(new TreeMap\u0026lt;\u0026gt;(comparator)); } public TreeSet(Collection\u0026lt;? extends E\u0026gt; c) { this(); addAll(c); } public TreeSet(SortedSet\u0026lt;E\u0026gt; s) { this(s.comparator()); addAll(s); } 使用TreeSet：\n@Test public void test7(){ Set\u0026lt;Employee\u0026gt; set = new TreeSet\u0026lt;\u0026gt;(); for(int i = 0; i \u0026lt; 5; i++){ set.add(new Employee(\u0026#34;test\u0026#34;,i,i)); } Iterator\u0026lt;Employee\u0026gt; iterator = set.iterator(); while (iterator.hasNext()){ Employee employee = iterator.next(); System.out.println(employee); } /** * 报错: * java.lang.ClassCastException: com.chapter12_collection.Employee cannot be cast to java.lang.Comparable * * at java.util.TreeMap.compare(TreeMap.java:1294) * at java.util.TreeMap.put(TreeMap.java:538) * at java.util.TreeSet.add(TreeSet.java:255) * at com.chapter12_collection.CollectionTest.test7(CollectionTest.java:115) * at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) * ... */ } 发现必须得把Employee转成Comparable，那么就让Employee实现Comparable接口呗。于是乎重写里面的compareTo（）方法：\n// 先按name排序，再按age排序 @Override public int compareTo(Object o) { if(o instanceof Employee){ Employee employee = (Employee) o; if(this.name == employee.getName()){ return Integer.compare(this.age, employee.getAge()); }else { return this.name.compareTo(employee.getName()); } }else { throw new RuntimeException(\u0026#34;输入的类型不是Employee\u0026#34;); } } 再来跑测试代码：\n@Test public void test7(){ Set\u0026lt;Employee\u0026gt; set = new TreeSet\u0026lt;\u0026gt;(); for(int i = 5; i \u0026gt; 0; i--){ set.add(new Employee(\u0026#34;test\u0026#34;+i,i,i)); } Iterator\u0026lt;Employee\u0026gt; iterator = set.iterator(); while (iterator.hasNext()){ Employee employee = iterator.next(); System.out.println(employee); } /** * 打印结果： * Employee{name=\u0026#39;test1\u0026#39;, age=1, salary=1} * Employee{name=\u0026#39;test2\u0026#39;, age=2, salary=2} * Employee{name=\u0026#39;test3\u0026#39;, age=3, salary=3} * Employee{name=\u0026#39;test4\u0026#39;, age=4, salary=4} * Employee{name=\u0026#39;test5\u0026#39;, age=5, salary=5} */ } 显然，此时是按照name从小到大排序的，而我们插入的时候是从大到小的，也就是说TreeSet是可以实现Comparable比较器排序的，关于自然排序就看下下面这段代码吧：\n@Test public void test8(){ Set\u0026lt;Integer\u0026gt; set = new TreeSet\u0026lt;\u0026gt;(); set.add(11); set.add(-1); set.add(33); set.add(22); set.add(44); Iterator\u0026lt;Integer\u0026gt; iterator = set.iterator(); while (iterator.hasNext()){ System.out.print(iterator.next() + \u0026#34; \u0026#34;); } /** * 打印结果： * -1 11 22 33 44 */ } ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java-set/","summary":"Set接口 HashSet、LinkedHashSet、TreeSet HashSet是Set接口的典型实现，大多数时候Set集合都使用这个实现","title":"Java Set"},{"content":"为什么要用反射 运行时决定执行逻辑 实现动态代理（Spring依赖注入） 实现依赖注入和AOP（Spring吃饭的家伙） 反射有什么缺点 性能损失：反射比直接调用方法或访问字段慢得多，因为它需要额外查找和解析类、方法和字段的信息。 代码可读性和维护性变得较差 在说反射之前，必须说一句，所谓java框架（比如大名鼎鼎的Spring）大多数都是动态代理+注解完成的，而动态代理（动态代理模式以及静态代理模式差异和使用可以在我的另一篇文章中看到）必须使用反射完成。反射可以获取本类、父类以及实现的接口中的所有方法以及所有属性。\n获取运行时类的实例 获取运行时类得实例主要有四种方式：\n@Test public void test4() throws ClassNotFoundException { /** * 获取运行时类的实例 */ // 调用运行时类的属性 Class\u0026lt;Person\u0026gt; clazz1 = Person.class; System.out.println(clazz1); // 通过运行时类的对象调用getClass() Person person = new Person(); Class\u0026lt;? extends Person\u0026gt; clazz2 = person.getClass(); System.out.println(clazz2); // 调用Class的静态方法：forName(String classPath) Class clazz3 = Class.forName(\u0026#34;com.reflect.Person\u0026#34;); System.out.println(clazz3); System.out.println(clazz1 == clazz2); System.out.println(clazz1 == clazz3); // 使用类的加载器 ClassLoader classLoader = ReflectTest.class.getClassLoader(); Class clazz4 = classLoader.loadClass(\u0026#34;com.reflect.Person\u0026#34;); System.out.println(clazz4); System.out.println(clazz1 == clazz4); } 另外，关于java.lang.Class类：\n类的加载过程：程序经过javac.exe命令后，会生成一个或者多个字节码文件(以.class结尾) 接着使用java.exe命令后对某个字节码文件进行解释运行，相当于将某个字节码文件加载到内存中，此过程称为类的加载。加载到内存中的类，称之为运行时类，此运行时类，作为Class的一个实例 换句话说，Class的实例就对应这一个运行时类 加载到内存中的运行时类，会缓存一定的时间，在此时间之内，我们可以通过不同的方式来获取此运行时类,在其生命周期类，这个运行时类也可以说是一个单例的 反射调用私有属性和私有方法 在使用反射之前，由于java的封装性原因，我们是访问不到私有属性和私有方法的，但是如果使用反射的话是可以访问到私有属性和私有方法的,通过。\n@Test public void test3() throws Exception{ Class clazz = Person.class; // 通过反射可以调用Person类的私有接口，比如私有构造器、私有方法和私有属性 // 调用私有构造器 Constructor constructor2 = clazz.getDeclaredConstructor(String.class); // 私有构造器、私有方法和私有属性必须使用setAccessible打开权限 constructor2.setAccessible(true); System.out.println(\u0026#34;begin....\u0026#34;); //此时通过对应的构造器创建实例 Object jim = constructor2.newInstance(\u0026#34;jim\u0026#34;); System.out.println(jim); Person person =(Person)jim; person.t2(\u0026#34;iop\u0026#34;); System.out.println(\u0026#34;** **** **** **** **** **\u0026#34;); // 调用私有属性 Field name = clazz.getDeclaredField(\u0026#34;name\u0026#34;); name.setAccessible(true); name.set(jim, \u0026#34;som\u0026#34;); System.out.println(jim); System.out.println(\u0026#34;** **** **** **** **** **** ***8\u0026#34;); // 调用私有方法 Method t1 = clazz.getDeclaredMethod(\u0026#34;t1\u0026#34;, String.class); t1.setAccessible(true); Object dd = (String)t1.invoke(jim, \u0026#34;dd\u0026#34;); System.out.println(dd); } 在使用私有属性和私有方法的时候必须开放权限：constructor2.setAccessible(true);问1：通过直接new的方式或反射的方式都可以调用公共结构，开发中该使用哪个？建议：直接new的方式什么时候会使用反射的方式：编译的时候不能确定应该new哪个对象（可以参考servlet、spring）\n问2：反射时可以访问内部资源和java的封装性是否有冲突不冲突，因为java的封装性只是说建议这样子做，而反射式提供了一种访问内部资源的方式\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java-%E5%8F%8D%E5%B0%84/","summary":"为什么要用反射 运行时决定执行逻辑 实现动态代理（Spring依赖注入） 实现依赖注入和AOP（Spring吃饭的家伙） 反射有什么缺点 性能损失：反","title":"Java-反射"},{"content":"java Stream是什么 首先，我们来看下java怎么描述Stream的：\nA sequence of elements supporting sequential and parallel aggregate operations.\n其实学习stream之前我以为stream式很难的，但是学完之后，发现其实还好，并不难，主要在于是否熟练。Stream是java8的新特性，它与 java.io 包里的 InputStream和 OutputStream是完全不同的概念.java8中的Stream主要是用于处理java中的数据的。而且Stream只是将原来的数据拷贝一份，然后通过中间操作处理拷贝的数据，最后通过终端操作将得到我们想要的数据。而且Stream是一种惰性加载的。（惰性加载：如果流的操作中没有执行终止操作也不会执行中间操作。）接下来我们看下Stream的总纲： 详细图：\nstream 创建 废话不多说，直接先上代码：\n// 创建Stream @Test public void test1(){ // 1.通过Collection系列集合提供得stream()或parallelStream()(并行流) // 所有的Collection集合都可以通过stream默认方法获取流 List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(16); Stream\u0026lt;String\u0026gt; stream1 = list.stream(); // 2.通过Arrays中的静态方法stream() 获取数组流 Employee[] employees = new Employee[10]; Stream\u0026lt;Employee\u0026gt; stream2 = Arrays.stream(employees); // 3. 通过Stream中的静态方法of()，实际上还是数组流 Stream\u0026lt;String\u0026gt; stream3 = Stream.of(\u0026#34;aa\u0026#34;,\u0026#34;bb\u0026#34;,\u0026#34;cc\u0026#34;); // 4. 无限流 (迭代,生成) Stream\u0026lt;Integer\u0026gt; stream4 = Stream.iterate(0,(x)-\u0026gt;x+2); stream4.limit(10).forEach(System.out::println); // 5. 使用generate(Supplier\u0026lt;T\u0026gt; s)生成流，需要重写Supplier中的get()方法 Stream.generate(()-\u0026gt;Math.random()*10).limit(5).forEach(System.out::println); // 6.创建一个空的stream Stream\u0026lt;Integer\u0026gt; stream5 = Stream.empty(); } 上面大体上把大多数创建流的方式列出来了，但是我记得之前在csdn上看到一篇博客，上面记载了很多创建流的方式，现在找不到那篇博客了，所以就先把这些方式列出来。\n中间操作 首先把测试过程中使用到的实体类以及对应的测试数据先整出来：\n@Data @Builder @NoArgsConstructor @AllArgsConstructor class Employee{ String name; int age; int salary; } List\u0026lt;Employee\u0026gt; employees = Arrays.asList( new Employee(\u0026#34;张三\u0026#34;, 11, 9000), new Employee(\u0026#34;李四\u0026#34;, 33, 3000), new Employee(\u0026#34;王五\u0026#34;, 44, 4000), new Employee(\u0026#34;王五\u0026#34;, 44, 4000), new Employee(\u0026#34;王五\u0026#34;, 44, 4000), new Employee(\u0026#34;p8\u0026#34;, 44, 4000), new Employee(\u0026#34;李四\u0026#34;, 44, 4000), new Employee(\u0026#34;p8\u0026#34;, 55, 2000) ); filter过滤 limit 截断 @Test public void test2(){ // filter过滤 // limit 截断 employees.stream().filter(x-\u0026gt;{ System.out.println(\u0026#34;执行中间操作\u0026#34;); return x.getAge() \u0026gt; 22; }).forEach(System.out::println); } skip @Test public void test3(){ // skip(n)，跳过n个元素 employees.stream().skip(1).forEach(System.out::println); } distinct去重 @Test public void test4(){ // distinct去重:通过流所生成元素的hashCode()和equals()去除重复元素 employees.stream().distinct().forEach(System.out::println); } map @Test public void test5(){ // map 接收lambda，将元素转换成其他形式或提取信息。 // 接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新的元素 List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;aaa\u0026#34;,\u0026#34;bbb\u0026#34;,\u0026#34;ccc\u0026#34;,\u0026#34;ddd\u0026#34;,\u0026#34;eee\u0026#34;); list.stream().map((str)-\u0026gt;str.toUpperCase()) .forEach(System.out::println); System.out.println(\u0026#34;----------------------------\u0026#34;); employees.stream() .map(Employee::getName) .forEach(System.out::println); System.out.println(\u0026#34;----------------------------\u0026#34;); list.stream().map(StreamTest::filterCharacter).forEach((sm)-\u0026gt;{ System.out.println(\u0026#34;--------第一层----------\u0026#34;); sm.forEach(System.out::println); }); } flatMap,基本与map功能相同，只是可以把一个二位map整成一个一维的，多维的可不可以弄成一维的还没有测试，后面可以试下。 @Test public void test6(){ List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;aaa\u0026#34;,\u0026#34;bbb\u0026#34;,\u0026#34;ccc\u0026#34;,\u0026#34;ddd\u0026#34;,\u0026#34;eee\u0026#34;); // flatMap 接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有的流连接成一个流。 list.stream().flatMap(StreamTest::filterCharacter).forEach(System.out::println); } public static Stream\u0026lt;Character\u0026gt; filterCharacter(String str){ List\u0026lt;Character\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for(Character ch:str.toCharArray()){ list.add(ch); } return list.stream(); } sorted,默认排序 @Test public void test7(){ // sorted()-默认排序 List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;aa\u0026#34;,\u0026#34;dd\u0026#34;,\u0026#34;cc\u0026#34;,\u0026#34;a\u0026#34;); list.stream().sorted().forEach(System.out::println); } sorted，重写Comparator中的compare方法 @Test public void test8(){ // sorted-自定义排序 employees.stream().sorted((e1, e2)-\u0026gt;{ if(e1.getAge() == e2.getAge()){ return e1.getName().compareTo(e2.getName()); }else{ return Integer.compare(e1.getAge(),e2.getAge()); } }).forEach(System.out::println); } 终止操作（终端操作） allMatch() 匹配查询集合中是否都符合条件，返回true/false anyMatch() 匹配查询集合中是否存在符合条件的，返回true/false count() 统计集合中数量……………… 在使用idea可以直接看到stream中的最终操作方法，也能一眼就看明白是要干什么的操作，所以就不一一写到笔记了。\n惰性加载 stream中的惰性加载就是在没有执行最终操作的情况下，所有的中间操作也不会执行。\n@Test public void test13(){ List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(); list.add(\u0026#34;1\u0026#34;); list.add(\u0026#34;2\u0026#34;); list.add(\u0026#34;3\u0026#34;); list.stream().filter(x -\u0026gt; { System.out.println(x); return true; }); } 上面这段代码并不会产生任何的输出，原因是filter只刻画了stream，但是并没有产生新的集合，而像这种没有实际功能，只是描述stream的操作，就叫做惰性求值。而如果在filter之后加上count()（最终操作）则会执行print操作，这种操作叫做及早求值：\n@Test public void test13(){ List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(); list.add(\u0026#34;1\u0026#34;); list.add(\u0026#34;2\u0026#34;); list.add(\u0026#34;3\u0026#34;); list.stream().filter(x -\u0026gt; { System.out.print(x+\u0026#34; \u0026#34;); return true; }).count(); // 打印结果： 1 2 3 } 惰性加载和及早求值区别：\n对流对象Stream进行惰性求值，返回值仍然是一个Stream对象。 对流对象Stream进行及早求值，返回值不再是一个Stream对象。 Stream 并发流 测试Stream并发流主要是通过计算1到50亿的累加，如下：\nlong s = 0L; long e = 5000000000L; 普通for循环 使用最基础的for去计算累加，如下：\n@Test public void test10(){ Instant start = Instant.now(); long sum = 0L; for(long i = s; i \u0026lt; e; i++) { sum += i; } System.out.println(sum); Instant end = Instant.now(); System.out.println(Duration.between(start,end).toMillis()); } 具体时间就不写了，有兴趣的可以自己试下，下面两个也是一样。\nfork-join框架 使用fork-join框架先要重写好RecursiveTask中的compute方法，在compute方法中进行fork()和join()操作。\npublic class ForkJoinSum extends RecursiveTask\u0026lt;Long\u0026gt; { private static final long serialVersionUID = 100000000L; private long start; private long end; private final long THRESHHOLD = 10000L; public ForkJoinSum(long start, long end){ this.start = start; this.end = end; } @Override protected Long compute() { if(end - start \u0026lt;= THRESHHOLD){ long sum = 0L; for(long i = start; i \u0026lt; end; i++) { sum += i; } return sum; } else { long mid = (end+start)/2; ForkJoinSum left = new ForkJoinSum(start, mid); left.fork(); ForkJoinSum right = new ForkJoinSum(mid+1, end); right.fork(); return left.join()+right.join(); } } } 然后再来测试：\n@Test public void test9(){ // 使用fork，join框架 Instant start = Instant.now(); ForkJoinSum forkJoinSum = new ForkJoinSum(s,e); System.out.println(forkJoinSum.compute()); Instant end = Instant.now(); System.out.println(Duration.between(start, end).toMillis()); } stream并发 使用stream并发流计算累加：\n@Test public void test11(){ // 流式并行 Instant start = Instant.now(); OptionalLong optionalLong = LongStream.rangeClosed(s,e) .parallel() .reduce(Long::sum); System.out.println(optionalLong.getAsLong()); Instant end = Instant.now(); System.out.println(Duration.between(start,end).toMillis()); } 实例 先定义一个实体类用于后续使用：\nclass Person{ private int id; private String name; private Date day; private int age; public Person() { } public Person(int id, String name, Date day, int age) { this.id = id; this.name = name; this.day = day; this.age = age; } public int getId() { return id; } public void setId(int id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } public Date getDay() { return day; } public void setDay(Date day) { this.day = day; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } } 判断List中的多个元素是否重复 假如给定数据为一个List,我们需要根据Person中的某几个元素判断是否存在重复。此时可以利用stream中的map和distinct获取count，与原始list的size进行比较判断是否存在重复：\n@Test public void test10(){ List\u0026lt;Person\u0026gt; peopleList = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 10; i++) { peopleList.add(new Person(i, \u0026#34;name\u0026#34;+i, new Date(), i+10)); peopleList.add(new Person(i, \u0026#34;name\u0026#34;+i, new Date(), i+10)); } long count = peopleList.stream().map(x -\u0026gt; x.getName() + \u0026#34;_\u0026#34; + x.getAge()).distinct().count(); System.out.println(peopleList.size() == count); } // 打印结果：false 根据上面的代码可以判断出peopleList中，name和age相同的数据存在重复。\nList中的元素相加求合 假如给定数据为一个List,我们需要根据Person中的某几个元素进行相加之后累加：\n@Test public void test11(){ List\u0026lt;Person\u0026gt; peopleList = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 10; i++) { peopleList.add(new Person(i, \u0026#34;name\u0026#34;+i, new Date(), i+10)); } Integer sum = peopleList.stream().map(x -\u0026gt; x.getId() + x.getAge()).reduce(0, Integer::sum); System.out.println(sum); } // 打印结果：190 小结 虽然上面的几个测试我没有写结果，但是我自己之前测的时候结果是：数据量较小的时候直接使用for累加花费的时间较短，另外两个所用时间都较多，而数据量较大的时候使用并发计算则所用时间较短，但是使用for累加所用时间是成倍数上升的。而stream流计算并发和fork-join框架计算所用时间是差不多的。这里只是使用了.parallel()来生成并发流，使用集合的parallelStream()也可以生成并发流的。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java8-stream/","summary":"java Stream是什么 首先，我们来看下java怎么描述Stream的： A sequence of elements supporting sequential and parallel aggregate operations. 其实学习stream之前我以为stream式很难的，","title":"Java8 Stream"},{"content":"lambda 初识lambda表达式 一个简单的方法，比较两个Integer：\npublic void Test1() { Comparator\u0026lt;Integer\u0026gt; com = new Comparator\u0026lt;Integer\u0026gt;() { @Override public int compare(Integer o1, Integer o2) { return Integer.compare(o1, o2); } }; TreeSet\u0026lt;Integer\u0026gt; treeSet = new TreeSet\u0026lt;\u0026gt;(com); } 下面的这个方法与上面的方法效果相同：\npublic void Test2() { Comparator\u0026lt;Integer\u0026gt; com = (x, y) -\u0026gt; Integer.compare(x, y); TreeSet\u0026lt;Integer\u0026gt; treeSet = new TreeSet\u0026lt;\u0026gt;(com); } 从上面就可以看出lambda表达式可以极大地简化代码量现在有一个需求，找出所有年龄大于35的员工,Employee的实体类属性如下\nString name; int age; int salary; 创建一个List保存数据：\nList\u0026lt;Employee\u0026gt; employees = Arrays.asList( new Employee(\u0026#34;张三\u0026#34;, 11, 9000), new Employee(\u0026#34;李四\u0026#34;, 33, 3000), new Employee(\u0026#34;王五\u0026#34;, 44, 4000), new Employee(\u0026#34;p8\u0026#34;, 55, 2000) ); 一开始，我们也许会选择一种最简单的方法去实现：\n@Test public List\u0026lt;Employee\u0026gt; Test3() { List\u0026lt;Employee\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (Employee employee : employees) { if (employee.age \u0026gt; 35) { list.add(employee) } } return list; } 优化一、使用策略设计模式 自己新建实现类来过滤员工功能 然后有了一个新的需求，找出所有员工中工资高于3500的员工，此时就需要加方法了，然后也许还会有别的需求（姓李的员工）等，我们不可能每次加需求都要加方法，于是这时候可以采用策略设计模式，设计一个接口MyInterface,里面声明一个用于处理过滤员工的方法：\npublic interface MyInterface\u0026lt;T\u0026gt; { boolean filter(T t); } 编写一个专门用于过滤员工的方法：\n/** * 用于过滤 Employee * * @param list * @param myInterface * @return */ List\u0026lt;Employee\u0026gt; filterEmployees(List\u0026lt;Employee\u0026gt; list, MyInterface\u0026lt;Employee\u0026gt; myInterface) { List\u0026lt;Employee\u0026gt; emp = new ArrayList\u0026lt;\u0026gt;(); for (Employee employee : list) { if (myInterface.filter(employee)) { emp.add(employee); } } return emp; } 之后如果需要使用员工过滤的方法时，调用filterEmployees方法时传入MyInterface的具体实现类，这个实现类中重写好所需要的filter方法。\n使用内部匿名类来实现过滤员工功能 我们此时在调用的方法中就是传入一个匿名内部类，重写好我们所需要的方法即可：\n@Test public void test4() { List\u0026lt;Employee\u0026gt; list = filterEmployees(employees, new MyInterface\u0026lt;Employee\u0026gt;() { @Override public boolean filter(Employee employee) { if (employee.age \u0026gt; 22) { return true; } return false; } }); for (Employee employee : list) { System.out.println(employee.name + \u0026#34; \u0026#34; + employee.age + \u0026#34; \u0026#34; + employee.salary); } } 优化二、使用lambda表达式 lambda表达式其实就是简化了使用匿名内部类的写法繁琐\n@Test public void test5() { List\u0026lt;Employee\u0026gt; list = filterEmployees(employees, (employee -\u0026gt; employee.age \u0026gt; 22)); for (Employee employee : list) { System.out.println(employee.name + \u0026#34; \u0026#34; + employee.age + \u0026#34; \u0026#34; + employee.salary); } } lambda原理 在讲almbda原理之前先说下函数式接口FunctionalInterface，FunctionalInterface就是接口中只有一个抽象方法的接口，此时可以使用注解@FunctionalInterface，如果注解的接口内部有多个抽象方法，编译器会报错。那么这和lambda有什么关系呢，思考一下，如果使用lambda来替代一个匿名内部类的写法，我们使用lambda的时候是没有指明使用实现接口的哪个方法的，也就是说如果接口内有多个抽象方法，编译器就不知道lambda想要重写哪个方法，这个时候自然会报错。注意事项：\n保持Lambda表达式简短和一目了然，过长的Lambda表达式通常是危险的，因为代码越长越难以读懂，意图看起来也不明，并且代码也难以复用，测试难度也大。 使用@FunctionalInterface注解，否则他人修改了函数式接口后使用lambda的地方就用不了了。 不要在Lambda表达中执行有\u0026quot;副作用\u0026quot;的操作，\u0026ldquo;副作用\u0026quot;是严重违背函数式编程的设计原则，比如在forEach操作里面操作外面的某个List或者设置某个Map这其实是不对的。 不要把Lambda表达式和匿名内部类同等对待。lambda和匿名内部类是有区别的，主要区别在于匿名内部类中的this和lambda中的this指代的是不同的实例。匿名内部类中的this指向当前匿名内部类的实例（且匿名内部类中的this只能指向内部类的实例，不能指向所在类的实例），而lambda中的this指向所在类的实例，测试如下： private String value = \u0026#34;Enclosing scope value\u0026#34;; @Test public void Test6() { int num = 333; MyInterface\u0026lt;Employee\u0026gt; myInterface = new MyInterface\u0026lt;Employee\u0026gt;() { String value = \u0026#34;Inner class value\u0026#34;; @Override public boolean filter(Employee employee) { System.out.println(\u0026#34;resultIC(this):\u0026#34;+this.value+num); System.out.println(\u0026#34;resultIC(normal):\u0026#34;+value+num); return false; } }; Employee employee = employees.get(0); myInterface.filter(employee); MyInterface\u0026lt;Employee\u0026gt; myInterface1 = employee1 -\u0026gt; { String value = \u0026#34;Lambda value\u0026#34;; System.out.println(\u0026#34;resultLambda(normal):\u0026#34;+value+num); System.out.println(\u0026#34;resultLambda(this):\u0026#34;+this.value+num); this.value = \u0026#34;show\u0026#34;; return true; }; System.out.println(\u0026#34;this.value(before filter):\u0026#34;+this.value); myInterface1.filter(employee); System.out.println(\u0026#34;this.value(after filter):\u0026#34;+this.value); } 打印结果： resultIC(this):Inner class value333 resultIC(normal):Inner class value333 this.value(before filter):Enclosing scope value resultLambda(normal):Lambda value333 resultLambda(this):Enclosing scope value333 this.value(after filter):show 多使用方法引用， 在Lambda表达式中 a -\u0026gt; a.toLowerCase()和String::toLowerCase都能起到相同的作用，但两者相比，后者通常可读性更高并且代码会简短。 尽量避免在Lambda的方法体中使用{}代码块： 优先使用 Foo foo = parameter -\u0026gt; buildString(parameter); private String buildString(String parameter) { String result = \u0026#34;Something \u0026#34; + parameter; //many lines of code return result; } 而不是 Foo foo = parameter -\u0026gt; { String result = \u0026#34;Something \u0026#34; + parameter; //many lines of code return result; }; lambda语法 lambda表达式的语法主要可以参考github on java8\njava8四大内置核心函数式接口 消费型接口(Consumer) 消费型接口源码：\n/** * Represents an operation that accepts a single input argument and returns no * result. Unlike most other functional interfaces, {@code Consumer} is expected * to operate via side-effects. * * \u0026lt;p\u0026gt;This is a \u0026lt;a href=\u0026#34;package-summary.html\u0026#34;\u0026gt;functional interface\u0026lt;/a\u0026gt; * whose functional method is {@link #accept(Object)}. * * @param \u0026lt;T\u0026gt; the type of the input to the operation * * @since 1.8 */ @FunctionalInterface public interface Consumer\u0026lt;T\u0026gt; { /** * Performs this operation on the given argument. * * @param t the input argument */ void accept(T t); } 从上述注释中可以看出，消费型接口就是接收一个参数，然后利用这个参数完成一系列操作。消费型接口使用：\npublic void happy(double money, Consumer\u0026lt;Double\u0026gt; consumer){ consumer.accept(money); } @Test public void test1(){ happy(10, (m)-\u0026gt; System.out.println(m)); // 打印：10.0 } @Test public void test5(){ // 与使用lambda表达式的效果相同 happy(10, new Consumer\u0026lt;Double\u0026gt;() { @Override public void accept(Double aDouble) { System.out.println(aDouble); } }); } 我们必须有一个方法A调用了消费型接口的accept方法，然后运行的时候调用方法A并传入一个消费者对象（可以通过匿名内部类完成），使用lambda则是简化了这段代码。\n供给型接口(Supplier) 供给型接口源码：\n/** * Represents a supplier of results. * * \u0026lt;p\u0026gt;There is no requirement that a new or distinct result be returned each * time the supplier is invoked. * * \u0026lt;p\u0026gt;This is a \u0026lt;a href=\u0026#34;package-summary.html\u0026#34;\u0026gt;functional interface\u0026lt;/a\u0026gt; * whose functional method is {@link #get()}. * * @param \u0026lt;T\u0026gt; the type of results supplied by this supplier * * @since 1.8 */ @FunctionalInterface public interface Supplier\u0026lt;T\u0026gt; { /** * Gets a result. * * @return a result */ T get(); } 供给型接口在get方法完成一系列操作后返回一个结果。供给型接口使用：\npublic List\u0026lt;Integer\u0026gt; getNumList(int length, Supplier\u0026lt;Integer\u0026gt; integerSupplier){ List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(length); for(int i = 0; i \u0026lt; length; i++){ list.add(integerSupplier.get()); } return list; } @Test public void test2(){ List\u0026lt;Integer\u0026gt; list = getNumList(10, ()-\u0026gt;(int)(Math.random()*100)); for(Integer in:list){ System.out.print(in + \u0026#34; \u0026#34;); } // 打印：41 13 90 13 23 54 69 98 22 25 } 和消费者接口一样，必有有一个方法A调用供给型接口中的get方法，然后调用这个方法A并提供一个供给型接口参数。\n函数型接口(Function) 函数型接口源码：\n/** * Represents a function that accepts one argument and produces a result. * * \u0026lt;p\u0026gt;This is a \u0026lt;a href=\u0026#34;package-summary.html\u0026#34;\u0026gt;functional interface\u0026lt;/a\u0026gt; * whose functional method is {@link #apply(Object)}. * * @param \u0026lt;T\u0026gt; the type of the input to the function * @param \u0026lt;R\u0026gt; the type of the result of the function * * @since 1.8 */ @FunctionalInterface public interface Function\u0026lt;T, R\u0026gt; { /** * Applies this function to the given argument. * * @param t the function argument * @return the function result */ R apply(T t); } 函数型接口使用：\n@Test public void test3(){ System.out.println(strHandler(\u0026#34;test\u0026#34;, (s)-\u0026gt;s.toUpperCase())); // 打印：TEST } public String strHandler(String str, Function\u0026lt;String, String\u0026gt; function){ return function.apply(str); } 断言型接口(Predicate) 断言型接口源码：\n/** * Represents a predicate (boolean-valued function) of one argument. * * \u0026lt;p\u0026gt;This is a \u0026lt;a href=\u0026#34;package-summary.html\u0026#34;\u0026gt;functional interface\u0026lt;/a\u0026gt; * whose functional method is {@link #test(Object)}. * * @param \u0026lt;T\u0026gt; the type of the input to the predicate * * @since 1.8 */ @FunctionalInterface public interface Predicate\u0026lt;T\u0026gt; { /** * Evaluates this predicate on the given argument. * * @param t the input argument * @return {@code true} if the input argument matches the predicate, * otherwise {@code false} */ boolean test(T t); } 断言型接口使用：\n@Test public void test4(){ List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;Hello\u0026#34;, \u0026#34;Lambda\u0026#34;, \u0026#34;Go\u0026#34;, \u0026#34;java\u0026#34;); list = filterStr(list, (s)-\u0026gt;s.contains(\u0026#34;o\u0026#34;)); for(String str:list){ System.out.print(str+\u0026#34; \u0026#34;); } // 打印：Hello Go } public List\u0026lt;String\u0026gt; filterStr(List\u0026lt;String\u0026gt; list, Predicate\u0026lt;String\u0026gt; predicate){ List\u0026lt;String\u0026gt; stringList = new ArrayList\u0026lt;\u0026gt;(16); for(String str: list){ if(predicate.test(str)){ stringList.add(str); } } return stringList; } 方法引用 什么是方法引用 若lambda体中的内容已经有方法已经实现了，那么就可以使用方法引用\n其实方法引用只是在lambda的基础上进一步简化编程的繁重工作，上面这句话就很好地说明了这一点，在使用lambda的过程中，也许我们会自己实现所需要的方法，但是如果已经有实现好的方法时，我们直接调用就好了，此时java就使用一种叫做方法引用的东西来简化调用的代码。使用方法引用主要有如下形式：\n引用静态方法\tClass::staticMethodName 引用某个对象的实例方法\tobject::instanceMethodName 引用某个类型的任意对象的实例方法\ttype::methodName 引用构造方法\tClassName::new 引用某个对象的实例方法 废话不多说，直接看代码：\n@Test public void test1(){ // 使用lambda PrintStream ps = System.out; Consumer\u0026lt;String\u0026gt; con = (x)-\u0026gt;ps.println(x); con.accept(\u0026#34;haha\u0026#34;); // 使用方法引用（对象::实例方法名） PrintStream ps1 = System.out; Consumer\u0026lt;String\u0026gt; con1 = ps::println; con1.accept(\u0026#34;dd\u0026#34;); Consumer\u0026lt;String\u0026gt; con2 = System.out::println; con2.accept(\u0026#34;iop\u0026#34;); /** * 打印结果： * haha * dd * iop */ } 上面的代码就展示了从lambda到方法引用的改变过程。当然，这里只是引用某个对象的实例方法。接下来进行一点改变：\n@Test public void test2(){ Employee employee = new Employee(\u0026#34;李四\u0026#34;,33,24); Supplier\u0026lt;String\u0026gt; supplier = ()-\u0026gt; employee.getName(); System.out.println(supplier.get()); // 对象::实例方法名 Supplier\u0026lt;Integer\u0026gt; supplier1 = employee::getAge; System.out.println(supplier1.get()); /** * 打印结果： * 李四 * 33 */ } 上面的test2()使用供应者接口，通过供应者接口拿到一个Integer，再输出到cmd，使用的还是 **对象::实例方法名 **。\n引用静态方法 @Test public void test3(){ Comparator\u0026lt;Integer\u0026gt; comparator = (x,y)-\u0026gt;Integer.compare(x,y); // 类名::静态方法名 Comparator\u0026lt;Integer\u0026gt; comparator1 = Integer::compare; System.out.println(comparator.compare(10,11)); System.out.println(comparator1.compare(10,11)); /** * 打印结果： * -1 * -1 */ } 上面的test3()是通过 Integer::compare 来生成一个Comparator的实例，再调用这个实例的compare方法来获取比较的结果，并将其输出到打印台。\n引用某个类型的任意对象的实例方法 这个引用讲道理我还不会用，主要是看到网上有人说有这个，自己对这些的研究还不够，暂时先写到这里，后面有机会再来更新一下。\n构造器引用 构造器引用，顾名思义，其实就是通过类名::new来获取一个引用，过程中使用了构造器。\n@FunctionalInterface // 取名这么随意主要是测试了一些今天看到的泛型使用时泛型的名称随意使用 interface MyFunction\u0026lt;T,U,R,J\u0026gt;{ J apply(T t,U u,R r); } @Test public void test5(){ Supplier\u0026lt;Employee\u0026gt; supplier = ()-\u0026gt;new Employee(\u0026#34;dd\u0026#34;,22,33); System.out.println(supplier.get()); // 其中new使用的Employee构造器与函数式接口中传入的相同，如下， // Supplier\u0026lt;Employee\u0026gt;只是说明要获取一个Employee对象，但是没有传入参数，则调用的为无参构造器 Supplier\u0026lt;Employee\u0026gt; supplier1 = Employee::new; System.out.println(supplier1.get()); System.out.println(\u0026#34;-------------\u0026#34;); // Function\u0026lt;Integer, Employee\u0026gt; function = Employee::new; // 由于使用了lombok，这里就不能这样写了，得传入三个参数，然后返回一个Employee // 于是自定义了一个函数式接口，传入三个参数，返回一个值（这里返回Employee） MyFunction\u0026lt;String, Integer, Integer, Employee\u0026gt; function = Employee::new; System.out.println(function.apply(\u0026#34;dd\u0026#34;,33,900)); /** * 打印结果： * Employee(name=dd, age=22, salary=33) * Employee(name=null, age=0, salary=0) * ------------- * Employee(name=dd, age=33, salary=900) */ } 其实很多在上面代码中的注释中已经写清楚了，这里就不再赘述。这里还有学到的一个例子，如下\n@Test public void test6(){ Function\u0026lt;Integer, String[]\u0026gt; function = (x)-\u0026gt;new String[x]; String[] strings = function.apply(10); System.out.println(strings.length); Function\u0026lt;Integer, Integer[]\u0026gt; function1 = Integer[]::new; System.out.println(function1.apply(20).length); /** * 打印结果： * 10 * 20 */ } 这个test中使用的是Integer[]::new，而不是普通的类名::new，所以我觉得还是有必要拿出来看看的，以后使用的时候可以参考下。\n总结 函数式编程就和vim一样，是一个熟能生巧的东西，结合Stream可以极大地方面编程，所以以后还是要多练多使用。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java8-%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E5%92%8Clambda/","summary":"lambda 初识lambda表达式 一个简单的方法，比较两个Integer： public void Test1() { Comparator\u0026lt;Integer\u0026gt; com = new Comparator\u0026lt;Integer\u0026gt;() { @Override public int compare(Integer o1, Integer o2) { return Integer.compare(o1, o2); } }; TreeSet\u0026lt;Integer\u0026gt; treeSet = new TreeSet\u0026lt;\u0026gt;(com); } 下面的这个方法与上","title":"Java8 函数式编程和Lambda"},{"content":"首先看下java中的参数传递机制: 基本数据类型传值（未传递地址）方式： class Main{ public static void main(String[] args) { Main main = new Main(); int a = 20; System.out.println(\u0026ldquo;test之前的a:\u0026rdquo; + a); main.test(a); System.out.println(\u0026ldquo;test之后的a:\u0026rdquo; + a); } void test(int a) { a = 10; System.out.println(\u0026ldquo;test中的a:\u0026rdquo; + a); } /* print: test之前的a:20 test中的a:10 test之后的a:20 */ }\n引用数据类型传值（传递的是引用，既地址）方式： @Test public void test1(){ int[] arr = {2,4,5,6}; int[] arr2 = getArr(arr); for(int i = 0; i \u0026lt; arr.length; i++) { System.out.print(arr[i]+\u0026quot; \u0026ldquo;); }\nSystem.out.println(); for(int i = 0; i \u0026lt; arr2.length; i++) { System.out.print(arr[i]+\u0026quot; \u0026quot;); } } public int[] getArr(int[] arr){ for(int i = 0; i \u0026lt; arr.length; i++){ arr[i] = 2; } return arr; } /*\n打印结果： 4 8 10 12 4 8 10 12 */ ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E4%BC%A0%E5%8F%82%E6%9C%BA%E5%88%B6/","summary":"首先看下java中的参数传递机制: 基本数据类型传值（未传递地址）方式： class Main{ public static void main(String[] args) { Main main = new Main(); int a = 20; System.out.println","title":"Java传参机制"},{"content":"Java动态代理 动态代理 实现方式一，JDK动态代理 public class Main { public static void main(String[] args) { MyInvocationHandler myInvocationHandler = new MyInvocationHandler(); Hello hello = (Hello) myInvocationHandler.newProxy(new HelloWorld()); hello.morning(\u0026#34;lin\u0026#34;); } } // 目标接口 public interface Hello { void morning(String name); } // 目标类 public class HelloWorld implements Hello { @Override public void morning(String name) { System.out.println(\u0026#34;Good Moning,\u0026#34;+name); } } // 代理类；方法调用会被转发到该类的invoke()方法。 class MyInvocationHandler implements InvocationHandler{ // 目标代理对象，本例中的HelloWorld的实例 private Object targetObject; // 构造代理对象 public Object newProxy(Object targetObject){ this.targetObject = targetObject; return Proxy.newProxyInstance( targetObject.getClass().getClassLoader(), // targetObject.getClass().getInterfaces(), this ); } //利用反射，在原逻辑上进行增强 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\u0026#34;代理执行之前\u0026#34;); Object invoke = method.invoke(targetObject, args); System.out.println(\u0026#34;代理执行之后\u0026#34;); return invoke; } } //打印结果： 代理开始之前 Good Moning,lin 代理开始之后 调用过程中的堆栈信息： 实现方式二，CGLIB动态代理 CGLIB(Code Generation Library)是一个基于ASM的字节码生成库，它允许我们在运行时对字节码进行修改和动态生成。CGLIB通过继承方式实现代理。 首先导入maven依赖\n\u0026lt;!-- https://mvnrepository.com/artifact/cglib/cglib --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;cglib\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cglib\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 因为没有实现接口该类无法使用JDK代理，通过CGLIB代理实现如下：\n首先实现一个MethodInterceptor，方法调用会被转发到该类的intercept()方法。 然后在需要使用HelloJava的时候，通过CGLIB动态代理获取代理对象。 // 目标类 public class HelloJava { public void hello(String name){ System.out.println(\u0026#34;hello,\u0026#34;+name); } } // 代理类 class MyMethodInterceptor implements MethodInterceptor{ // 进行增强 @Override public Object intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { System.out.println(\u0026#34;代理执行之前\u0026#34;); Object res = methodProxy.invokeSuper(o, args); System.out.println(\u0026#34;代理执行之后\u0026#34;); } } public class Main { public static void main(String[] args) { Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(HelloJava.class); enhancer.setCallback(new MyMethodInterceptor()); // 通过enhancer创建HelloJava实例 HelloJava helloJava = (HelloJava) enhancer.create(); helloJava.hello(\u0026#34;lin\u0026#34;); } } // 结果输出： 代理执行之前 hello,lin 代理执行之后 调用过程中的堆栈信息： 总结动态代理对象 动态代理是JDK在运行期动态使用反射机制创建class字节码并加载的过程，通过动态代理，我们可以在对象创建前后进行增强，或者对象方法调用前后进行增强，在Spring中借助该技术实现了AOP。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/","summary":"Java动态代理 动态代理 实现方式一，JDK动态代理 public class Main { public static void main(String[] args) { MyInvocationHandler myInvocationHandler = new MyInvocationHandler(); Hello hello = (Hello) myInvocationHandler.newProxy(new HelloWorld()); hello.morning(\u0026#34;lin\u0026#34;); } } // 目标接口 public interface Hello { void morning(String name); } // 目标类 public class HelloWorld implements","title":"Java动态代理"},{"content":"class Person implements Cloneable{ String name; int age; @Override public String toString() { return \u0026#34;Person{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } public Person(String name, int age) { this.name = name; this.age = age; } public Person(int age, String name) { this.name = name; this.age = age; } public Person() { } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } @Override public Person clone() throws CloneNotSupportedException { return (Person) super.clone(); } @Override public void finalize() throws Throwable { System.out.println(\u0026#34;finalize...\u0026#34;); super.finalize(); } } public class SubPerson extends Person { String name; int age; @Override public String toString() { return super.toString()+\u0026#34;SubPerson{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } } public static void main(String[] args) { try { SubPerson person = new SubPerson(); Field[] allFields = FieldUtils.getAllFields(person.getClass()); int a = 10; for (Field field : allFields) { if(field.getName() == \u0026#34;age\u0026#34;){ field.setAccessible(true); field.set(person, a++); } } System.out.println(person); } catch (Exception e) { e.printStackTrace(); } } 输出结果：Person{name=\u0026lsquo;null\u0026rsquo;, age=11}SubPerson{name=\u0026lsquo;null\u0026rsquo;, age=10}\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E5%8F%8D%E5%B0%84%E5%AF%B9%E7%88%B6%E5%AD%90%E7%B1%BB%E5%B1%9E%E6%80%A7%E7%9A%84%E5%A4%84%E7%90%86/","summary":"class Person implements Cloneable{ String name; int age; @Override public String toString() { return \u0026#34;Person{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } public Person(String name, int age) { this.name = name; this.age = age; } public Person(int age, String name) { this.name = name; this.age = age; } public Person() { } public String getName() { return name; } public void setName(String name)","title":"Java反射对父子类属性的处理"},{"content":"取本类和父类的所有成员变量 要取本类和基类的所有成员变量，Class类中提供的两种获取类中成员变量的方法都不能直接实现这个需求，但是可以通过简单的while循环来实现。\n// 取所有字段（包括基类的字段） Field[] allFields = clazz.getDeclaredFields(); Class superClass = clazz.getSuperclass(); while (superClass != null) { Field[] superFileds = superClass.getDeclaredFields(); allFields = ArrayUtils.addAll(allFields, superFileds); superClass = superClass.getSuperclass(); } ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E5%8F%8D%E5%B0%84%E8%8E%B7%E5%8F%96%E7%88%B6%E7%B1%BB%E4%BF%A1%E6%81%AF/","summary":"取本类和父类的所有成员变量 要取本类和基类的所有成员变量，Class类中提供的两种获取类中成员变量的方法都不能直接实现这个需求，但是可以通过简","title":"Java反射获取父类信息"},{"content":"1.变量 1.1变量声明 //1、单变量声明,类型放在变量名之后，可以为任意类型 var 变量名 类型 var v1,v2,v3 string //多变量同类型声明 //2、多变量声明 var { v1 int v2 []int } 1.2变量初始化 //1、使用关键字var，声明变量类型并赋值 var v1 int=10 //2、使用关键字var，直接对变量赋值，go可以自动推导出变量类型 var v2=10 //3、直接使用“：=”对变量赋值，不使用var，两者同时使用会语法冲突，推荐使用 v3:=10 1.3变量赋值 //1、声明后再变量赋值 var v int v=10 //2、多重赋值，经常使用在函数的多返回值中，err,v=func(arg) i，j=j,i //两者互换，并不需要引入中间变量 1.4匿名变量 //Go中所有声明后的变量都需要调用到，当出现函数多返回值，并且部分返回值不需要使用时，可以使用匿名变量丢弃该返回值 func GetName()(firstName,lastName,nickName string){ return \u0026#34;May\u0026#34;,\u0026#34;Chan\u0026#34;,\u0026#34;Make\u0026#34; } _,_,nickName:=GetName() //使用匿名变量丢弃部分返回值 2.常量 Go语言中，常量是编译时期就已知且不可变的值，常量可以是数值类型（整型、浮点型、复数类型）、布尔类型、字符串类型。 2.1字面常量 //字面常量(literal)指程序中硬编码的常量 3.14 “foo” true 2.2常量定义 //1、可以限定常量类型，但非必需 const Pi float64 = 3.14 //2、无类型常量和字面常量一样 const zero=0.0 //3、多常量赋值 const( size int64=1024 eof=-1 ) //4、常量的多重赋值，类似变量的多重赋值 const u,v float32=0,3 const a,b,c=3,4,\u0026#34;foo\u0026#34; //无类型常量的多重赋值 //5、常量赋值是编译期行为，可以赋值为一个编译期运算的常量表达式 const mask=1\u0026lt;\u0026lt;3 2.3预定义常量 //预定义常量：true、false、iota //iota：可修改常量，在每次const出现时被重置为0，在下一个const出现前，每出现一次iota，其代表的值自动增1。 const( //iota重置为0 c0=iota //c0==0 c1=iota //c1==1 c2=iota //c2==2 ) //两个const赋值语句一样可以省略后一个 const( //iota重置为0 c0=iota //c0==0 c1 //c1==1 c2 //c2==2 ) 2.4枚举 枚举指一系列相关常量。\nconst( Sunday=iota //Sunday==0,以此类推 Monday Tuesday Wednesday Thursday Friday Saturday //大写字母开头表示包外可见 numberOfDays //小写字母开头表示包内私有 ) ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E5%8F%98%E9%87%8F/","summary":"1.变量 1.1变量声明 //1、单变量声明,类型放在变量名之后，可以为任意类型 var 变量名 类型 var v1,v2,v3 string //多变量同类型声明 //2、多变量声明 var { v1 int","title":"Java变量"},{"content":"java可变参数列表 从java5开始，java支持一种参数写法：Java类型后面三个点(如String…)，叫可变长度参数列表。向其中传入参数时，它支持传入数组，个数不一定的同类型（\u0026hellip;前面的类型）参数。第一次看到别人的代码里写了它的时候是有点懵的，但是用过两次之后就发现这个东西其实很简单。\npublic void printNames(String...names){ for(String name:names){ System.out.println(name); } } @Test public void test2(){ // 传入数组 String[] names = {\u0026#34;baidu\u0026#34;,\u0026#34;ali\u0026#34;,\u0026#34;tentce\u0026#34;}; printNames(names); } @Test public void test3(){ // 传入个数不一定的参数(可以为0个) printNames(\u0026#34;baidu\u0026#34;,\u0026#34;ali\u0026#34;,\u0026#34;tentce\u0026#34;); } 其实查看idea反编译后的文件可以发现：\npublic void printNames(String... names) { String[] var2 = names; int var3 = names.length; for(int var4 = 0; var4 \u0026lt; var3; ++var4) { String name = var2[var4]; System.out.println(name); } } @Test public void test2() { String[] names = new String[]{\u0026#34;baidu\u0026#34;, \u0026#34;ali\u0026#34;, \u0026#34;tentce\u0026#34;}; this.printNames(names); } @Test public void test3() { this.printNames(\u0026#34;baidu\u0026#34;, \u0026#34;ali\u0026#34;, \u0026#34;tentce\u0026#34;); } 也就是说其实java编译器是将这个可变长度参数当成了一个数组，只是说这个数组在写法上是方便了程序员的。接着再测试一波：\npublic void printNames(String...names){ System.out.println(names); } public void printNames(String[] names){ for(String name:names){ System.out.println(name); } } 编译器报错，printNames is already defined in \u0026hellip;.。也就是说编译器的确将这个可变长度参数当成了一个数组。另外，我试着将一个可变数组作为实参传入一个形参为数组的方法中：\n@Test public void test4(){ String[] str = new String[]{\u0026#34;abc\u0026#34;,\u0026#34;def\u0026#34;}; test5(str); } public void test5(String...str){ test6(str); } public void test6(String[] str){ for (String s : str) { System.out.print(s+\u0026#34;,\u0026#34;); } } 编译器不报错，说明有戏，运行后打印结果：\nabc,def, 这也就证明了可变参数其实就是数组，只是写法上有些不同而已。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0/","summary":"java可变参数列表 从java5开始，java支持一种参数写法：Java类型后面三个点(如String…)，叫可变长度参数列表。向其中传入参","title":"Java可变参数"},{"content":"Throwable throw new Exception()既代表 java 运行进入了一个新的分支，不再执行new Exception()后面的语句了，之后再来执行finally中的内容。\njava将所有的错误封装为一个对象，其根本父类为 Throwable, Throwable 有两个子类：Error 和 Exception。\nError Error一般为底层的不可恢复的类； Error 是 Throwable 的子类，用于指示合理的应用程序不应该试图捕获的严重问题。大多数这样的错误都是异常条件。虽然 ThreadDeath 错误是一个“正规”的条件，但它也是 Error 的子类，因为大多数应用程序都不应该试图捕获它。在执行该方法期间，无需在其 throws 子句中声明可能抛出但是未能捕获的 Error 的任何子类，因为这些错误可能是再也不会发生的异常条件。 Exception Exception 类及其子类是 Throwable 的一种形式，它指出了合理的应用程序想要捕获的条件。 Exception：分为未检查异常(RuntimeException)和已检查异常(非RuntimeException)。未检查异常是因为程序员没有进行必需要的检查，因为疏忽和错误而引起的错误。 RuntimeException（运行时异常、既unchecked，未检查异常）是那些可能在 Java 虚拟机正常运行期间抛出的异常的超类。可能在执行方法期间抛出但未被捕获的, RuntimeException 的任何子类都无需在 throws 子句中进行声明。它是Exception 的子类。 几个经典的RunTimeException： java.lang.NullPointerException; java.lang.ArithmaticException; java.lang.ArrayIndexoutofBoundsException； Runtime Exception 和 Exception Runtime Exception：在定义方法时不需要声明会抛出runtime exception； 在调用这个方法时不需要捕获这个runtime exception； runtime exception是从java.lang.RuntimeException或java.lang.Error类衍生出来的。 例如：nullpointexception，IndexOutOfBoundsException就属于runtime exception Exception:定义方法时必须声明所有可能会抛出的exception； 在调用这个方法时，必须捕获它的checked exception，不然就得把它的exception传递下去；exception是从java.lang.Exception类衍生出来的。例如：IOException，SQLException就属于Exception。Exception 属于应用程序级别的异常，这类异常必须捕捉,Exception体系包括RuntimeException体系和其他非RuntimeException的体系RuntimeException 表示系统异常，比较严重，如果出现RuntimeException，那么一定是程序员的错误 异常处理机制 在java中，异常有两种处理机制：\ntry-catch-finally throw 上面说的异常处理的两种方式是有区别的，第一种遇到异常后在catch中直接处理掉，处理完成后继续执行try-catch代码块后面的代码，而throw则是抛给上一层处理（可以一直向上抛，直到在）。\n一个简单的例子：\n@Test public void test1(){ int i = 10 / 0; System.out.println(\u0026#34;程序除0了...\u0026#34;); /** * 打印结果： * java.lang.ArithmeticException: / by zero * * at com.exception.ExceptionTest.test2(ExceptionTest.java:32) */ } 在这个例子中我是直接尝试让程序除0，然后此时就会直接抛出ArithmeticException，后面的打印代码也是直接不再执行的，这样就影响了程序的正常运行。\n异常处理机制一：try-catch-finally（捕获异常） 其实不管是哪一种Exception，在我们知道会发生异常的时候，最终的解决方案都是try-catch-finally,throw到最后还是要通过try-catch-finally来解决的。我们对上面的例子进行改良：\n@Test public void test2(){ try { int i = 10 / 0; System.out.println(\u0026#34;程序除0了...\u0026#34;); }catch (Exception e){ System.out.println(\u0026#34;catch到了异常...\u0026#34;); }finally { System.out.println(\u0026#34;finally中的代码...\u0026#34;); } System.out.println(\u0026#34;try-catch-finally之后的代码...\u0026#34;); /** * 打印结果： * catch到了异常... * finally中的代码... * try-catch-finally之后的代码... */ } 此时我们就看到，在发生异常的时候，我们可以在catch中解决好碰到的异常，然后代码块后面的代码跟着正常执行。\n异常处理机制二：throws(声明异常) 在上面的try-catch机制中我们可以看成自身感冒了，然后自己去药店买了点药，吃完后就好了，不会有什么影响；而throw就类似生病了，自身吃药治不好(既当前方法不处理)，这个时候我们就需要到医院跟医生交代我们有什么问题，然后让医生来解决，可能当前医生治不好，那么这个医生是可以接着throw到上一级的。\n@Test public void test4() throws FileNotFoundException { new FileInputStream(new File(\u0026#34;dd\u0026#34;)); System.out.println(\u0026#34;---------\u0026#34;); /** * 打印结果： * java.io.FileNotFoundException: dd (系统找不到指定的文件。) * * at java.io.FileInputStream.open0(Native Method) */ } 直接爆红出异常，而且后面的打印语句是没有执行的。说明throw这种方式也会影响程序的正常执行，所有我们需要在调用test4()的地方try-catch处理。\n手动抛异常 在这里介绍手动抛RuntimeException和Exception：\npublic class MyClass{ public MyClass() throws RuntimeException{ throw new RuntimeException(); } public MyClass(String msg) throws Exception { throw new Exception(msg); } } 然后我们调用这两个构造器的时候的处理方式如下：\n@Test public void test5(){ new MyClass(); /** * 打印结果： * java.lang.RuntimeException * at com.exception.MyClass.\u0026lt;init\u0026gt;(MyClass.java:15) */ } @Test public void test6(){ try { new MyClass(\u0026#34;测试untracked Exception\u0026#34;); } catch (Exception e) { System.out.println(\u0026#34;捕获到了异常\u0026#34;); } System.out.println(\u0026#34;执行完了try-catch\u0026#34;); /** * 打印结果： * 捕获到了异常 * 执行完了try-catch */ } 自定义异常 自定义异常必须继承自Exception或者Exception的子类，一个简单的自定义异常如下：\npublic class MyException extends Exception { public MyException(){ super(); } public MyException(String msg){ super(msg); } } 抛的方式如下：\npublic MyClass(String msg) throws MyException { throw new MyException(msg); } 异常中的子父类 在java中，若碰到异常的时候采用try-catch方式捕获异常，如果第一个catch捕获的异常必须和后面捕获的异常同级或者是后面捕获的异常的子类。 在代码中throw出去的异常一定得是方法上throws出去的异常的子类。 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E5%BC%82%E5%B8%B8/","summary":"Throwable throw new Exception()既代表 java 运行进入了一个新的分支，不再执行new Exception()后面的语句了，之后再来执行finally中的","title":"Java异常"},{"content":"在java中经常会使用到排序，通常使用的java内置提供的排序方式：\nArrays.sort（） Collection.sort() Collections.sort() Stream中使用sort 对一批对象进行排序的方式：（ps：对对象的多个属性进行排序则多次使用排序方法即可，比如先对Person的age排序，再对name排序，则需要使用两次排序）\n/** * java排序方法： * 1. Arrays.sort（） * 2. Collection.sort() * 3. Collections.sort() * 4. Stream中使用sort */ public class Sort { public static void main(String[] args) { List\u0026lt;Person\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); Person[] people = new Person[10]; for (int i = 0; i \u0026lt; 10; i++) { Person person = new Person(i / 2, \u0026#34;l\u0026#34; + i); people[i] = person; list.add(person); } // Arrays.sort（） System.out.println(\u0026#34;-------begin Arrays.sort()\u0026#34;); Arrays.sort(people, (o1, o2) -\u0026gt; { if (o1.age \u0026gt; o2.age) { return -1; } else if (o1.age \u0026lt; o2.age) { return 1; } else { return 0; } }); for (Person person : people) { System.out.println(person); } System.out.println(\u0026#34;------\u0026#34;); for (Person person : list) { System.out.println(person); } System.out.println(\u0026#34;-----\u0026#34;); list.sort((o1, o2) -\u0026gt; { if (o1.age \u0026gt; o2.age) { return -1; } else if (o1.age \u0026lt; o2.age) { return 1; } else { return 0; } }); for (Person person : list) { System.out.println(person); } System.out.println(\u0026#34;-----\u0026#34;); Collections.sort(list, (o1, o2) -\u0026gt; { if (o1.age \u0026gt; o2.age) { return 1; } else if (o1.age \u0026lt; o2.age) { return -1; } else { return 0; } }); for (Person person : list) { System.out.println(person); } System.out.println(\u0026#34;-----\u0026#34;); list.stream().sorted(Comparator.comparing(Person::getAge).reversed()).forEach(System.out::println); } } class Person { int age; String name; public Person() { } public Person(int age, String name) { this.age = age; this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public String toString() { return \u0026#34;Person{\u0026#34; + \u0026#34;age=\u0026#34; + age + \u0026#34;, name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } 打印结果：\n-------begin Arrays.sort() Person{age=4, name=\u0026#39;l8\u0026#39;} Person{age=4, name=\u0026#39;l9\u0026#39;} Person{age=3, name=\u0026#39;l6\u0026#39;} Person{age=3, name=\u0026#39;l7\u0026#39;} Person{age=2, name=\u0026#39;l4\u0026#39;} Person{age=2, name=\u0026#39;l5\u0026#39;} Person{age=1, name=\u0026#39;l2\u0026#39;} Person{age=1, name=\u0026#39;l3\u0026#39;} Person{age=0, name=\u0026#39;l0\u0026#39;} Person{age=0, name=\u0026#39;l1\u0026#39;} ------ Person{age=0, name=\u0026#39;l0\u0026#39;} Person{age=0, name=\u0026#39;l1\u0026#39;} Person{age=1, name=\u0026#39;l2\u0026#39;} Person{age=1, name=\u0026#39;l3\u0026#39;} Person{age=2, name=\u0026#39;l4\u0026#39;} Person{age=2, name=\u0026#39;l5\u0026#39;} Person{age=3, name=\u0026#39;l6\u0026#39;} Person{age=3, name=\u0026#39;l7\u0026#39;} Person{age=4, name=\u0026#39;l8\u0026#39;} Person{age=4, name=\u0026#39;l9\u0026#39;} ----- Person{age=4, name=\u0026#39;l8\u0026#39;} Person{age=4, name=\u0026#39;l9\u0026#39;} Person{age=3, name=\u0026#39;l6\u0026#39;} Person{age=3, name=\u0026#39;l7\u0026#39;} Person{age=2, name=\u0026#39;l4\u0026#39;} Person{age=2, name=\u0026#39;l5\u0026#39;} Person{age=1, name=\u0026#39;l2\u0026#39;} Person{age=1, name=\u0026#39;l3\u0026#39;} Person{age=0, name=\u0026#39;l0\u0026#39;} Person{age=0, name=\u0026#39;l1\u0026#39;} ----- Person{age=0, name=\u0026#39;l0\u0026#39;} Person{age=0, name=\u0026#39;l1\u0026#39;} Person{age=1, name=\u0026#39;l2\u0026#39;} Person{age=1, name=\u0026#39;l3\u0026#39;} Person{age=2, name=\u0026#39;l4\u0026#39;} Person{age=2, name=\u0026#39;l5\u0026#39;} Person{age=3, name=\u0026#39;l6\u0026#39;} Person{age=3, name=\u0026#39;l7\u0026#39;} Person{age=4, name=\u0026#39;l8\u0026#39;} Person{age=4, name=\u0026#39;l9\u0026#39;} ----- Person{age=4, name=\u0026#39;l8\u0026#39;} Person{age=4, name=\u0026#39;l9\u0026#39;} Person{age=3, name=\u0026#39;l6\u0026#39;} Person{age=3, name=\u0026#39;l7\u0026#39;} Person{age=2, name=\u0026#39;l4\u0026#39;} Person{age=2, name=\u0026#39;l5\u0026#39;} Person{age=1, name=\u0026#39;l2\u0026#39;} Person{age=1, name=\u0026#39;l3\u0026#39;} Person{age=0, name=\u0026#39;l0\u0026#39;} Person{age=0, name=\u0026#39;l1\u0026#39;} ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E6%8E%92%E5%BA%8F/","summary":"在java中经常会使用到排序，通常使用的java内置提供的排序方式： Arrays.sort（） Collection.sort() Collections.sort() Stream中使用sort 对一批对象进行排","title":"Java排序"},{"content":"Calendar类 使用场景 public class CalendarUtils { /** * 获取本月第x天 * @return */ public static Date getDayOfCurrentMonth(Calendar c, int x) { // 设置时间为本月第一天 c.set(Calendar.DAY_OF_MONTH, x); // 将小时至0 c.set(Calendar.HOUR_OF_DAY, 0); // 将分钟至0 c.set(Calendar.MINUTE, 0); // 将秒至0 c.set(Calendar.SECOND,0); // 将毫秒至0 c.set(Calendar.MILLISECOND, 0); return c.getTime(); } } ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E6%97%A5%E6%9C%9F%E5%A4%84%E7%90%86/","summary":"Calendar类 使用场景 public class CalendarUtils { /** * 获取本月第x天 * @return */ public static Date getDayOfCurrentMonth(Calendar c, int x) { // 设置时间为本月第一天 c.set(Calendar.DAY_OF_MONTH, x); // 将小时至0 c.set(Calendar.HOUR_OF_DAY, 0); // 将分钟至0 c.set(Calendar.MINUTE, 0); // 将秒至","title":"Java日期处理"},{"content":"前言 对一个java后台开发者而言，提到缓存，第一反应就是redis和memcache。利用这类缓存足以解决大多数的性能问题了，并且java针对这两者也都有非常成熟的api可供使用。但是我们也要知道，这两种都属于remote cache（分布式缓存），应用的进程和缓存的进程通常分布在不同的服务器上，不同进程之间通过RPC或HTTP的方式通信。这种缓存的优点是缓存和应用服务解耦，支持大数据量的存储，缺点是数据要经过网络传输，性能上会有一定损耗。与分布式缓存对应的是本地缓存，缓存的进程和应用进程是同一个，数据的读写都在一个进程内完成，这种方式的优点是没有网络开销，访问速度很快。缺点是受JVM内存的限制，不适合存放大数据。本篇文章我们主要主要讨论Java本地缓存的的一些常用方案。\n本地缓存常用技术 本地缓存和应用同属于一个进程，使用不当会影响服务稳定性，所以通常需要考虑更多的因素，例如容量限制、过期策略、淘汰策略、自动刷新等。常用的本地缓存方案有：\n根据HashMap自实现本地缓存 Guava Cache Caffeine Encache 总体来说，对于本地缓存的方案中，笔者比较推荐Caffeine，性能上遥遥领先。虽然Encache功能更为丰富，甚至提供了持久化和集群的功能，但是这些功能完全可以依靠其他方式实现。真实的业务工程中，建议使用Caffeine作为本地缓存，另外使用redis或者memcache作为分布式缓存，构造多级缓存体系，保证性能和可靠性。下面分别进行介绍：\n1. 根据HashMap自定义实现本地缓存 缓存的本质就是存储在内存中的KV数据结构，对应的就是jdk中的HashMap，但是要实现缓存，还需要考虑并发安全性、容量限制等策略，下面简单介绍一种利用LinkedHashMap实现缓存的方式：\npublic class LRUCache extends LinkedHashMap { /** * 可重入读写锁，保证并发读写安全性 */ private ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock(); private Lock readLock = readWriteLock.readLock(); private Lock writeLock = readWriteLock.writeLock(); /** * 缓存大小限制 */ private int maxSize; public LRUCache(int maxSize) { super(maxSize + 1, 1.0f, true); this.maxSize = maxSize; } @Override public Object get(Object key) { readLock.lock(); try { return super.get(key); } finally { readLock.unlock(); } } @Override public Object put(Object key, Object value) { writeLock.lock(); try { return super.put(key, value); } finally { writeLock.unlock(); } } @Override protected boolean removeEldestEntry(Map.Entry eldest) { return this.size() \u0026gt; maxSize; } } 复制代码LinkedHashMap维持了一个链表结构，用来存储节点的插入顺序或者访问顺序（二选一），并且内部封装了一些业务逻辑，只需要覆盖removeEldestEntry方法，便可以实现缓存的LRU淘汰策略。此外我们利用读写锁，保障缓存的并发安全性。需要注意的是，这个示例并不支持过期时间淘汰的策略。自实现缓存的方式，优点是实现简单，不需要引入第三方包，比较适合一些简单的业务场景。缺点是如果需要更多的特性，需要定制化开发，成本会比较高，并且稳定性和可靠性也难以保障。对于比较复杂的场景，建议使用比较稳定的开源工具。\n2. 基于Guava Cache实现本地缓存 Guava是Google团队开源的一款 Java 核心增强库，包含集合、并发原语、缓存、IO、反射等工具箱，性能和稳定性上都有保障，应用十分广泛。Guava Cache支持很多特性：\n支持最大容量限制 支持两种过期删除策略（插入时间和访问时间） 支持简单的统计功能 基于LRU算法实现 Guava Cache的使用非常简单，首先需要引入maven包： com.google.guava guava 18.0 复制代码一个简单的示例代码如下：public class GuavaCacheTest { public static void main(String[] args) throws Exception { //创建guava cache Cache\u0026lt;String, String\u0026gt; loadingCache = CacheBuilder.newBuilder() //cache的初始容量 .initialCapacity(5) //cache最大缓存数 .maximumSize(10) //设置写缓存后n秒钟过期 .expireAfterWrite(17, TimeUnit.SECONDS) //设置读写缓存后n秒钟过期,实际很少用到,类似于expireAfterWrite //.expireAfterAccess(17, TimeUnit.SECONDS) .build(); String key = \u0026ldquo;key\u0026rdquo;; // 往缓存写数据 loadingCache.put(key, \u0026ldquo;v\u0026rdquo;); // 获取value的值，如果key不存在，调用collable方法获取value值加载到key中再返回 String value = loadingCache.get(key, new Callable() { @Override public String call() throws Exception { return getValueFromDB(key); } }); // 删除key loadingCache.invalidate(key); } private static String getValueFromDB(String key) { return \u0026ldquo;v\u0026rdquo;; } } 复制代码总体来说，Guava Cache是一款十分优异的缓存工具，功能丰富，线程安全，足以满足工程化使用，以上代码只介绍了一般的用法，实际上springboot对guava也有支持，利用配置文件或者注解可以轻松集成到代码中。\n3. Caffeine Caffeine是基于java8实现的新一代缓存工具，缓存性能接近理论最优。可以看作是Guava Cache的增强版，功能上两者类似，不同的是Caffeine采用了一种结合LRU、LFU优点的算法：W-TinyLFU，在性能上有明显的优越性。Caffeine的使用，首先需要引入maven包： com.github.ben-manes.caffeine caffeine 2.5.5 复制代码使用上和Guava Cache基本类似：public class CaffeineCacheTest { public static void main(String[] args) throws Exception { //创建guava cache Cache\u0026lt;String, String\u0026gt; loadingCache = Caffeine.newBuilder() //cache的初始容量 .initialCapacity(5) //cache最大缓存数 .maximumSize(10) //设置写缓存后n秒钟过期 .expireAfterWrite(17, TimeUnit.SECONDS) //设置读写缓存后n秒钟过期,实际很少用到,类似于expireAfterWrite //.expireAfterAccess(17, TimeUnit.SECONDS) .build(); String key = \u0026ldquo;key\u0026rdquo;; // 往缓存写数据 loadingCache.put(key, \u0026ldquo;v\u0026rdquo;); // 获取value的值，如果key不存在，获取value后再返回 String value = loadingCache.get(key, CaffeineCacheTest::getValueFromDB); // 删除key loadingCache.invalidate(key); } private static String getValueFromDB(String key) { return \u0026ldquo;v\u0026rdquo;; } } 复制代码相比Guava Cache来说，Caffeine无论从功能上和性能上都有明显优势。同时两者的API类似，使用Guava Cache的代码很容易可以切换到Caffeine，节省迁移成本。需要注意的是，SpringFramework5.0（SpringBoot2.0）同样放弃了Guava Cache的本地缓存方案，转而使用Caffeine。\n4. Encache Encache是一个纯Java的进程内缓存框架，具有快速、精干等特点，是Hibernate中默认的CacheProvider。同Caffeine和Guava Cache相比，Encache的功能更加丰富，扩展性更强：\n支持多种缓存淘汰算法，包括LRU、LFU和FIFO 缓存支持堆内存储、堆外存储、磁盘存储（支持持久化）三种 支持多种集群方案，解决数据共享问题 Encache的使用，首先需要导入maven包： org.ehcache ehcache 3.8.0 复制代码以下是一个简单的使用案例：public class EncacheTest { public static void main(String[] args) throws Exception { // 声明一个cacheBuilder CacheManager cacheManager = CacheManagerBuilder.newCacheManagerBuilder() .withCache(\u0026ldquo;encacheInstance\u0026rdquo;, CacheConfigurationBuilder //声明一个容量为20的堆内缓存 .newCacheConfigurationBuilder(String.class,String.class, ResourcePoolsBuilder.heap(20))) .build(true); // 获取Cache实例 Cache\u0026lt;String,String\u0026gt; myCache = cacheManager.getCache(\u0026ldquo;encacheInstance\u0026rdquo;, String.class, String.class); // 写缓存 myCache.put(\u0026ldquo;key\u0026rdquo;,\u0026ldquo;v\u0026rdquo;); // 读缓存 String value = myCache.get(\u0026ldquo;key\u0026rdquo;); // 移除换粗 cacheManager.removeCache(\u0026ldquo;myCache\u0026rdquo;); cacheManager.close(); } } 复制代码\n总结 从易用性角度，Guava Cache、Caffeine和Encache都有十分成熟的接入方案，使用简单。 从功能性角度，Guava Cache和Caffeine功能类似，都是只支持堆内缓存，Encache相比功能更为丰富 从性能上进行比较，Caffeine最优、GuavaCache次之，Encache最差(下图是三者的性能对比结果） ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E6%9C%AC%E5%9C%B0%E7%BC%93%E5%AD%98/","summary":"前言 对一个java后台开发者而言，提到缓存，第一反应就是redis和memcache。利用这类缓存足以解决大多数的性能问题了，并且java针","title":"Java本地缓存"},{"content":"JDK1.5之前的枚举 在JDK1.5之前是没有enum这个关键字的，那么那个时代是怎么实现枚举的呢？主要是通过私有化构造器，然后在类里面创建静态final的对象，在类的外面通过 ** 类名.对象名 ** 来使用枚举的，如下：\nclass Season{ String name; String description; private Season(String name, String description) { this.name = name; this.description = description; } public static final Season SPRING = new Season(\u0026#34;Spring\u0026#34;, \u0026#34;春天\u0026#34;); public static final Season SUMMER = new Season(\u0026#34;Summer\u0026#34;, \u0026#34;夏天\u0026#34;); public static final Season AUTUMN = new Season(\u0026#34;Autumn\u0026#34;, \u0026#34;秋天\u0026#34;); public static final Season WINTER = new Season(\u0026#34;Winter\u0026#34;, \u0026#34;冬天\u0026#34;); public String getName() { return name; } public String getDescription() { return description; } @Override public String toString() { return \u0026#34;Season{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, description=\u0026#39;\u0026#34; + description + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } // 测试方法 @Test public void test1(){ Season Spring = Season.SPRING; Season Summer = Season.SUMMER; Season Autumn = Season.AUTUMN; Season Winter = Season.WINTER; System.out.println(Spring); System.out.println(Spring.getName()+\u0026#34; \u0026#34;+Spring.getDescription()); /** * 打印结果： * Season{name=\u0026#39;Spring\u0026#39;, description=\u0026#39;春天\u0026#39;} * Spring 春天 */ } JDK1.5之后的枚举 在JDK1.5之后，出现了enum关键字，它的作用就是简化前面使用枚举的繁琐，解放程序员的双手的：\nenum Season1{ SPRING(\u0026#34;Spring\u0026#34;,\u0026#34;春天\u0026#34;), SUMMER(\u0026#34;Summer\u0026#34;, \u0026#34;夏天\u0026#34;), AUTUMN(\u0026#34;Autumn\u0026#34;, \u0026#34;秋天\u0026#34;), WINTER(\u0026#34;Winter\u0026#34;, \u0026#34;冬天\u0026#34;); String name; String description; Season1(String name, String description) { this.name = name; this.description = description; } public String getName() { return name; } public String getDescription() { return description; } @Override public String toString() { return \u0026#34;Season{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, description=\u0026#39;\u0026#34; + description + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } @Test public void test2(){ Season1 Spring = Season1.SPRING; Season1 Summer = Season1.SUMMER; System.out.println(Spring); Season1[] season1s = Season1.values(); for(Season1 season1: season1s){ System.out.println(season1 + \u0026#34; ----------\u0026#34;+season1.getName()+\u0026#34;--\u0026#34;+season1.getDescription()); } /** * 打印结果： * Season{name=\u0026#39;Spring\u0026#39;, description=\u0026#39;春天\u0026#39;} * Season{name=\u0026#39;Spring\u0026#39;, description=\u0026#39;春天\u0026#39;} ----------Spring--春天 * Season{name=\u0026#39;Summer\u0026#39;, description=\u0026#39;夏天\u0026#39;} ----------Summer--夏天 * Season{name=\u0026#39;Autumn\u0026#39;, description=\u0026#39;秋天\u0026#39;} ----------Autumn--秋天 * Season{name=\u0026#39;Winter\u0026#39;, description=\u0026#39;冬天\u0026#39;} ----------Winter--冬天 */ } 使用enum之后只是有几个点要注意一下的：\n对象名紧跟在类名后面 对象名后面的参数其实就是传向构造器中的参数 在我看来，其实enum就是一个类，只是这个类定义的时候与其他类不同而已，它的使用方法也略微有点不同，它有一些自己特有的方法，比如values(),valueOf(String str)等。同样，作为一个类，它也能实现接口，比如：\ninterface EnumInterface{ void show(); } enum Season1 implements EnumInterface{ SPRING(\u0026#34;Spring\u0026#34;,\u0026#34;春天\u0026#34;){ @Override public void show(){ System.out.println(\u0026#34;Spring show()\u0026#34;); } }, SUMMER(\u0026#34;Summer\u0026#34;, \u0026#34;夏天\u0026#34;){ @Override public void show(){ System.out.println(\u0026#34;Summer show()\u0026#34;); } }, AUTUMN(\u0026#34;Autumn\u0026#34;, \u0026#34;秋天\u0026#34;){ @Override public void show(){ System.out.println(\u0026#34;Autumn show()\u0026#34;); } }, WINTER(\u0026#34;Winter\u0026#34;, \u0026#34;冬天\u0026#34;){ @Override public void show(){ System.out.println(\u0026#34;Winter show()\u0026#34;); } }; String name; String description; Season1(String name, String description) { this.name = name; this.description = description; } public String getName() { return name; } public String getDescription() { return description; } @Override public String toString() { return \u0026#34;Season{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, description=\u0026#39;\u0026#34; + description + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } @Test public void test2(){ Season1 Spring = Season1.SPRING; Season1 Summer = Season1.SUMMER; System.out.println(Spring); Season1[] season1s = Season1.values(); for(Season1 season1: season1s){ System.out.println(season1 + \u0026#34; ----------\u0026#34;+season1.getName()+\u0026#34;--\u0026#34;+season1.getDescription()); season1.show(); } /** * 打印结果： * Season{name=\u0026#39;Spring\u0026#39;, description=\u0026#39;春天\u0026#39;} * Season{name=\u0026#39;Spring\u0026#39;, description=\u0026#39;春天\u0026#39;} ----------Spring--春天 * Spring show() * Season{name=\u0026#39;Summer\u0026#39;, description=\u0026#39;夏天\u0026#39;} ----------Summer--夏天 * Summer show() * Season{name=\u0026#39;Autumn\u0026#39;, description=\u0026#39;秋天\u0026#39;} ----------Autumn--秋天 * Autumn show() * Season{name=\u0026#39;Winter\u0026#39;, description=\u0026#39;冬天\u0026#39;} ----------Winter--冬天 * Winter show() */ } 此时，在每个对象中重写show()方法，可以使得每个对象都具有不同的行为（实现策略模式），倘若只是在类中重写show()方法，则所有的对象都只是具有一个相同的行为而已。\n小结 枚举并非什么神奇的东西，它只不过是帮助我们简化了一些操作而已，比如我们之前写一些枚举状态之类的东西，可能是这样：\nclass Status{ public static final String NEW = \u0026#34;NEW\u0026#34;; public static final String FINISHED = \u0026#34;FINISHED\u0026#34;; } 用了枚举之后就是这样的，在枚举类的外部还可以使用values()来获取一组Status的对象的数组，极大的方便了我们对状态的遍历。\nenum Status1{ NEW(\u0026#34;NEW\u0026#34;), FINISHED(\u0026#34;FINISHED\u0026#34;); private String str; private Status1(String str){ this.str = str; } } Enum源码分析 假设有这么一个简单的枚举:\npublic enum EnumTest { SOMEONE, ANOTHER_ONE } 首先对其进行编译，然后使用命令javap -verbose EnumTest.class对其反编译，得到如下部分:\npublic final class com.lin.EnumTest extends java.lang.Enum\u0026lt;com.lin.EnumTest\u0026gt; 所以，对于Java来说，枚举是一个语法糖。\n使用策略枚举代替策略模式 普通写法： enum Operation { PLUS,MINUS,TIMES,DIVIDE; double apply(double x,double y){ switch (this){ case PLUS:return x + y; case MINUS:return x - y; case TIMES:return x * y; case DIVIDE:return x / y; } throw new AssertionError(\u0026#34;Unknow op: \u0026#34; + this); } } 使用策略枚举使得代码更加健壮、扩展性更好： enum Operation { PLUS(\u0026#34;+\u0026#34;) { @Override double apply(double x, double y) { return x + y; } }, MINUS(\u0026#34;-\u0026#34;) { @Override double apply(double x, double y) { return x - y; } }, TIMES(\u0026#34;*\u0026#34;) { @Override double apply(double x, double y) { return x * y; } }, DIVIDE(\u0026#34;/\u0026#34;) { @Override double apply(double x, double y) { return x / y; } }; private final String symbol; Operation(String symbol) { this.symbol = symbol; } @Override public String toString() { return this.symbol; } abstract double apply(double x, double y); } 优雅的嵌套枚举策略模式： enum PayrollDay { MonDAY(PayType.WEEKDAY), WEEKDAY(PayType.WEEKDAY), TUESDAY(PayType.WEEKDAY), WENDESDAY(PayType.WEEKDAY), THURSDAY(PayType.WEEKDAY), FRIDAY(PayType.WEEKDAY), SATURDAY(PayType.WEEKEND), SUNDAY(PayType.WEEKEND); private PayType payType; PayrollDay(PayType payType) { this.payType = payType; } double pay(double hoursWorked, double payRate) { return payType.pay(hoursWorked, payRate); } //这里是嵌套枚举 private enum PayType { WEEKDAY { @Override double overtimePay(double hrs, double payRate) { return 0; } }, WEEKEND { @Override double overtimePay(double hrs, double payRate) { return 0; } }; private static final int HOURS_PRE_SHIFT = 8; abstract double overtimePay(double hrs, double payRate); double pay(double hoursWorked, double payRate) { double basePay = hoursWorked * payRate; return basePay + overtimePay(hoursWorked, payRate); } } } ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E6%9E%9A%E4%B8%BE/","summary":"JDK1.5之前的枚举 在JDK1.5之前是没有enum这个关键字的，那么那个时代是怎么实现枚举的呢？主要是通过私有化构造器，然后在类里面创建","title":"Java枚举"},{"content":"概述 泛型在java中有很重要的地位，在面向对象编程及各种设计模式中有非常广泛的应用。\n什么是泛型？为什么要使用泛型？Java泛型（generics）是JDK 5中引入的一个新特性，允许在定义类和接口的时候使用类型参数（type parameter）。\n泛型就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。 泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。\n在泛型出现之前，使用容器时我们都是使用Object来作为参数，然后通过向下转型获取我们想要的数据。比如：\n@Test public void test1(){ List list = new ArrayList(); list.add(\u0026#34;aaaa\u0026#34;); list.add(100); for(int i = 0; i\u0026lt; list.size();i++){ String item = (String)list.get(i); System.out.println(item); } /** * 报错： * aaaa * * java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.String */ } 显然此时向下转型失败，因为List中有Integer数据。在没有泛型的情况下，这就要求编程人员对代码的掌控能力十分高，而且还得时刻准备好检查是否可以向下转型。有没有办法处理这种情况呢，我们可以在编写代码的时候创建一个约定，约定好只能向这个容器放入什么类型的数据，在编译的时候编译器如果发现容器中出现了其他类型的数据就报错。\n编译期有效 上面也说了，泛型只在编译期有效，我们可以测试一下：\n@Test public void test2(){ List\u0026lt;String\u0026gt; list1 = new ArrayList\u0026lt;String\u0026gt;(); List\u0026lt;Integer\u0026gt; list2 = new ArrayList\u0026lt;Integer\u0026gt;(); Class classStringArrayList = list1.getClass(); Class classIntegerArrayList = list2.getClass(); if(classStringArrayList.equals(classIntegerArrayList)){ System.out.println(\u0026#34;类型相同\u0026#34;); } /** * 打印结果： * 类型相同 */ } 通过上面的例子可以证明，在编译之后程序会采取去泛型化的措施。也就是说Java中的泛型，只在编译阶段有效。在编译过程中，正确检验泛型结果后，会将泛型的相关信息擦出，并且在对象进入和离开方法的边界处添加类型检查和类型转换的方法。也就是说，泛型信息不会进入到运行时阶段。\n对此总结成一句话：泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型。\n泛型的使用 泛型有三种使用方式，分别为：泛型类、泛型接口、泛型方法\n泛型类 泛型类的最基本的写法如下：\npublic class Order\u0026lt;T\u0026gt; { private T orderNum; private int orderLine; private String money; ... } 在上面这个例子中，我们new对象的时候传入什么类型，那么orderNum就是什么类型的，比如：\nOrder\u0026lt;String\u0026gt; order = new Order\u0026lt;\u0026gt;(); 则此时orderNum就是一个String类型的变量。而如果我们不传类型时，则默认是为Object，那么这个时候就可能出现这种情况：\n@Test public void test3(){ Order order13 = new Order(13, 11, \u0026#34;99\u0026#34;); System.out.println(order13.getOrderNum().getClass().getName()); order13 = new Order(\u0026#34;123\u0026#34;, 11, \u0026#34;99\u0026#34;); System.out.println(order13.getOrderNum().getClass().getName()); /** * 打印结果： * java.lang.Integer * java.lang.String */ } 另外，泛型的类型参数只能是类类型，不能是简单类型。\n接下来看下泛型类在继承时会出现的情况：\nclass Father\u0026lt;T1, T2\u0026gt;{} // 子类不保留父类的泛型 // 1） 没有类型 擦除 class Son\u0026lt;A, B\u0026gt; extends Father{} //等价于class Son extends Father\u0026lt;Object, Object\u0026gt;{} // 2)具体类型 class Son2\u0026lt;A, B\u0026gt; extends Father\u0026lt;Integer, String\u0026gt;{} //子类保留父类的泛型 // 1)全部保留 class Son3\u0026lt;T1, T2, A, B\u0026gt; extends Father\u0026lt;T1, T2\u0026gt;{} // 2)部分保留 class Son4\u0026lt;T2, A, B\u0026gt; extends Father\u0026lt;Integer, T2\u0026gt;{} 泛型在继承方面的体现：\nList\u0026lt;Object\u0026gt; list = null; List\u0026lt;String\u0026gt; list1 = null; list = list1; // 编译不通过，IDE直接报错 List\u0026lt;String\u0026gt; stringList = null; ArrayList\u0026lt;String\u0026gt; stringArrayList = null; stringList = stringArrayList; // 编译通过 结论：\n类A是类B的父类，G\u0026lt; A \u0026gt;和G\u0026lt; B \u0026gt;是不相关的类型，既并列的类型 类A是类B的父类，A\u0026lt; G \u0026gt;是B\u0026lt; G \u0026gt;的父类 泛型接口 泛型接口与泛型类的定义及使用基本相同。感觉差不多，这里就不做过多的赘述。\n泛型方法 泛型方法跟它所在的类是不是泛型没关系，调用泛型方法时不需要特意指定类型参数的实际类型，编译器可以自动推断。一个简单的泛型方法例子（主要使用\u0026lt; E \u0026gt; 这个标记来标识泛型方法）：\nprivate final static \u0026lt;E\u0026gt; boolean check(E e){ if(e instanceof String){ return true; }else{ return false; } } @Test public void test6(){ Employee employee = new Employee(); System.out.println(check(employee)); } @Test public void test7(){ String str = null; System.out.println(check(str)); } 显然，它是根据传入的参数类型来进行判定的，与方法所在的类是没有关系的。而且泛型方法是可以加上static和final关键字的，而泛型类中的静态方法是不能访问类上定义的泛型的，否则会报错，因为静态方法加载时在类实例化之前的，也就是说泛型T是一个不确定的类型。\n总结一下，泛型方法能使方法独立于类而产生变化。下面时在网上看到的一个指导规则：\n无论何时，如果你能做到，你就该尽量使用泛型方法。也就是说，如果使用泛型方法将整个类泛型化， 那么就应该使用泛型方法。另外对于一个static的方法而已，无法访问泛型类型的参数。 所以如果static方法要使用泛型能力，就必须使其成为泛型方法。 泛型通配符以及泛型上下限 经常发现有List\u0026lt;? super T\u0026gt;、Set\u0026lt;? extends T\u0026gt;的声明，是什么意思呢？\n\u0026lt;? super T\u0026gt;:有下限，表示包括T在内的任何T的父类；比如List\u0026lt;? super Apple\u0026gt; apples; apples.add(new Object()); \u0026lt;? extends T\u0026gt;有上限，表示包括T在内的任何T的子类；比如List\u0026lt;? extends Fruit\u0026gt; flist = new ArrayList\u0026lt;Apple\u0026gt;(); 关于泛型数组(待更) List\u0026lt;String\u0026gt;[] ls = new ArrayList\u0026lt;String\u0026gt;[10]; // 不允许 List\u0026lt;?\u0026gt;[] ls1 = new ArrayList\u0026lt;?\u0026gt;[10]; // 允许 List\u0026lt;String\u0026gt;[] ls2 = new ArrayList[10]; // 运行 下面使用Sun的一篇文档的一个例子来说明这个问题：\nList\u0026lt;String\u0026gt;[] lsa = new List\u0026lt;String\u0026gt;[10]; // Not really allowed. Object o = lsa; Object[] oa = (Object[]) o; List\u0026lt;Integer\u0026gt; li = new ArrayList\u0026lt;Integer\u0026gt;(); li.add(new Integer(3)); oa[1] = li; // Unsound, but passes run time store check String s = lsa[1].get(0); // Run-time error: ClassCastException. 这种情况下，由于JVM泛型的擦除机制，在运行时JVM是不知道泛型信息的，所以可以给oa[1]赋上一个ArrayList而不会出现异常，但是在取出数据的时候却要做一次类型转换，所以就会出现ClassCastException，如果可以进行泛型数组的声明，上面说的这种情况在编译期将不会出现任何的警告和错误，只有在运行时才会出错。而对泛型数组的声明进行限制，对于这样的情况，可以在编译期提示代码有类型安全问题，比没有任何提示要强很多。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E6%B3%9B%E5%9E%8B/","summary":"概述 泛型在java中有很重要的地位，在面向对象编程及各种设计模式中有非常广泛的应用。 什么是泛型？为什么要使用泛型？Java泛型（generi","title":"Java泛型"},{"content":"随着spring的流行，java注解的使用成为了java工程师必不可少的技能。\n注解基本知识 元注解：@Retention、 @Target、 @Document、 @Inherited； Annotation型定义为@interface, 所有的Annotation会自动继承java.lang.Annotation这一接口,并且不能再去继承别的类或是接口。 参数成员只能用public或默认(default)这两个访问权修饰 参数成员只能用基本类型byte，short，char，int，long，float，double，boolean八种基本数据类型和String、Enum、Class、annotations等数据类型，以及这一些类型的数组。 要获取类、方法和字段的注解信息，必须通过Java的反射技术来获取 Annotation对象,除此之外没有别的获取注解对象的方法 注解也可以没有定义成员, 不过这样注解就没啥用了，只起到标识作用 元注解详解 自定义注解类时, 可以指定目标 (类、方法、字段, 构造函数等) , 注解的生命周期(运行时,class文件或者源码中有效), 是否将注解包含在javadoc中及是否允许子类继承父类中的注解, 这些都是通过元注解完成的。\n@Target 表示该注解目标,可能的 ElemenetType 参数包括： ElemenetType.CONSTRUCTOR 构造器声明ElemenetType.FIELD 域声明(包括 enum 实例) ElemenetType.LOCAL_VARIABLE 局部变量声明ElemenetType.METHOD 方法声明ElemenetType.PACKAGE 包声明ElemenetType.PARAMETER 参数声明ElemenetType.TYPE 类，接口(包括注解类型)或enum声明 @Retention表示该注解的生命周期,可选的 RetentionPolicy 参数包括 RetentionPolicy.SOURCE 注解将被编译器丢弃RetentionPolicy.CLASS 注解在class文件中可用，但会被JVM丢弃RetentionPolicy.RUNTIME JVM将在运行期也保留注释，因此可以通过反射机制读取注解的信息 @Documented(/Documented 指示将此注解包含在 javadoc 中 @Inherited 指示允许子类继承父类中的注解 自定义注解使用 自定义注解:\n@Target({ElementType.METHOD, ElementType.TYPE, ElementType.PARAMETER, ElementType.FIELD}) @Retention(RetentionPolicy.RUNTIME) // 如果不是RUNTIME，在运行期拿到的会是null public @interface MyAnnotation { String desc(); int value(); } 使用自定义注解：\n@MyAnnotation(desc = \u0026#34;class-Person\u0026#34;, value = 0) class Person{ @MyAnnotation(desc = \u0026#34;field-name\u0026#34;, value = 1) public String name; @MyAnnotation(desc = \u0026#34;function-show1()\u0026#34;, value = 2) public String show1(@MyAnnotation(desc = \u0026#34;parameter-p1\u0026#34;,value = 3) String p1){ System.out.println(\u0026#34;test1...\u0026#34;); return p1; } } 测试自定义注解：\npublic class TestAnnotation { public static void printMyAnnotation(String fieldName, MyAnnotation annotation){ System.out.println(fieldName+\u0026#34;上的注解：\u0026#34; + annotation + \u0026#34;; 它的desc：\u0026#34;+annotation.desc()+\u0026#34;; 它的value:\u0026#34;+annotation.value()); } public static void main(String[] args) throws Exception { Class\u0026lt;Person\u0026gt; clazz = Person.class; MyAnnotation annotation; // 获取类上的注解 annotation = clazz.getAnnotation(MyAnnotation.class); printMyAnnotation(\u0026#34;类\u0026#34;, annotation); // 获取方法上的注解 Method show1 = clazz.getDeclaredMethod(\u0026#34;show1\u0026#34;, String.class); annotation = show1.getAnnotation(MyAnnotation.class); printMyAnnotation(\u0026#34;方法\u0026#34;, annotation); // 获取参数上的注解 Annotation[][] annotations = show1.getParameterAnnotations(); for (Annotation[] annotation1 : annotations) { for (Annotation annotation2 : annotation1) { annotation = (MyAnnotation) annotation2; printMyAnnotation(\u0026#34;方法参数\u0026#34;, annotation); } } // 获取字段上注解 Field name = clazz.getDeclaredField(\u0026#34;name\u0026#34;); annotation = name.getAnnotation(MyAnnotation.class); printMyAnnotation(\u0026#34;字段\u0026#34;, annotation); } } 打印结果：\n类上的注解：@com.annotation.MyAnnotation(desc=class-Person, value=0); 它的desc：class-Person; 它的value:0 方法上的注解：@com.annotation.MyAnnotation(desc=function-show1(), value=2); 它的desc：function-show1(); 它的value:2 方法参数上的注解：@com.annotation.MyAnnotation(desc=parameter-p1, value=3); 它的desc：parameter-p1; 它的value:3 字段上的注解：@com.annotation.MyAnnotation(desc=field-name, value=1); 它的desc：field-name; 它的value:1 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E6%B3%A8%E8%A7%A3%E4%B8%8E%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E8%A7%A3/","summary":"随着spring的流行，java注解的使用成为了java工程师必不可少的技能。 注解基本知识 元注解：@Retention、 @Target、 @D","title":"Java注解与自定义注解"},{"content":"关于浅拷贝和深拷贝，简单来说就是创建一个和已知对象一模一样的对象。深入了解浅拷贝和深拷贝，对于Java中的值传递或者引用传递将会有更深的理解。\nJava基本类型和引用方式 Java的数据类型分为两大类：基本数据类型和引用类型。 基本数据类型包括字符类型char，布尔类型boolean以及数值类型byte、short、int、long、float、double。 引用类型则包括类、接口、数组、枚举等，同时Java也为每种基本数据类型提供了封装类型，分别是Character,Boolean,Byte,Short,Integer,Long,Floag,Double。引用类型是一种对象类型，它的值指向内存空间的引用，就是地址。 基本数据类型的变量是存储在栈内存中，而引用类型变量是存储在栈内存中，保存的是实际对象在堆内存中的地址，实际对象的属性保存在堆内存中。\n创建对象的方式 通过new 关键词：这是最常用的一种方式，通过new关键词调用类的有参或无参构造方法来创建对象，比如Object o = new Object(); 调用Class类的newInstance方法：默认调用类的无参构造方法创建对象。比如Object object = Class.forName(\u0026ldquo;java.lang.Object\u0026rdquo;).newInstance(); 通过Constructor类的newInstance方法：与2类似，都是通过反射来实现创建对象，比如Object object = Object.class.getConstructor().newInstance(); 利用Clone方法：Clone是Object类中的一个方法，通过对象A.clone()方法会创建一个内容和对象A一模一样的对象B。比如Person clone = person.clone(); 反序列化：序列化是把堆内存中的Java对象数据，通过某种方式把对象存储在磁盘文件中或者传递给其他网络结点（在网络上传输）。而反序列化则是把磁盘文件中的对象数据或者网络结点上的对象数据，恢复成Java对象模型的过程。 浅拷贝 简单来说就是利用Clone方法拷贝属性的值\n深拷贝 深拷贝是相对于浅拷贝来说的，本质原理是每一个属性类中的属性都要被clone一次。实际生产过程一般通过序列化和反序列化完成\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E6%B5%85%E6%8B%B7%E8%B4%9D%E5%92%8C%E6%B7%B1%E6%8B%B7%E8%B4%9D/","summary":"关于浅拷贝和深拷贝，简单来说就是创建一个和已知对象一模一样的对象。深入了解浅拷贝和深拷贝，对于Java中的值传递或者引用传递将会有更深的理解","title":"Java浅拷贝和深拷贝"},{"content":"重载(Overload) 重载(overloading) 是在一个类里面，方法名字相同，而参数不同。返回类型可以相同也可以不同。\n注意：在一个类里面，只有方法名字相同，而参数不同才算是重载，与返回类型无关。既无法以返回值类型作为重载函数的区分标准。\npublic class NameConflict { public void show(){} public int show(){return 1;} } 像上面这种写法，编译的时候直接会报Error： 已在类 com.chapter9_interface.NameConflict中定义了方法 show()\n重写(Override) 重写是子类对父类的允许访问的方法的实现过程进行重新编写, 返回值和形参都不能改变。即外壳不变，核心重写！\n总结 方法的重写(Overriding)和重载(Overloading)是java多态性的不同表现，重写是父类与子类之间多态性的一种表现，重载可以理解成多态的具体表现形式。\n方法重载是一个类中定义了多个方法名相同,而他们的参数的数量不同或数量相同而类型和次序不同,则称为方法的重载(Overloading)。 方法重写是在子类存在方法与父类的方法的名字相同,而且参数的个数与类型一样,返回值也一样的方法,就称为重写(Overriding)。 方法重载是一个类的多态性表现,而方法重写是子类与父类的一种多态性表现。 ","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E9%87%8D%E8%BD%BD%E5%92%8C%E9%87%8D%E5%86%99/","summary":"重载(Overload) 重载(overloading) 是在一个类里面，方法名字相同，而参数不同。返回类型可以相同也可以不同。 注意：在一个类里","title":"Java重载和重写"},{"content":"什么是面向对象？这大概是java中最重要的一部分了，写这篇文章主要是自己之前java基础不怎么样，然后今天看了一些关于面向对象和多态的文章，做下笔记。\n面向对象 java中什么是对象 java中万物皆对象，既所有的一切都可以是对象，动物可以是对象，人可以是对象，头也可以是对象\u0026hellip; 总之，就是我们可以看到的事物基本上都可以是对象。\n什么是面向对象 面向对象并不仅仅是这几个字而已，这是一种编程思想，它强调的是具备功能的对象，以对象为基本单位；在实际开发中，可以有效地帮助企业解决项目庞大不好管理的问题；讲到面向对象编程，就不得讲讲面向过程编程；面向过程强调的是功能行为，以函数为最小单位。\n面向过程编程和面向对象编程 在这里先讲个把大象放进冰箱的例子，在面向过程编程中，我们的做法是：\n打开冰箱 把大象放进冰箱 关闭冰箱 然而在面向对象编程时却不一样了，通常做法是这样的：\n创建冰箱类，并声明打开和关闭冰箱的方法 创建大象类，并声明进入冰箱的方法 创建操作者类，并声明将大象放入冰箱、打开和关闭冰箱的方法 面向对象三大特征 封装 为什么需要封装？封装的作用？ 我要用洗衣机，只需要按一下开关，有必要了解洗衣机内部的结构吗？ 我要用电脑，我只需要知道怎么用就行了，有必要了解电脑的内部结构吗？ 。。。 程序设计一直以来都在追求“高内聚、低耦合” 高内聚：类的内部数据细节自己完成，不允许外部干涉 低耦合：仅对外暴露少量的方法用于使用 隐藏对象内部的复杂性，只对外公开简单的接口。便于外界调用，从而提高系统的可扩展性、可维护性。通俗的说，把该隐藏的隐藏起来，该暴露的暴露出来，这就是封装性的设计思想。\njava封装性的体现需要权限修饰符来配合。 四种权限修饰符（从小到大排列）：private、default(缺省)、protected、public\n作用域 当前类 同一包(package) 子孙类 其他包 public Y Y Y Y protected Y Y Y N default Y Y N N private Y N N N 关于抽象类的一些变化：JDK 1.8以前，抽象类的方法默认访问权限为protectedJDK 1.8时，抽象类的方法默认访问权限变为default关于接口JDK 1.8以前，接口中的方法必须是public的JDK 1.8时，接口中的方法可以是public的，也可以是default的\n继承 继承体现的是is a的关系，比如动物类继承生物类，那么就可以说动物类是一个生物类，反过来则不行。在java中是没有多继承的，那么有的时候我们需要多继承怎么办呢？java提供了接口机制。接口：比如鸟继承动物类，可是并不是所有的动物都能飞，而鸟是可以飞的，那么我们就可以自己写一个Flyable接口，然后鸟在继承动物类的时候实现这个接口，另外鸟是可以实现多个接口的：\nclass Bird extends Animal implements Flyable, Eatable{ // 重写接口中的方法。。。 } 多态 多态性：可以理解未一个事物的多种形态（或者多种行为）。对象的多态性：父类的引用指向子类的对象。多态的使用前提：1. 类的继承；2. 方法的重写\n有了对象的多态性以后，我们在编译器，只能调用父类中声明的方法，但在运行期，我们实际执行的的是子类重写父类的方法，总结如下：\n编译看左面，运行看右面\n对象的多态性只适用于方法，不适用于属性（编译和运行都看左边）\n陷阱：“重写”私有方法 class Aniaml{ private void f() { System.out.println(\u0026#34;private f()\u0026#34;); } } class Cat extends Aniaml{ public void f() { System.out.println(\u0026#34;public f()\u0026#34;); } } public class PrivateOverride { public static void main(String[] args) { Aniaml aniaml = new Cat(); aniaml.f(); /** * 报错： * Error:(22, 15) java: f()可以在com.polymorphism.Aniaml中访问private */ } } 其实这也体现了上面说的方法的多态性为编译看左面，运行看右面。另外，也许你一不小心会尝试这样做：\npublic class PrivateOverride { private void f() { System.out.println(\u0026#34;private f()\u0026#34;); } public static void main(String[] args) { PrivateOverride po = new Derived(); po.f(); /** * 打印结果： * private f() */ } } class Derived extends PrivateOverride { public void f() { System.out.println(\u0026#34;public f()\u0026#34;); } } 你期待的 打印结果是public f()，然而 private 方法也是 final 的，对于派生类来说是隐蔽的。因此，这里 Derived 的 f() 是一个全新的方法；因为基类版本的 f() 屏蔽了 Derived ，因此它都不算是重载方法。结论是只有非 private 方法才能被重写，但是得小心重写 private 方法的现象，编译器不报错，但不会按我们所预期的执行。为了清晰起见，派生类中的方法名采用与基类中 private 方法名不同的命名。\nJava 基本数据类型与类的内部结构 基本数据类型、包装类、String 基本数据类型 大小/字节 包装类 byte 1 Byte short 2 Short char 2 Character int 4 Integer float 4 Float long 8 Long double 8 Double boolean JVM决定 Boolean 基本数据类型转换为包装类 基本数据类型转换为包装类都可以通过调用包装类的构造器来完成，比如：\nInteger in1 = new Integer(10); Float f1 = new Float(1.23f); Boolean b1 = new Boolean(true); 关于包装类，可以看包装类里面的源码实现。比如：\nBoolean b2 = new Boolean(\u0026#34;true123\u0026#34;); // b2为false Boolean类中对使用String类型的参数构造器处理方式为：\nreturn ((s != null) \u0026amp;\u0026amp; s.equalsIgnoreCase(\u0026#34;true\u0026#34;)); 所有上面的b2为false。\n包装类转换为基本数据类型 包装类转换为基本数据类型基本都是通过调用包装类Xxx的xxxValue()完成的，比如：\nInteger in1 = new Integer(12); int i1 = in1.intValue(); System.out.println(i1+11); /** * 打印结果： * 23 */ Float fl1 = new Float(12.3f); float f1 = fl1.floatValue(); /** * 打印结果： * 12.3 */ 自动装箱和自动拆箱 在jdk5之后，jdk提供类自动装箱和自动拆箱，不再要求程序员像上面一样强行处理基本数据类型，为处理基本数据类型提供了极大地便利：\n// 自动装箱 Integer in1 = 10; // 自动拆箱 int in2 = in1; System.out.println(in1 + \u0026#34; \u0026#34;+in2); /** * 打印结果： * 10 10 */ 当然，在这里也有一个小陷阱需要注意一下，就是Boolean和boolean的初始化是不同的，Boolean初始化出来时null，而boolean初始完成后时false：\nclass D{ Boolean flag1; //null boolean flag2; //false } 基本数据类型、包装类和String之间的相互转换 基本数据类型、包装类转换为String类型有两种方式\n使用连接运算： int num1 = 10; String str1 = num1+\u0026#34;\u0026#34;; 调用String重载的valueOf(Xxx xxx)方法即可。 float f1 = 12.3f; String str2 = String.valueOf(f1); String类型转换为基本数据类型、包装类调用包装类的parseXxx(String s)方法\n@Test public void test2(){ String str1 = \u0026#34;123a\u0026#34;; // 错误的情况 ： // int in1 = (int)str1; // Integer in2 = (Integer) str1; // 可能会报NumberFormatException int in1 = Integer.parseInt(str1); boolean b1 = Boolean.parseBoolean(\u0026#34;true1\u0026#34;); } 类的内部结构——代码块 代码块的作用：初始化类、对象 代码块如果有修饰的话，只能使用static 代码块只要分为静态代码块和非静态代码块 静态代码块 内部可以有输出语句 随着类的加载而执行，而且只执行一次 作用：初始化类的信息 如果一个类中定义了多个静态代码块，则按照声明的先后顺序执行 非静态代码块 内部可以有输出语句 随着对象的创建而执行 每创建一个对象，就执行一次非静态代码块 作用：可以才创建对象时，对对象的属性等进行初始化 如果一个类中定义了多个非静态代码块，则按照声明的先后顺序执行 静态代码块和非静态代码块使用实例 public class BlockTest { @Test public void test1(){ System.out.println(Person.desc); Person p1 = new Person(); Person p2 = new Person(); System.out.println(\u0026#34;\\n\u0026#34;+p1.getName()+\u0026#34; \u0026#34;+p1.getAge()); System.out.println(p2.getName()+\u0026#34; \u0026#34;+p2.getAge()); } } class Person{ private String name; private int age; static String desc = \u0026#34;这是一个人\u0026#34;; // 静态代码块 static { System.out.println(\u0026#34;static block\u0026#34;); desc = \u0026#34;在静态进行了修改。。。\u0026#34;+desc; } // 非静态代码块 { System.out.println(\u0026#34;nonstatic block\u0026#34;); this.name = \u0026#34;dd\u0026#34;; this.age = 13; } public String getName() { return name; } public int getAge() { return age; } } 打印结果：\nstatic block 在静态进行了修改。。。这是一个人 nonstatic block nonstatic block dd 13 dd 13 类的内部结构——内部类 当一个事物的内部，还有一个部分需要一个完整的结果进行描述，而这个内部的完整结构又只为外部事物提供服务，那么整个内部的完整结构最好使用内部类。比如人可以抽象成一个类，而人的脑袋也可以抽象成一个类，这个时候就可以将脑袋声明为人的内部类。 在java中，允许一个类的定义位于另一个类的内部，前者称为称为内部类，后者称为外部类。 Inner class一般用于定义它的类或语句之内，在外部引用它时必须给出完整的名称，Inner class的名字不能与包含它的外部类类名相同； 成员内部类（static成员内部类与非static成员内部类） 一方面，作为外部类的成员具有如下特点：\n调用外部类的结构 可以被static修饰 可以被4中不同的权限修饰 另一方面，作为一个类具有如下特点：\n类里面可以定义属性、方法、构造器等 可以被final修饰，表示此类不能被继承，言外之意，不使用final，就可以被继承 可以被abstract修饰 通常，我们使用内部类主要关注如下3个问题：\n如何实例化成员内部类的对象 如何在成员内部类中区分调用外部类的结构 开发中局部内部类的使用（详细请看下面的局部内部类） 关于前面两个问题，可以参考下面的使用：\npublic class InnerClass { @Test public void test1(){ // 实例化非静态内部类 Animal a1 = new Animal(); Animal.Head head1 = a1.new Head(); head1.show(); // 实例化静态内部类 Animal.Hand hand = new Animal.Hand(); hand.f(); // 外部类有继承关系时，若内部类没有进行重写，则默认还是使用外部类父类的内部类。 Person p1 = new Person(\u0026#34;tom\u0026#34;,22); Person.Head head2 = p1.new Head(); head2.thinking(); Animal.Footer footer = p1.new Footer(); footer.show(); p1.change(); p1.show(); /** * 打印结果： * Animal head.... * animal hand f()... * thinking... * Animal footer show... * null * Person{name=\u0026#39;eye change tom\u0026#39;, age=22} */ } } class Animal{ static class Hand{ public void f(){ System.out.println(\u0026#34;animal hand f()...\u0026#34;); } } class Head{ public void show(){ System.out.println(\u0026#34;Animal head....\u0026#34;); } } class Footer{ public void show(){ System.out.println(\u0026#34;Animal footer show...\u0026#34;); } } } class Person extends Animal{ String name; int age; public Person(String name, int age) { this.name = name; this.age = age; } class Head{ public void thinking(){ System.out.println(\u0026#34;thinking...\u0026#34;); } } class Eye{ String name; public void changeName(){ System.out.println(this.name); // 使用Person.this.xx来调用外部类的属性 Person.this.name = \u0026#34;eye change \u0026#34;+ Person.this.name; } } public void change(){ Eye eye = new Eye(); eye.changeName(); } public void show(){ System.out.println(this.toString()); } @Override public String toString() { return \u0026#34;Person{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } } 局部内部类（方法内，代码块内，构造器内） 局部内部类包含着匿名内部类，其实匿名内部类就是局部内部类的一种简写。在java中类似下面这种局部内部类的并不常见：\npublic void method(){ class AA{ } } 主要的还是下面这种：\n// 返回一个实现了Comparable接口的类的对象 public Comparable getComparable(){ class MyComparable implements Comparable{ @Override public int compareTo(Object o) { return 0; } } return new MyComparable(); } 上面这种写法可以更加简便，既使用匿名内部类：\n// 返回一个实现了Comparable接口的类的对象 public Comparable getComparable(){ return new Comparable() { @Override public int compareTo(Object o) { return 0; } }; } 而且匿名内部类里面只能调用局部变量，不能修改局部变量的值，但是可以修改外部成员变量的值，使用OutClass.this.value访问。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/java%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","summary":"什么是面向对象？这大概是java中最重要的一部分了，写这篇文章主要是自己之前java基础不怎么样，然后今天看了一些关于面向对象和多态的文章，","title":"Java面向对象"},{"content":"背景 在公司经常会遇到一些需要做一连串相似的业务逻辑判断需求，比如使用不同支付方式实现商品打折、商店根据客户的vip等级给予客户不同的优惠政策之类的业务场景。假设现在我们接到一个需求，根据客户的VIP等级，给与不同的优惠政策： // VIP1 消费1000 ~ 2000,9折优惠， 消费2000~5000,8折优惠，消费5000~10000，7折优惠, 消费10000~，6折优惠 static String VIP1 = \u0026#34;VIP1\u0026#34;; // VIP2 消费1000 ~ 2000,8.5折优惠， 消费2000~5000,7.5折优惠，消费5000~10000，6.5折优惠，消费10000~，5.5折优惠 static String VIP2 = \u0026#34;VIP2\u0026#34;; // VIP3 消费1000 ~ 2000,8折优惠， 消费2000~5000,7折优惠，消费5000~10000，6折优惠， 消费10000~，5折优惠 static String VIP3 = \u0026#34;VIP3\u0026#34;; // VIP4 消费1000 ~ 2000,7.5折优惠， 消费2000~5000,6.5折优惠，消费5000~10000，5.5折优惠， 消费10000~，4.5折优惠 static String VIP4 = \u0026#34;VIP4\u0026#34;; // VIP5 消费1000 ~ 2000,7折优惠， 消费2000~5000,6折优惠，消费5000~10000，5折优惠， 消费10000~，4折优惠 static String VIP5 = \u0026#34;VIP5\u0026#34;; // VIP6 消费1000 ~ 2000,6.5折优惠， 消费2000~5000,5.5折优惠，消费5000~10000，4.5折优惠， 消费10000~，3.5折优惠 static String VIP6 = \u0026#34;VIP6\u0026#34;; if-else 现在商店来了一个客户，我们需要根据客户的会员等级实现不同的优惠策略。通常使用if-else代码如下：\nstatic BigDecimal PRICE1000 = new BigDecimal(1000); static BigDecimal PRICE2000 = new BigDecimal(2000); static BigDecimal PRICE5000 = new BigDecimal(5000); static BigDecimal PRICE10000 = new BigDecimal(10000); public BigDecimal getPrice(Client client, BigDecimal price){ BigDecimal realPrice = price; if(VIP1.equals(client.getType())){ if(PRICE1000.compareTo(price) \u0026lt; 0 \u0026amp;\u0026amp; PRICE2000.compareTo(price) \u0026gt;= 0){ realPrice = new BigDecimal(\u0026#34;0.9\u0026#34;).multiply(price); } else if(PRICE2000.compareTo(price) \u0026lt; 0 \u0026amp;\u0026amp; PRICE5000.compareTo(price) \u0026gt;= 0){ realPrice = new BigDecimal(\u0026#34;0.8\u0026#34;).multiply(price); } else if(PRICE5000.compareTo(price) \u0026lt; 0 \u0026amp;\u0026amp; PRICE10000.compareTo(price) \u0026gt;= 0){ realPrice = new BigDecimal(\u0026#34;0.7\u0026#34;).multiply(price); } else if(PRICE10000.compareTo(price) \u0026lt; 0){ realPrice = new BigDecimal(\u0026#34;0.6\u0026#34;).multiply(price); } } else if(VIP2.equals(client.getType())){ //... } else if(VIP3.equals(client.getType())){ //... } else if(VIP4.equals(client.getType())){ //... } else if(VIP5.equals(client.getType())){ //... } else if(VIP6.equals(client.getType())){ //... } return realPrice; } 策略模式 很抱歉，实在写不下去了，重复这样子写有些累，后面VIP2~VIP6只需要仿照VIP1的优惠策略写就行，我在这里只是想要表达这种写法实在不怎么样，读者明白我的意思就行。这里可以通过使用策略模式进行优化：\n// 策略接口 public interface VIP { static BigDecimal PRICE1000 = new BigDecimal(1000); static BigDecimal PRICE2000 = new BigDecimal(2000); static BigDecimal PRICE5000 = new BigDecimal(5000); static BigDecimal PRICE10000 = new BigDecimal(10000); BigDecimal getPrice(BigDecimal price); } // 具体策略实现类 public class VIP1 implements VIP { @Override public BigDecimal getPrice(BigDecimal price) { BigDecimal realPrice = price; if(PRICE1000.compareTo(price) \u0026lt; 0 \u0026amp;\u0026amp; PRICE2000.compareTo(price) \u0026gt;= 0){ realPrice = new BigDecimal(\u0026#34;0.9\u0026#34;).multiply(price); } else if(PRICE2000.compareTo(price) \u0026lt; 0 \u0026amp;\u0026amp; PRICE5000.compareTo(price) \u0026gt;= 0){ realPrice = new BigDecimal(\u0026#34;0.8\u0026#34;).multiply(price); } else if(PRICE5000.compareTo(price) \u0026lt; 0 \u0026amp;\u0026amp; PRICE10000.compareTo(price) \u0026gt;= 0){ realPrice = new BigDecimal(\u0026#34;0.7\u0026#34;).multiply(price); } else if(PRICE10000.compareTo(price) \u0026lt; 0){ realPrice = new BigDecimal(\u0026#34;0.6\u0026#34;).multiply(price); } return realPrice; } } // 这里只将VIP1的具体实现放了上来，其他几种策略意思差不多 public class Shop { public BigDecimal getPrice(Client client, BigDecimal price){ VIP vip = null; if(VIP1.equals(client.getType())){ vip = new VIP1(); } else if(VIP2.equals(client.getType())){ vip = new VIP2(); } else if(VIP3.equals(client.getType())){ vip = new VIP3(); } else if(VIP4.equals(client.getType())){ vip = new VIP4(); } else if(VIP5.equals(client.getType())){ vip = new VIP5(); } else if(VIP6.equals(client.getType())){ vip = new VIP6(); } return vip.getPrice(price); } public static void main(String[] args) { Shop shop = new Shop(); Client client = new Client(); client.setType(Shop.VIP1); client.shopping(shop, new BigDecimal(10000)); } } 策略模式+工厂模式 显然，这样子代码看着舒服了一些，而且后面如果哪个VIP等级的优惠政策有了更改，我们只需要在相应的策略实现类中进行修改即可，另外之后如果添加VIP7\u0026hellip;VIPN是只需要添加具体策略实现类就行。当然，这样也会导致后面的类文件十分多，会增添项目文件管理上的麻烦，这一点是需要我们注意的。另外，眼尖的你应该也发现了，上面的代码还是有很多if-else，具体策略类中的if-else暂时无能为力（可以使用策略模式，但是感觉使用了策略模式之后项目文件管理会变成一个巨大的麻烦），后面如果我有了方法解决这个问题，会再更新这篇文章。具体使用哪种策略时使用的if-else判断是可以利用Map来替换，Map中的key为用户VIP类型，value为具体策略类型。利用Map我们可以直接通过get方法拿到我们想要的具体策略实现类的实例，从而获取相应的方法。具体实现大体如下：\npublic class VIPFactory { private static VIPFactory factory = new VIPFactory(); private VIPFactory(){} private static Map vipMap = new HashMap\u0026lt;\u0026gt;(); static { vipMap.put(Shop.VIP1, new VIP1()); vipMap.put(Shop.VIP2, new VIP2()); vipMap.put(Shop.VIP3, new VIP3()); vipMap.put(Shop.VIP4, new VIP4()); vipMap.put(Shop.VIP5, new VIP5()); vipMap.put(Shop.VIP6, new VIP6()); } public static VIPFactory getInstance(){ return factory; } public VIP getVip(String vipType){ return (VIP) vipMap.get(vipType); } } public class Shop { public BigDecimal getPrice(Client client, BigDecimal price){ VIP vip = VIPFactory.getInstance().getVip(client.getType()); return vip.getPrice(price); } public static void main(String[] args) { Shop shop = new Shop(); Client client = new Client(); client.setType(Shop.VIP1); client.shopping(shop, new BigDecimal(10000)); } } 具体的策略实现类我就不再赘述了，工厂使用的是单例模式。其实这个时候可以很明显到感觉代码看起来舒服多了。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%A9%E7%94%A8%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E5%92%8C%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E4%BC%98%E5%8C%96%E4%BB%A3%E7%A0%81%E4%B8%AD%E8%BF%87%E5%A4%9A%E7%9A%84if-else%E6%80%9D%E8%B7%AF/","summary":"背景 在公司经常会遇到一些需要做一连串相似的业务逻辑判断需求，比如使用不同支付方式实现商品打折、商店根据客户的vip等级给予客户不同的优惠政策","title":"利用策略模式和工厂模式优化代码中过多的if-else思路"},{"content":"概念梳理 并行\n多个线程在同一时间在CPU上运行。\n并发表示一会做这个事情，一会做另一个事情，存在着调度。单核 CPU 不可能存在并行（微观上）。\n临界区临界区用来表示一种公共资源或者说是共享数据，可以被多个线程使用。但是每一次，只能有一个线程使用它，一旦临界区资源被占用，其他线程要想使用这个资源，就必须等待。\n阻塞与非阻塞\n阻塞和非阻塞通常用来形容多线程间的相互影响。比如一个线程占用了临界区资源，那么其它所有需要这个资源的线程就必须在这个临界区中进行等待，等待会导致线程挂起。这种情况就是阻塞。\n此时，如果占用资源的线程一直不愿意释放资源，那么其它所有阻塞在这个临界区上的线程都不能工作。阻塞是指线程在操作系统层面被挂起。阻塞一般性能不好，需大约8万个时钟周期来做调度。\n非阻塞则允许多个线程同时进入临界区。\n死锁死锁是进程死锁的简称，是指多个进程循环等待他方占有的资源而无限的僵持下去的局面。\n活锁\n假设有两个线程1、2，它们都需要资源 A/B，假设1号线程占有了 A 资源，2号线程占有了 B 资源；由于两个线程都需要同时拥有这两个资源才可以工作，为了避免死锁，1号线程释放了 A 资源占有锁，2号线程释放了 B 资源占有锁；此时 AB 空闲，两个线程又同时抢锁，再次出现上述情况，此时发生了活锁。\n饥饿饥饿是指某一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行。\n生命周期 创建状态当用 new 操作符创建一个新的线程对象时，该线程处于创建状态。处于创建状态的线程只是一个空的线程对象，系统不为它分配资源。\n就绪状态执行线程的 start() 方法使线程处于就绪状态。\n运行状态调度为线程分配必须的系统资源，安排其运行，并调用线程体——run()方法，这样就使得该线程处于可运行状态（Runnable）。\n休眠状态\n调用了 sleep() 方法； 阻塞状态当发生下列事件时，处于运行状态的线程会转入到阻塞状态：\n当一个线程试图获取一个内部的对象锁（非java.util.concurrent库中的锁），而该锁被其他线程持有，则该线程进入阻塞状态。 当一个线程等待另一个线程通知调度器一个条件时，该线程进入等待状态。例如调用：Object.wait()、Thread.join()以及等待Lock或Condition。 线程输入/输出阻塞； 线程调用 wait() 方法等待特定条件的满足； 如果线程在等待某一条件，另一个对象必须通过 notify() 或 notifyAll() 方法通知等待线程条件的改变； 如果线程是因为输入输出阻塞，需要等待输入输出完成。 线程的创建 java在jdk5之前只提供继承Thread和实现Runnable方式来创建线程，在jdk5之后则新增了两个方法来创建线程。\n继承Thread方式 /** * 通过继承于Thread类 * 重写run()方法，业务逻辑代码放在run()中。 */ class Thread1 extends Thread{ public long times; public Thread1(long times){ this.times = times; } @Override public void run(){ while (times \u0026gt;= 0) { System.out.println(Thread.currentThread().getName()+\u0026#34;** *** times:\u0026#34;+times--); } } } // main中调用： public static void main(String[] args) { Thread1 thread1 = new Thread1(5); thread1.start(); // 不能直接通过调用run()的方式直接启动线程,此时仍处于主线程(main)中。 // thread1.run(); // 多次通过start()启动线程会报IllegalThreadStateException // thread1.start(); int times = 5; while (times \u0026gt;= 0) { System.out.println(Thread.currentThread().getName()+\u0026#34;** *** times:\u0026#34;+times--); } } 打印结果：\nmain** *** times:5 Thread-0** *** times:5 Thread-0** *** times:4 Thread-0** *** times:3 main** *** times:4 Thread-0** *** times:2 main** *** times:3 main** *** times:2 main** *** times:1 main** *** times:0 Thread-0** *** times:1 Thread-0** *** times:0 实现Runnable接口方式 /** * 实现Runnable接口方式， * 重写run()方法，业务逻辑代码放在run()中。 * 调用的时候需要new Thread(传入实现了Runnable接口的实体类对象)，比如：new Thread(p).start(); */ class Thread3 implements Runnable{ public long times; public Thread3(long times){ this.times = times; } @Override public void run() { while (times \u0026gt;= 0) { System.out.println(Thread.currentThread().getName()+\u0026#34;** *** times:\u0026#34;+times--); } } } // main中调用： public static void main(String[] args) { Thread3 thread3 = new Thread3(5); new Thread(thread3).start(); int times = 5; while (times \u0026gt;= 0) { System.out.println(Thread.currentThread().getName()+\u0026#34;** *** times:\u0026#34;+times--); } } 打印结果：\nmain** *** times:5 Thread-0** *** times:5 main** *** times:4 Thread-0** *** times:4 main** *** times:3 main** *** times:2 main** *** times:1 main** *** times:0 Thread-0** *** times:3 Thread-0** *** times:2 Thread-0** *** times:1 Thread-0** *** times:0 实现Callable接口方式 Callable接口源码：\n/** * A task that returns a result and may throw an exception. * Implementors define a single method with no arguments called * {@code call}. * * \u0026lt;p\u0026gt;The {@code Callable} interface is similar to {@link * java.lang.Runnable}, in that both are designed for classes whose * instances are potentially executed by another thread. A * {@code Runnable}, however, does not return a result and cannot * throw a checked exception. * * \u0026lt;p\u0026gt;The {@link Executors} class contains utility methods to * convert from other common forms to {@code Callable} classes. * * @see Executor * @since 1.5 * @author Doug Lea * @param \u0026lt;V\u0026gt; the result type of method {@code call} */ @FunctionalInterface public interface Callable\u0026lt;V\u0026gt; { /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception; } /** * 实现Callable接口方式， * 重写call()方法，将线程中需要执行的业务逻辑代码放在run()中。 */ // 1.创建一个实现Callable的类 class Thread4 implements Callable\u0026lt;Integer\u0026gt;{ // 2.实现call()，将线程中需要执行的业务逻辑代码放在run()中。 @Override public Integer call() throws Exception { int sum = 0; for(int i = 0; i \u0026lt;= 5; i++) { if(i % 2 == 0){ System.out.println(Thread.currentThread().getName()+\u0026#34;** *** i:\u0026#34;+i); sum+=i; } } return sum; } } // main中调用： public static void main(String[] args) { // 3.创建Callable接口实现类的对象 Thread4 thread4 = new Thread4(); // 4.将此Callable接口实现类的对象作为参数传递到FutureTask构造器中，创建FutureTask的对象 FutureTask futureTask = new FutureTask(thread4); // 5.将FutureTask的对象作为参数传递到Thread类的构造器中，创建Thread对象并调用start() new Thread(futureTask).start(); int times = 5; while (times \u0026gt;= 0) { System.out.println(Thread.currentThread().getName()+\u0026#34;** *** times:\u0026#34;+times--); } try { // 6.获取Callable中call方法的返回值 // get()返回值即为FutureTask构造器参数Callable实现类重写的call()的返回值。 Object o = futureTask.get(); System.out.println(o); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } } 打印结果：\nmain** *** times:5 Thread-0** *** i:0 main** *** times:4 main** *** times:3 main** *** times:2 main** *** times:1 main** *** times:0 Thread-0** *** i:2 Thread-0** *** i:4 6 使用线程池 main中调用，Thread3和Thread4同上\npublic static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(10); // 只适合Runnable方式, executorService.execute(new Thread3(5)); // 适合Callable方式和Runnable方式,返回Future对象 Future\u0026lt;Integer\u0026gt; submit = executorService.submit(new Thread4()); try { System.out.println(submit.get()); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); }finally { executorService.shutdown(); } } 打印结果：\npool-1-thread-1** *** times:5 pool-1-thread-1** *** times:4 pool-1-thread-1** *** times:3 pool-1-thread-1** *** times:2 pool-1-thread-1** *** times:1 pool-1-thread-1** *** times:0 pool-1-thread-2** *** i:0 pool-1-thread-2** *** i:2 pool-1-thread-2** *** i:4 6 四种创建方式比较 通过继承Thread和实现Runnable接口创建线程的方式比较简单，只要注意将需要进行逻辑处理的代码方法重写的run()就好。通过实现Callable接口和使用线程池来创建线程是jdk5之后的新方式。\n实现Callable接口\n与使用Runnable相比，Callable功能更强大些\n可以有返回值，FutureTask的对象的get()可以获取重写的call()的返回值 方法可以抛出异常 支持泛型的返回值 需要借助FutureTask类，比如获取返回结果 使用线程池背景： 经常创建和销毁、使用量特别大的资源，比如并发情况下的线程，对性能影响很大思路：提前创建好多个线程，放入线程池中，使用时直接获取，使用完放回池中。可以避免频繁创建销毁，实现重复利用。类似生活中的公共交通工具。好处：\n提高响应速度（减少了创建新线程的时间） 降低资源消耗（重复利用线程池中线程，不需要每次都创建） 便于线程管理 Java中创建线程池很简单，只需要调用Executors中相应的便捷方法即可，比如Executors.newFixedThreadPool(int nThreads)，但是便捷不仅隐藏了复杂性，也为我们埋下了潜在的隐患（OOM，线程耗尽）。\n// Java线程池的完整构造函数 public ThreadPoolExecutor( int corePoolSize, // 线程池长期维持的线程数，即使线程处于Idle状态，也不会回收。 int maximumPoolSize, // 线程数的上限 long keepAliveTime, TimeUnit unit, // 超过corePoolSize的线程的idle时长， // 超过这个时间，多余的线程会被回收。 BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, // 任务的排队队列 ThreadFactory threadFactory, // 新线程的产生方式 RejectedExecutionHandler handler) // 拒绝策略 详细可以查看ThreadPoolExecutor类源码。也可以参考https://www.cnblogs.com/CarpenterLee/p/9558026.html\n线程安全问题 假设有3个窗口在同时卖50张火车票，通过如下代码来实现：\nclass Window extends Thread{ private static int tickets = 50; // 用来计算run()总共跑了多少次 public static int sum = 0; @Override public void run() { while (tickets \u0026gt; 0){ try { sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+\u0026#34;:卖票，票号为：\u0026#34;+tickets--); sum++; } } } public static void main(String[] args) { Window window1 = new Window(); Window window2 = new Window(); Window window3 = new Window(); window1.setName(\u0026#34;窗口1\u0026#34;); window2.setName(\u0026#34;窗口2\u0026#34;); window3.setName(\u0026#34;窗口3\u0026#34;); window1.start(); window2.start(); window3.start(); try { sleep(10000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Window.sum); } 最后几条打印结果：\n窗口1:卖票，票号为：3 窗口3:卖票，票号为：2 窗口1:卖票，票号为：1 窗口3:卖票，票号为：1 窗口2:卖票，票号为：0 72 结果发现3个窗口总共卖了72次，而且其中有多张票号有问题（重票和负数、0号票）的票，原因是多个线程可能同时执行下面代码：\nSystem.out.println(Thread.currentThread().getName()+\u0026#34;:卖票，票号为：\u0026#34;+tickets--); 而且这些线程持有的tickets相同，所有就会出现重票，这就是线程安全问题。\n同步代码块解决线程安全问题 解决通过继承Thread类创建的多线程程序引起的安全问题 class Window extends Thread { private static int tickets = 50; // 用来计算run()总共跑了多少次 public static int sum = 0; @Override public void run() { while (true) { synchronized (Window.class) { if(tickets \u0026gt; 0){ try { sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \u0026#34;:卖票，票号为：\u0026#34; + tickets--); sum++; }else { break; } } } } } public static void main(String[] args) { Window window1 = new Window(); Window window2 = new Window(); Window window3 = new Window(); window1.setName(\u0026#34;窗口1\u0026#34;); window2.setName(\u0026#34;窗口2\u0026#34;); window3.setName(\u0026#34;窗口3\u0026#34;); window1.start(); window2.start(); window3.start(); try { sleep(10000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Window.sum); } 打印结果：\n窗口1:卖票，票号为：50 窗口1:卖票，票号为：49 ... 窗口2:卖票，票号为：4 窗口2:卖票，票号为：3 窗口2:卖票，票号为：2 窗口2:卖票，票号为：1 50 解决通过实现Runnable接口创建的多线程程序引起的安全问题 class Window2 implements Runnable { private int tickets = 50; public static int sum = 0; @Override public void run() { while (true) { synchronized (this) { if (tickets \u0026gt; 0) { try { sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \u0026#34;:卖票，票号为：\u0026#34; + tickets--); sum++; } else { break; } } } } } public static void main(String[] args) { Window2 window = new Window2(); Thread window1 = new Thread(window); Thread window2 = new Thread(window); Thread window3 = new Thread(window); window1.setName(\u0026#34;窗口1\u0026#34;); window2.setName(\u0026#34;窗口2\u0026#34;); window3.setName(\u0026#34;窗口3\u0026#34;); window1.start(); window2.start(); window3.start(); try { sleep(6000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Window2.sum); } 打印结果：\n窗口2:卖票，票号为：50 窗口2:卖票，票号为：49 ... 窗口3:卖票，票号为：3 窗口3:卖票，票号为：2 窗口3:卖票，票号为：1 50 同步方法解决线程安全问题 解决通过继承Thread类创建的多线程程序引起的安全问题 class Window extends Thread { private static int tickets = 50; // 用来计算run()总共跑了多少次 public static int sum = 0; @Override public void run() { while (true) { if(!compute()){ break; } } } private static synchronized boolean compute(){ if(tickets \u0026gt; 0){ try { sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \u0026#34;:卖票，票号为：\u0026#34; + tickets--); sum++; return true; } return false; } } 打印结果：\n窗口1:卖票，票号为：50 窗口3:卖票，票号为：49 ... 窗口2:卖票，票号为：3 窗口2:卖票，票号为：2 窗口2:卖票，票号为：1 50 解决通过实现Runnable接口创建的多线程程序引起的安全问题 class Window2 implements Runnable { private int tickets = 50; public static int sum = 0; @Override public void run() { while (true) { if(!compute()){ break; } } } private synchronized boolean compute(){ if(tickets \u0026gt; 0){ try { sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \u0026#34;:卖票，票号为：\u0026#34; + tickets--); sum++; return true; } return false; } } 打印结果：\n窗口1:卖票，票号为：50 窗口1:卖票，票号为：49 ... 窗口3:卖票，票号为：3 窗口3:卖票，票号为：2 窗口3:卖票，票号为：1 50 Lock解决线程安全问题 jdk5之后，\n解决通过继承Thread类创建的多线程程序引起的安全问题 class Window2 implements Runnable { private int tickets = 50; public static int sum = 0; private ReentrantLock lock = new ReentrantLock(true); @Override public void run() { while (true) { try { lock.lock(); if(tickets \u0026gt; 0){ try { sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \u0026#34;:卖票，票号为：\u0026#34; + tickets--); sum++; }else { break; } }finally { lock.unlock(); } } } } 打印结果：\n窗口2:卖票，票号为：50 窗口1:卖票，票号为：49 窗口3:卖票，票号为：48 ... 窗口2:卖票，票号为：2 窗口1:卖票，票号为：1 50 解决通过实现Runnable接口创建的多线程程序引起的安全问题 class Window extends Thread { private static int tickets = 50; // 用来计算run()总共跑了多少次 public static int sum = 0; private static ReentrantLock lock = new ReentrantLock(true); @Override public void run() { while (true) { try{ lock.lock(); if(tickets \u0026gt; 0){ try { sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \u0026#34;:卖票，票号为：\u0026#34; + tickets--); sum++; } else { break; } }finally { lock.unlock(); } } } } 打印结果：\n窗口1:卖票，票号为：50 窗口2:卖票，票号为：49 ... 窗口3:卖票，票号为：3 窗口1:卖票，票号为：2 窗口2:卖票，票号为：1 50 线程通信 生产者消费者问题 生产者-消费者模式是一个十分经典的多线程并发协作的模式，所谓生产者-消费者问题，实际上主要是包含了两类线程，一种是生产者线程用于生产数据，另一种是消费者线程用于消费数据，为了解耦生产者和消费者的关系，通常会采用共享的数据区域，就像是一个仓库，生产者生产数据之后直接放置在共享数据区中，并不需要关心消费者的行为；而消费者只需要从共享数据区中去获取数据，就不再需要关心生产者的行为。但是，这个共享数据区域中应该具备这样的线程间并发协作的功能：\n如果共享数据区已满的话，阻塞生产者继续生产数据放置入内； 如果共享数据区为空的话，阻塞消费者继续消费数据； 实现案例：\nclass Clerk{ private int sum = 0; public synchronized void pruduce(){ if(sum \u0026lt; 20){ sum++; System.out.println(Thread.currentThread().getName()+\u0026#34;** ****生产第\u0026#34;+sum+\u0026#34;个数据\u0026#34;); notify(); }else { try { wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } public synchronized void comsumer(){ if(sum \u0026gt; 0){ System.out.println(Thread.currentThread().getName()+\u0026#34;** ****消费第\u0026#34;+sum+\u0026#34;个数据\u0026#34;); sum--; notify(); }else { try { wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } } class Productor implements Runnable{ Clerk clerk; public Productor(Clerk clerk){ this.clerk = clerk; } @Override public void run() { while (true){ try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } clerk.pruduce(); } } } class Comsumer implements Runnable{ Clerk clerk; public Comsumer(Clerk clerk){ this.clerk = clerk; } @Override public void run() { while (true){ try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } clerk.comsumer(); } } } public class ComsumerTest { public static void main(String[] args) { Clerk clerk = new Clerk(); Productor productor = new Productor(clerk); Comsumer comsumer = new Comsumer(clerk); Thread threadProductor = new Thread(productor); Thread threadComsumer = new Thread(comsumer); threadProductor.setName(\u0026#34;Productor\u0026#34;); threadComsumer.setName(\u0026#34;Comsumer\u0026#34;); threadProductor.start(); threadComsumer.start(); } } 死锁以及死锁避免 死锁的定义 所谓死锁是指多个线程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。例如，某计算机系统中只有一台打印机和一台输入 设备，进程P1正占用输入设备，同时又提出使用打印机的请求，但此时打印机正被进程P2 所占用，而P2在未释放打印机之前，又提出请求使用正被P1占用着的输入设备。这样两个进程相互无休止地等待下去，均无法继续执行，此时两个进程陷入死锁状态。\n死锁产生原因 系统资源的竞争\n通常系统中拥有的不可剥夺资源，其数量不足以满足多个进程运行的需要，使得进程在运行过程中，会因争夺资源而陷入僵局，如磁带机、打印机等。只有对不可剥夺资源的竞争才可能产生死锁，对可剥夺资源的竞争是不会引起死锁的。\n进程推进顺序非法\n进程在运行过程中，请求和释放资源的顺序不当，也同样会导致死锁。例如，并发进程 P1、P2分别保持了资源R1、R2，而进程P1申请资源R2，进程P2申请资源R1时，两者都会因为所需资源被占用而阻塞。\nJava中死锁最简单的情况是，一个线程T1持有锁L1并且申请获得锁L2，而另一个线程T2持有锁L2并且申请获得锁L1，因为默认的锁申请操作都是阻塞的，所以线程T1和T2永远被阻塞了。导致了死锁。这是最容易理解也是最简单的死锁的形式。但是实际环境中的死锁往往比这个复杂的多。可能会有多个线程形成了一个死锁的环路，比如：线程T1持有锁L1并且申请获得锁L2，而线程T2持有锁L2并且申请获得锁L3，而线程T3持有锁L3并且申请获得锁L1，这样导致了一个锁依赖的环路：T1依赖T2的锁L2，T2依赖T3的锁L3，而T3依赖T1的锁L1。从而导致了死锁。\n死锁产生条件 互斥条件进程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内某资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。通俗点讲就是一个资源每次只能被一个进程使用。独木桥每次只能通过一个人。\n不剥夺条件进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放（只能是主动释放)。通俗点讲就是一个进程因请求资源而阻塞时，对已获得的资源保持不放。乙不退出桥面，甲也不退出桥面。\n请求和保持条件进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。通俗点讲就是进程已获得的资源，在未使用完之前，不能强行剥夺。甲不能强制乙退出桥面，乙也不能强制甲退出桥面。\n循环等待条件循环等待条件：存在一种进程资源的循环等待链，链中每一个进程已获得的资源同时被链中下一个进程所请求。即存在一个处于等待状态的进程集合{Pl, P2, \u0026hellip;, pn}，其中Pi等 待的资源被P(i+1)占有（i=0, 1, \u0026hellip;, n-1)，Pn等待的资源被P0占有。通俗点讲就是若干进程之间形成一种头尾相接的循环等待资源关系。如果乙不退出桥面，甲不能通过，甲不退出桥面，乙不能通过。\n死锁产生实例 class Dead implements Runnable{ StringBuffer s1 = new StringBuffer(); StringBuffer s2 = new StringBuffer(); @Override public void run() { synchronized(s1){ try { sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } s1.append(\u0026#34;ab\u0026#34;); synchronized(s2){ s2.append(\u0026#34;cd\u0026#34;); } } synchronized (s2){ try { sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } s2.append(\u0026#34;ab\u0026#34;); synchronized(s1){ s1.append(\u0026#34;cd\u0026#34;); } } System.out.println(s1+\u0026#34;\\n\u0026#34;+s2); } } public static void main(String[] args) { Dead dead = new Dead(); new Thread(dead).start(); new Thread(dead).start(); } 如何避免死锁 在有些情况下死锁是可以避免的。下面介绍三种用于避免死锁的技术：\n加锁顺序（线程按照一定的顺序加锁） 加锁时限（线程尝试获取锁的时候加上一定的时限，超过时限则放弃对该锁的请求，并释放自己占有的锁） 死锁检测 1、加锁顺序当多个线程需要相同的一些锁，但是按照不同的顺序加锁，死锁就很容易发生。如果能确保所有的线程都是按照相同的顺序获得锁，那么死锁就不会发生。上面的那个例子就是加锁顺序不当导致的。避免嵌套封锁：这是死锁最主要的原因的，如果你已经有一个资源了就要避免封锁另一个资源。如果你运行时只有一个对象封锁，那是几乎不可能出现一个死锁局面的。\n2、加锁时限另外一个可以避免死锁的方法是在尝试获取锁的时候加一个超时时间，这也就意味着在尝试获取锁的过程中若超过了这个时限该线程则放弃对该锁请求。若一个线程没有在给定的时限内成功获得所有需要的锁，则会进行回退并释放所有已经获得的锁，然后等待一段随机的时间再重试。这段随机的等待时间让其它线程有机会尝试获取相同的这些锁，并且让该应用在没有获得锁的时候可以继续运行(加锁超时后可以先继续运行干点其它事情，再回头来重复之前加锁的逻辑)。\n3、死锁检测死锁检测是一个更好的死锁预防机制，它主要是针对那些不可能实现按序加锁并且锁超时也不可行的场景。主要可以参考银行家算法的思想。\n","permalink":"https://luolin1024.github.io/blog_prepublish/%E6%8A%80%E6%9C%AF%E6%8F%90%E5%8D%87/java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B/","summary":"概念梳理 并行 多个线程在同一时间在CPU上运行。 并发表示一会做这个事情，一会做另一个事情，存在着调度。单核 CPU 不可能存在并行（微观上）。 临界区临","title":"多线程编程"},{"content":"互惠 欲先取之，必先予之 先拒绝，后让步，也可以造就互惠效应\n承诺与一致 人们趋于遵守自己对外暴露的承诺 登门槛效应：从一件小事开始，当你同意了他人的要求，并有所付出，那么下一次大概率还是会同意他的要求 做出一个承诺所需要付出的努力越多，这个承诺对许诺者的影响就越大。【经历了干辛万苦才得到某样东西的人比那些不费吹灰之力就得到这样东西的人对这样东西会更加珍惜】\n社会认同 只要人群中的大部分人开始做一件相同的事，那么剩余的人也会渐渐开始做这件事。例如生意中每一笔交易都会强化这样一种印象：其他类似的人也想得到这种产品，因此这种产品一定不错。 从众效应会很大的影响人们的判断 在那些对情况不熟悉或没有把握、因而必须从外界寻找证据的人中间，社会认同是最有效的。\n重点内容有两个\n不确定性：当人们对自己的处境不是很有把握时，更有可能根据他人的行为来决定自己应该怎么办。 相似性：与我们类似的人的行为对我们最有影响力。 喜好 我们大多数人更容易答应自己认识和喜欢的人所提出的要求”\n喜欢他人的原因5个原因 外表魅力。 相似性，我们喜欢跟自己相似的人，相似表现在对某件事情的看法、家庭环境、成长背景、兴趣爱好。 称赞，人人都喜欢听好话 接触和合作，一般来说，我们总是比较喜欢自己熟悉的东西 关联，聪明的人懂得将积极正面的事情同自己联系起来，从而塑造自我形象。外貌形象带来的影响。 如何抵御他人的喜好影响力 比较好的做法应该是一种有意识的努力：把精力集中在这一笔生意，也就是说丹要卖给我们的车上。当然，当我们做任何一个决定时，都应该把提出要求的人和提出的要求分开。\n权威 人们总是倾向于遵从权威人物的意愿行事\n如何获得权威性 头衔 衣着 外部标志，比如老板们的豪车 如何保护自己被盲目引导 识别出什么时候应该听从权威的意见，什么时候则不应该。 识别权威的真假 识别权威的意图 稀缺 什么是稀缺：从个人的角度有供不应求的现象\n去爱一样东西的方法之—就是意识到它可能会失去。——格•克 • 切斯特顿\n数量有限、时间有限会导致稀缺 当一种机会变得比较难得时，我们也就失去了自己的一部分自由。 与希望获得一样东西的渴望相比，害怕失去同样价值的东西的恐惧似乎更能成为人们行动的动力。当供应由充足变为短缺时，人们对小甜饼产生了比供应一直短缺时更积极的正面反应。 按照短缺原理，如果我们觉得某条信息不可多得，这条信息对我们就会更有说服力。 对稀少资源的竞争会导致狂热 如何避免稀缺带来的影响 多问自己为什么？ 比如购买一件看起来比较稀缺的商品时，从我为什么要买它找到\n","permalink":"https://luolin1024.github.io/blog_prepublish/pre-publish/%E5%BD%B1%E5%93%8D%E5%8A%9B/","summary":"互惠 欲先取之，必先予之 先拒绝，后让步，也可以造就互惠效应 承诺与一致 人们趋于遵守自己对外暴露的承诺 登门槛效应：从一件小事开始，当你同意了他人的","title":"影响力"},{"content":"序 每天忙于脚下的六便士时，也要偶尔抬头看看天上的月亮\n文章故事 “我”是一位作家，在一次偶然的机会下认识了思特里克兰德，沿着“我”所了解的思特里克兰德有关的事件开始讲述故事。思特里克兰德原本有一个美好的家庭，一个美丽的妻子，自己本人在银行上班，妻子喜欢与艺术家们交往，可却深爱着自己的丈夫，但这一切不过是暴风雨前的平静而已。突然有一天，思特里克兰德辞职了，独自一人离开伦敦前往巴黎，想要在巴黎独身一人学习画画。而一开始思特里克兰德夫人却认为是有一个女人把思特里克兰德哄骗到巴黎，想要在巴黎过纸醉金迷的生活，直到“我”告诉思特里克兰德夫人真相之后，她才接受事实，从一个阔太太腰身一变开始为了生活而工作。多年后，我来到巴黎，再次遇见思特里克兰德，他现在住的更加残破不堪，但他毫不在意。由于住的不好，思特里克兰德生病了，斯特洛夫把他带回家照顾，但却没有想到斯特洛夫夫人爱上了思特里克兰德并要追随思特里克兰德，斯特洛夫将自己的，房子留给了二人。不久，思特里克兰德离开了这间房子，而这导致了斯特洛夫夫人自杀身亡。接下来思特里克兰德去了塔希提，在那里与一个本土女孩再一次结婚生子，并完成了一生最辉煌的著作。 我认为这本书是在鼓励世人去追逐自己的梦想，追逐梦想就是追逐噩梦，在这个过程中，或许会得不到家人的理解，被他人嘲笑，被认为是特立独行的。但还是有人放弃一切去追寻自己的梦想，而这需要巨大的勇气。 而在这平凡的生活中，我们常常忙于生活的日常，忘记了心中的理想，忘记了自己的月亮。但我希望我可以在这满是六便士的路上矢志不渝的追寻月亮。\n名句摘录 为什么讨人喜欢的女人总是嫁给头脑不好的人呢?因为聪明的男人是不会娶讨人喜欢的女人的。 其实，一个人可以兼备卑鄙和伟大、邪恶与善良 善良过头就是愚蠢，从那些受他恩惠却反咬一口的人身上就能看出这一点。 过去的事我已经不再回想了，我要抓住现在，只有现在是永恒的 女人就是这样的生物，她对待一个自己不爱的男人会比对其他人残忍得多 通常来说，在进行社交的时候，人们只会让你看到他希望别人看到他的样子，所以你只能从他无意识的一些小动作，小习惯，或者不经意间在面颊上流露过的一丝情绪来对他进行推断和揣测，一个人倘若将面具戴久了，可能就摘不下来了，久而久之就会变成和自己的面具一样的人。 上帝的磨盘虽然转的很慢，但是却磨得很细 魔鬼在干坏事之前总是可以引用《圣经》的 ","permalink":"https://luolin1024.github.io/blog_prepublish/pre-publish/%E6%9C%88%E4%BA%AE%E4%B8%8E%E5%85%AD%E4%BE%BF%E5%A3%AB/","summary":"序 每天忙于脚下的六便士时，也要偶尔抬头看看天上的月亮 文章故事 “我”是一位作家，在一次偶然的机会下认识了思特里克兰德，沿着“我”所了解的思特里","title":"月亮与六便士"},{"content":"无限进步，无限超越\n关注架构、互联网技术、分布式、服务化、数据库等\n分享个人思考、前沿技术、高效工具和实用编程技巧\n","permalink":"https://luolin1024.github.io/about/","summary":"about","title":"About"},{"content":" luolin的博客 种一棵树最好的时间是十年前，其次是现在 美团技术团队 美团技术团队 廖雪峰的官方网站 廖雪峰的官方网站 阮一峰的网络日志 阮一峰的网络日志 ","permalink":"https://luolin1024.github.io/links/","summary":"links","title":"Links"}]